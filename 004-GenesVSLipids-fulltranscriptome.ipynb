{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ad3ec6-29fd-4355-887d-ad1a72a62e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import anndata\n",
    "\n",
    "imputed_h5ad_path =\"./C57BL6J-638850-imputed-log2.h5ad\" ####### download from the Allen institute the imputed MERFISH dataset\n",
    "adata = anndata.read_h5ad(imputed_h5ad_path, backed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc17938-bbfd-4645-a8a0-59ba15dee9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042a7f5-e55d-4b1a-af96-be60b2b87fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35f80d-600e-4a6c-92ab-f710c0d63b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var['gene_symbol'].to_csv(\"genes_implist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e775624c-3ccf-4f2c-81d4-abb7ed31bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.var['gene_symbol'][adata.var['gene_symbol'] == \"Mbp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2d57da-d535-4cf3-b91b-1c3bb7008e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "merfish = pd.read_parquet(\"./zenodo/multimodal/cell_filtered_w500genes.parquet\") # just basic preprocessing of the Allen MERFISH coronal atlas\n",
    "datavignettes = pd.read_parquet(\"./zenodo/maindata_2.parquet\")\n",
    "lipidsinallen = datavignettes[['xccf','yccf','zccf']].dropna()\n",
    "merfishinallen = merfish[['x_ccf', 'y_ccf', 'z_ccf']]\n",
    "merfishinallen.columns = ['xccf','yccf','zccf']\n",
    "merfishinallen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c448dfc-94cd-480f-abfb-9068ea0632d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = 'xccf'\n",
    "print(merfishinallen[xx].max())\n",
    "print(lipidsinallen[xx].max())\n",
    "\n",
    "xx = 'yccf'\n",
    "print(merfishinallen[xx].max())\n",
    "print(lipidsinallen[xx].max())\n",
    "\n",
    "xx = 'zccf'\n",
    "print(merfishinallen[xx].max())\n",
    "print(lipidsinallen[xx].max()) # perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a1c1f-b2f6-41ba-bba2-f585892b8a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcf30e14-99d2-4d9d-b305-dc10ef4e2de5",
   "metadata": {},
   "source": [
    "## Match the two datasets by constrained neighbor search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e57be7-90bd-418b-a19d-c857a4af32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache\n",
    "mcc = MouseConnectivityCache(manifest_file='mouse_connectivity_manifest.json')\n",
    "annotation, _ = mcc.get_annotation_volume()\n",
    "merfish['x_index'] = (merfish['x_ccf']*40).astype(int)\n",
    "merfish['y_index'] = (merfish['y_ccf']*40).astype(int)\n",
    "merfish['z_index'] = (merfish['z_ccf']*40).astype(int)\n",
    "merfish['id'] = annotation[merfish['x_index'], merfish['y_index'], merfish['z_index']]\n",
    "merfish['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23bae31-ad69-417e-a399-d12ec129b8ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datavignettes = datavignettes.dropna(subset=['id'])\n",
    "datavignettes['id'] = datavignettes['id'].astype(int).astype(str)\n",
    "merfish['id'] = merfish['id'].astype(str)\n",
    "merfishinallen['id'] = merfish['id'].values\n",
    "#drop vascular and immune cells first...\n",
    "merfishinallen['division'] = merfish['division'].values\n",
    "merfishinallen = merfishinallen.loc[~merfishinallen['division'].isin(['6 Vascular', '7 Immune']),:]\n",
    "datavignettes =datavignettes.dropna(subset=['xccf'])\n",
    "datavignettess = datavignettes.copy().loc[datavignettes['SectionID'].isin([76.,  82., 106.,   2., 131.,  88.,  63., 112.,  60.,  62., 118.,\n",
    "     21.,  45., 123.,  58., 100.,  83.,  61.,  59.,  98.,  28.,  19.,\n",
    "     43.,  18., 107.,  29., 104., 124.,  52., 129.,  14.,  78.,  15.,\n",
    "     65.,  89.,  41., 117., 111.,  68.,  70., 125.,  92.,  16., 122.,\n",
    "    114.,  91.,  11.,  24.,  71.,  46.,  57., 120.,  75.]),:]# focus on preselected good sections...\n",
    "\n",
    "datavignettess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7629fc0a-a231-4727-984a-68037f3d026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import cKDTree\n",
    "from threadpoolctl import threadpool_limits, threadpool_info\n",
    "threadpool_limits(limits=8)\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "\n",
    "# 1) pre-group merfish and build trees - just a fast precomputation here!\n",
    "\n",
    "trees = {}\n",
    "feats = {}\n",
    "\n",
    "for id_, sub in tqdm(merfish.groupby('id')): \n",
    "    coords = sub[['x_ccf','y_ccf','z_ccf']].to_numpy()\n",
    "    trees[id_] = cKDTree(coords)\n",
    "    valid_idx = sub.index[sub.index.isin(adata.obs_names)]\n",
    "    feats[id_] = np.asarray(adata[valid_idx, :].X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3677eef-32f2-426b-9ec5-d2523944e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.075\n",
    "idxs = []\n",
    "means = []\n",
    "\n",
    "for iiii in tqdm(datavignettess['SectionID'].unique()): ### reduced to 53 sensible sections\n",
    "    datavignettes = datavignettess.loc[datavignettess['SectionID'] == iiii,:]\n",
    "\n",
    "    for id_, dsub in datavignettes.groupby('id'):\n",
    "        tree = trees.get(id_)\n",
    "        if tree is None:\n",
    "            continue\n",
    "        qpts = dsub[['xccf','yccf','zccf']].to_numpy()\n",
    "        nbrs_list = tree.query_ball_point(qpts, r=thr)\n",
    "        arr = feats[id_]\n",
    "        for i, nbrs in enumerate(nbrs_list):\n",
    "            if nbrs:\n",
    "                idxs.append(dsub.index[i])\n",
    "                means.append(arr[nbrs].mean(axis=0))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183dc98e-c83f-4f00-b710-e646797bb19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('means.pkl', 'wb') as f:\n",
    "    pickle.dump(means, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4d67c8-38b8-4fbb-b8b5-5aecd77d96e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(np.array(means), index=idxs, columns=adata.var['gene_symbol'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca29eaf3-d7a8-4640-9609-8045646613c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threadpoolctl import threadpool_limits, threadpool_info\n",
    "threadpool_limits(limits=8)\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "\n",
    "result.to_parquet(\"spatialgoodgexpr_WHOLETRANSCRIPTOME.parquet\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e341a71b-2320-4f9a-a57e-8c936c4e5bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datavignettes = datavignettess\n",
    "datavignettes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0c80d8-c036-416d-afe1-bc621c82ac03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result['SectionID'] = datavignettes.loc[result.index,'SectionID']\n",
    "result['xccf'] = datavignettes.loc[result.index,'xccf']\n",
    "result['yccf'] = datavignettes.loc[result.index,'yccf']\n",
    "result['zccf'] = datavignettes.loc[result.index,'zccf']\n",
    "result['boundary'] = datavignettes.loc[result.index,'boundary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f25f5-bf24-4731-b3b5-3e1a2bf88012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc831572-5257-4227-a83c-008eb695c3db",
   "metadata": {},
   "source": [
    "## Check imputation quality visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83596ac1-8109-4be7-b07c-2c112e7e2c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r = result\n",
    "sections_top10_fast = r['xccf'].groupby(r['SectionID']).mean().sort_values()[::5].index # equispace rostrocaudally manually good sections...\n",
    "sections_top10_fast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for xxx in sections_top10_fast:\n",
    "    mer = result.loc[result['SectionID'] == xxx,:]\n",
    "\n",
    "    cont = mer.loc[mer['boundary'] == 1,:]\n",
    "\n",
    "    plt.scatter(mer['zccf'], -mer['yccf'], c=mer['ENSMUSG00000041607'], cmap=\"Reds\", s=0.1, rasterized=True)\n",
    "    plt.scatter(cont['zccf'], -cont['yccf'],\n",
    "                     c='black', s=0.01, alpha=1.0, rasterized=True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc950a-648e-45b2-8863-b1ca48f5a864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "559087c1-2408-4d5f-a3a9-ccddebede717",
   "metadata": {},
   "source": [
    "## Train genes to lipids XGBoost models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0cff0e-5dc2-4b67-aaa2-67212d6ce32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import anndata\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial import cKDTree\n",
    "from threadpoolctl import threadpool_limits, threadpool_info\n",
    "threadpool_limits(limits=8)\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "\n",
    "datavignettes = pd.read_parquet(\"./zenodo/maindata_2.parquet\")\n",
    "result = pd.read_parquet(\"spatialgoodgexpr_WHOLETRANSCRIPTOME.parquet\") # computed just above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e99ad-5b83-40cc-ba58-76446de29757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- DATA SETUP ----\n",
    "genes        = result.iloc[:,:8460]                    \n",
    "lipids       = datavignettes.loc[genes.index, :].iloc[:, :173]\n",
    "lipids2learn = datavignettes.columns[:173]\n",
    "sids         = datavignettes.loc[genes.index, 'SectionID']\n",
    "\n",
    "# ---- HYPERPARAM GRID ----\n",
    "param_dist = {\n",
    "    \"n_estimators\":  [300],\n",
    "    \"learning_rate\": [0.05],\n",
    "    \"max_depth\":     [6],\n",
    "    \"subsample\":     [0.6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c88489-9842-4aa8-b31e-11408531a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample for feasibility\n",
    "sections = sids.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e2bf0-079c-4f23-990d-cdfa23a872a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanccf = datavignettes.loc[genes.index, 'xccf'].groupby(datavignettes.loc[genes.index, 'SectionID']).mean().sort_values()\n",
    "meanccf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7169a8f3-bac3-4848-aa8c-8771b54b6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_to_train_on = meanccf.loc[meanccf.index < 110][::4].index.values # remove pregnancy as well, it's a condition\n",
    "len(sections_to_train_on) # i'll start small from only 11 sections..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68bbf03-8f01-4106-8b52-9d7ae0a96c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "sids         = sids.loc[sids.isin(sections_to_train_on)]\n",
    "genes        = genes.loc[sids.index,:]                     \n",
    "lipids       = lipids.loc[sids.index,:] \n",
    "lipids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e680674c-b786-40d2-b585-88f4c5b9ff9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, ParameterSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from joblib import dump\n",
    "from threadpoolctl import threadpool_limits\n",
    "\n",
    "# limit threads for reproducibility\n",
    "threadpool_limits(limits=8)\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "\n",
    "n_iter     = 1\n",
    "param_list = list(ParameterSampler(param_dist, n_iter=n_iter, random_state=42))\n",
    "\n",
    "def pearson_scorer(y_true, y_pred):\n",
    "    if np.std(y_true) == 0 or np.std(y_pred) == 0:\n",
    "        return 0.0\n",
    "    return pearsonr(y_true, y_pred)[0]\n",
    "\n",
    "def process_lipid(lipid):\n",
    "    X = genes\n",
    "    y = lipids[lipid]\n",
    "\n",
    "    X_tmp, X_test,  y_tmp,  y_test  = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val,  y_train, y_val  = train_test_split(X_tmp, y_tmp, test_size=0.25, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_tr_s = scaler.transform(X_train).astype(np.float32)\n",
    "    X_val_s = scaler.transform(X_val).astype(np.float32)\n",
    "    X_te_s  = scaler.transform(X_test).astype(np.float32)\n",
    "\n",
    "    print(\"alive\")\n",
    "    \n",
    "    records = []\n",
    "    best_model = None\n",
    "    best_score = -np.inf\n",
    "\n",
    "    for params in param_list:\n",
    "        model = xgb.XGBRegressor(\n",
    "            tree_method='hist',\n",
    "            grow_policy='lossguide',\n",
    "            n_jobs=2,\n",
    "            random_state=42,\n",
    "            **params\n",
    "        )\n",
    "\n",
    "        model.fit(\n",
    "            X_tr_s, y_train,\n",
    "            eval_set=[(X_val_s, y_val)],\n",
    "            early_stopping_rounds=10,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        y_pred = model.predict(X_te_s)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r   = pearson_scorer(y_test, y_pred)\n",
    "        records.append({**params, 'Test_MSE': mse, 'Test_R': r})\n",
    "\n",
    "        if r > best_score:\n",
    "            best_score = r\n",
    "            best_model = model\n",
    "\n",
    "    results_df = pd.DataFrame(records)\n",
    "    res_fname = f\"{lipid.replace(' ','_').replace('/','_')}_xgb_results.csv\"\n",
    "    results_df.to_csv(res_fname, index=False)\n",
    "\n",
    "    model_fname = f\"{lipid.replace(' ','_').replace('/','_')}_xgb_model.joblib\"\n",
    "    dump(best_model, model_fname)\n",
    "\n",
    "    explainer = shap.TreeExplainer(best_model)\n",
    "    shap_vals = explainer.shap_values(X_te_s)\n",
    "    df_shap = pd.DataFrame(shap_vals, columns=X.columns)\n",
    "    shap_fname = f\"{lipid.replace(' ','_').replace('/','_')}_xgb_shap_values.parquet\" \n",
    "    df_shap.to_parquet(shap_fname)\n",
    "\n",
    "    return lipid, results_df\n",
    "\n",
    "\n",
    "lipids_subset = lipids2learn[1:] \n",
    "results_by_lipid = {}\n",
    "for lip in tqdm(lipids_subset):\n",
    "    lipid_name, df = process_lipid(lip)\n",
    "    results_by_lipid[lipid_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd467913-ed4e-401f-b80a-74f570edc92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "587fd6f7-8da5-4848-998d-cb5a567771e1",
   "metadata": {},
   "source": [
    "## Extract the best cell type markers from the imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b3b157-ab75-40ad-8593-2829d493fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_types = merfish['labels_supertype']\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "def compute_enrichment_scores(adata, cell_types: pd.Series,\n",
    "                              alpha: float = 1.0, beta: float = 1.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute E(i,g) = (mean_i_g / mean_g)^alpha * (freq_i_g / freq_g)^beta\n",
    "    \"\"\"\n",
    "    ct = cell_types.reindex(adata.obs_names).dropna()\n",
    "    ad = adata[ct.index]  \n",
    "    \n",
    "    X = ad.X  \n",
    "    n_cells, n_genes = X.shape\n",
    "    types = ct.unique()\n",
    "    \n",
    "    if sparse.issparse(X):\n",
    "        mean_g = np.ravel(X.mean(axis=0))\n",
    "        freq_g = np.ravel(X.astype(bool).sum(axis=0)) / n_cells\n",
    "    else:\n",
    "        mean_g = X.mean(axis=0)\n",
    "        freq_g = (X > 0).sum(axis=0) / n_cells\n",
    "    \n",
    "    enrich = np.zeros((types.size, n_genes), dtype=float)\n",
    "    for i, t in enumerate(types):\n",
    "        mask = (ct == t).values\n",
    "        Xi = X[mask]\n",
    "        ni = mask.sum()\n",
    "        if sparse.issparse(Xi):\n",
    "            mean_i = np.ravel(Xi.mean(axis=0))\n",
    "            freq_i = np.ravel(Xi.astype(bool).sum(axis=0)) / ni\n",
    "        else:\n",
    "            mean_i = Xi.mean(axis=0)\n",
    "            freq_i = (Xi > 0).sum(axis=0) / ni\n",
    "        \n",
    "        enrich[i, :] = (mean_i/mean_g)**alpha * (freq_i/freq_g)**beta\n",
    "    \n",
    "    return pd.DataFrame(enrich, index=types, columns=adata.var_names)\n",
    "\n",
    "def rank_genes_by_max_enrichment(enrich_df: pd.DataFrame, top_n: int = 20) -> pd.Series:\n",
    "    \"\"\"Take each gene’s max across types and return the top_n.\"\"\"\n",
    "    return enrich_df.max(axis=0).nlargest(top_n)\n",
    "\n",
    "def assign_genes_to_cell_types(enrich_df: pd.DataFrame,\n",
    "                               threshold: float, top_x: int = 20) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each gene, pick the type with highest E; if E>=threshold, assign it.\n",
    "    Then report the top_x per cell type.\n",
    "    \"\"\"\n",
    "    best_score = enrich_df.max(axis=0)\n",
    "    best_type  = enrich_df.idxmax(axis=0)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'gene':        enrich_df.columns,\n",
    "        'cell_type':   best_type.values,\n",
    "        'enrichment':  best_score.values\n",
    "    })\n",
    "    df = df[df.enrichment >= threshold]\n",
    "    \n",
    "    return (df\n",
    "            .sort_values(['cell_type','enrichment'], ascending=[True,False])\n",
    "            .groupby('cell_type')\n",
    "            .head(top_x)\n",
    "            .reset_index(drop=True))\n",
    "\n",
    "enrichment_scores = compute_enrichment_scores(adata, cell_types)\n",
    "detect = merfish[['labels_supertype', 'labels_division']].drop_duplicates()\n",
    "badtypes = detect.loc[detect['labels_division'].isin(['6 Vascular', '7 Immune']), 'labels_supertype'] \n",
    "enrichment_scores = enrichment_scores.drop(badtypes)\n",
    "enrichment_scores.to_parquet(\"enrichment_scores_full_transcriptome.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1fa77e-1dcc-440a-a081-744b3df22499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f2b6e-3340-4b3c-b49d-7118963ab331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "B = 2000          \n",
    "threshold = 1e-6   \n",
    "N = 20            \n",
    "enrichment_scores =enrichment_scores.loc[enrichment_scores.index.isin(cell_types.value_counts().sort_values().index[cell_types.value_counts().sort_values() > 150]),:]\n",
    "\n",
    "common_genes = region_matrix.columns.intersection(genemarkerish.index)\n",
    "if len(common_genes) < len(region_matrix.columns):\n",
    "    print(f\"Warning: Dropping {len(region_matrix.columns) - len(common_genes)} genes \"\n",
    "          f\"from region_matrix that are not in genemarkerish.\")\n",
    "if len(common_genes) < len(genemarkerish.index):\n",
    "    print(f\"Warning: Dropping {len(genemarkerish.index) - len(common_genes)} genes \"\n",
    "          f\"from genemarkerish that are not in region_matrix.\")\n",
    "\n",
    "region_matrix = region_matrix.loc[:, common_genes]\n",
    "genemarkerish = genemarkerish.loc[common_genes]\n",
    "\n",
    "\n",
    "marker_ranks = genemarkerish.rank(method=\"average\", ascending=True)\n",
    "marker_ranks = 8460 - marker_ranks \n",
    "all_genes = list(common_genes)\n",
    "gene2idx = { g: i for i, g in enumerate(all_genes) }\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "G = 8460       # total number of genes\n",
    "B = 2000       # bootstraps\n",
    "N = 20         # draw size per bootstrap\n",
    "\n",
    "rng = np.random.default_rng(seed=0)\n",
    "samples = np.empty((B, N), dtype=int)\n",
    "\n",
    "for b in range(B):\n",
    "    samples[b, :] = rng.choice(G, size=N, replace=False)\n",
    "\n",
    "null_means_N20 = marker_ranks_array[samples].mean(axis=1)\n",
    "null_means_N20.sort()\n",
    "\n",
    "import pickle\n",
    "\n",
    "filename = \"all_shap_norms_controlling_outliers.pkl\"\n",
    "\n",
    "with open(filename, \"rb\") as f:\n",
    "    all_shap_norms = pickle.load(f)\n",
    "\n",
    "region_matrices = all_shap_norms\n",
    "\n",
    "lipid_names = np.load(\"lipids4xgbimpo.npy\")\n",
    "lipid_names\n",
    "\n",
    "records = []\n",
    "for lipid_name, region_matrix in tqdm(zip(lipid_names, region_matrices)):\n",
    "    \n",
    "    for region in region_matrix.index:  \n",
    "        row = region_matrix.loc[region] \n",
    "        \n",
    "        filtered = row[row >= threshold]\n",
    "        if len(filtered) < N:\n",
    "            continue\n",
    "\n",
    "        top20 = filtered.nlargest(N).index.tolist() \n",
    "        top20_idx = [gene2idx[g] for g in top20]\n",
    "        \n",
    "        T_obs = marker_ranks_array[top20_idx].mean()\n",
    "\n",
    "        # empirical p: fraction of null_means_N20 <= T_obs\n",
    "        pos = np.searchsorted(null_means_N20, T_obs, side=\"right\")\n",
    "        p_emp = (pos + 1) / (B + 1)\n",
    "\n",
    "        records.append({\n",
    "            \"lipid\":       lipid_name,\n",
    "            \"region\":      region,\n",
    "            \"T_obs\":       T_obs,\n",
    "            \"p_value_raw\": p_emp,\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame.from_records(records)\n",
    "\n",
    "reject, p_adj, _, _ = multipletests(results_df[\"p_value_raw\"].values,\n",
    "                                    alpha=0.05, method=\"fdr_bh\")\n",
    "results_df[\"p_value_fdr\"] = p_adj\n",
    "results_df[\"significant_FDR05\"] = reject\n",
    "\n",
    "num_tests = len(results_df)\n",
    "num_sig   = results_df[\"significant_FDR05\"].sum()\n",
    "frac_sig  = 100.0 * num_sig / num_tests\n",
    "print(f\"{num_sig} / {num_tests} = {frac_sig:.1f}% of region‐lipid pairs are marker‐enriched at FDR<0.05.\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "plt.hist(results_df['p_value_fdr'], bins=100, color=\"gray\")\n",
    "\n",
    "plt.axvline(x=0.05, color='red', linestyle='--', linewidth=2, label='FDR = 0.05')\n",
    "\n",
    "plt.xlim(0, 0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"pvalues_xgb_shap_celltypemarkers.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a2bd0-2e75-4001-a330-1340fe1bdd0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026365a6-a672-48ca-b545-5cbeeb200371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
