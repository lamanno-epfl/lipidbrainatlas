{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ad3ec6-29fd-4355-887d-ad1a72a62e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "merfish = pd.read_parquet(\"./zenodo/multimodal/cell_filtered_w500genes.parquet\") # just basic preprocessing of the Allen MERFISH coronal atlas\n",
    "datavignettes = pd.read_parquet(\"./zenodo/maindata_2.parquet\")\n",
    "lipidsinallen = datavignettes[['xccf','yccf','zccf']].dropna()\n",
    "merfishinallen = merfish[['x_ccf', 'y_ccf', 'z_ccf']]\n",
    "merfishinallen.columns = ['xccf','yccf','zccf']\n",
    "merfishinallen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcab5cf-a3d3-461e-9e47-9a79e44b86cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c448dfc-94cd-480f-abfb-9068ea0632d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = 'xccf'\n",
    "print(merfishinallen[xx].max())\n",
    "print(lipidsinallen[xx].max())\n",
    "\n",
    "xx = 'yccf'\n",
    "print(merfishinallen[xx].max())\n",
    "print(lipidsinallen[xx].max())\n",
    "\n",
    "xx = 'zccf'\n",
    "print(merfishinallen[xx].max())\n",
    "print(lipidsinallen[xx].max()) # perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a1c1f-b2f6-41ba-bba2-f585892b8a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcf30e14-99d2-4d9d-b305-dc10ef4e2de5",
   "metadata": {},
   "source": [
    "## Match the two datasets by constrained neighbor search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e57be7-90bd-418b-a19d-c857a4af32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from allensdk.core.mouse_connectivity_cache import MouseConnectivityCache\n",
    "mcc = MouseConnectivityCache(manifest_file='mouse_connectivity_manifest.json')\n",
    "annotation, _ = mcc.get_annotation_volume()\n",
    "merfish['x_index'] = (merfish['x_ccf']*40).astype(int)\n",
    "merfish['y_index'] = (merfish['y_ccf']*40).astype(int)\n",
    "merfish['z_index'] = (merfish['z_ccf']*40).astype(int)\n",
    "merfish['id'] = annotation[merfish['x_index'], merfish['y_index'], merfish['z_index']]\n",
    "merfish['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23bae31-ad69-417e-a399-d12ec129b8ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datavignettes = datavignettes.dropna(subset=['id'])\n",
    "datavignettes['id'] = datavignettes['id'].astype(int).astype(str)\n",
    "merfish['id'] = merfish['id'].astype(str)\n",
    "merfishinallen['id'] = merfish['id'].values\n",
    "#drop vascular and immune cells first...\n",
    "merfishinallen['division'] = merfish['division'].values\n",
    "merfishinallen = merfishinallen.loc[~merfishinallen['division'].isin(['6 Vascular', '7 Immune']),:]\n",
    "datavignettes =datavignettes.dropna(subset=['xccf'])\n",
    "datavignettess = datavignettes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b70de3-92f4-4e11-93b9-db293e951bb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import cKDTree\n",
    "from threadpoolctl import threadpool_limits, threadpool_info\n",
    "threadpool_limits(limits=8)\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "\n",
    "# 1) pre-group merfish and build trees\n",
    "trees = {}\n",
    "feats = {}\n",
    "for id_, sub in merfish.groupby('id'): # this is a priori done for all sections once\n",
    "    coords = sub[['x_ccf','y_ccf','z_ccf']].to_numpy()\n",
    "    trees[id_] = cKDTree(coords)\n",
    "    feats[id_] = sub.iloc[:, -554:-55].to_numpy()\n",
    "    \n",
    "from tqdm import tqdm\n",
    "\n",
    "thr = 0.075\n",
    "idxs = []\n",
    "means = []\n",
    "\n",
    "for iiii in tqdm(datavignettess['SectionID'].unique()):\n",
    "    datavignettes = datavignettess.loc[datavignettess['SectionID'] == iiii,:]\n",
    "\n",
    "    for id_, dsub in datavignettes.groupby('id'):\n",
    "        tree = trees.get(id_)\n",
    "        if tree is None:\n",
    "            continue\n",
    "        qpts = dsub[['xccf','yccf','zccf']].to_numpy()\n",
    "        nbrs_list = tree.query_ball_point(qpts, r=thr)\n",
    "        arr = feats[id_]\n",
    "        for i, nbrs in enumerate(nbrs_list):\n",
    "            if nbrs:\n",
    "                idxs.append(dsub.index[i])\n",
    "                means.append(arr[nbrs].mean(axis=0))\n",
    "\n",
    "                datavignettes = datavignettess                \n",
    "result = pd.DataFrame(np.array(means), index=idxs, columns=sub.iloc[:, -554:-55].columns)\n",
    "result['SectionID'] = datavignettes.loc[result.index,'SectionID']\n",
    "result['xccf'] = datavignettes.loc[result.index,'xccf']\n",
    "result['yccf'] = datavignettes.loc[result.index,'yccf']\n",
    "result['zccf'] = datavignettes.loc[result.index,'zccf']\n",
    "result['boundary'] = datavignettes.loc[result.index,'boundary']\n",
    "result.to_parquet(\"spatialgoodgexpr.parquet\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8a6b27-7a87-496d-bdd7-a4a0c9903e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc831572-5257-4227-a83c-008eb695c3db",
   "metadata": {},
   "source": [
    "## Check imputation quality visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83596ac1-8109-4be7-b07c-2c112e7e2c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r = result.loc[result['SectionID'].isin([76.,  82., 106.,   2., 131.,  88.,  63., 112.,  60.,  62., 118.,\n",
    "     21.,  45., 123.,  58., 100.,  83.,  61.,  59.,  98.,  28.,  19.,\n",
    "     43.,  18., 107.,  29., 104., 124.,  52., 129.,  14.,  78.,  15.,\n",
    "     65.,  89.,  41., 117., 111.,  68.,  70., 125.,  92.,  16., 122.,\n",
    "    114.,  91.,  11.,  24.,  71.,  46.,  57., 120.,  75.]),:]\n",
    "\n",
    "sections_top10_fast = r['xccf'].groupby(r['SectionID']).mean().sort_values()[::5].index # equispace rostrocaudally manually good sections...\n",
    "sections_top10_fast\n",
    "\n",
    "# i wanna keep\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for xxx in sections_top10_fast:\n",
    "    mer = result.loc[result['SectionID'] == xxx,:]\n",
    "\n",
    "    cont = mer.loc[mer['boundary'] == 1,:]\n",
    "\n",
    "    plt.scatter(mer['zccf'], -mer['yccf'], c=mer['ENSMUST00000102665'], cmap=\"Reds\", s=0.1, rasterized=True)\n",
    "    plt.scatter(cont['zccf'], -cont['yccf'],\n",
    "                     c='black', s=0.01, alpha=1.0, rasterized=True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc950a-648e-45b2-8863-b1ca48f5a864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "559087c1-2408-4d5f-a3a9-ccddebede717",
   "metadata": {},
   "source": [
    "## Train genes to lipids XGBoost models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e849bc7-f44b-4c35-adfe-7c2074427034",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "genes = result.iloc[:,:499]\n",
    "lipids = datavignettes.loc[genes.index,:].iloc[:,:173]\n",
    "sids = datavignettes.loc[genes.index,'SectionID']\n",
    "lipids2learn = datavignettes.columns[:173]\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, ParameterSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import xgboost as xgb\n",
    "\n",
    "from threadpoolctl import threadpool_limits\n",
    "threadpool_limits(limits=8)\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "\n",
    "# ---- SECTIONS TO LOOP OVER ----\n",
    "sections_to_use = np.array([41.0, 91.0, 11.0, 104.0, 58.0, 60.0, 88.0, 76.0, 65.0, 83.0, 78.0])\n",
    "\n",
    "# ---- SCORER FOR PEARSON R ----\n",
    "def pearson_scorer(y_true, y_pred):\n",
    "    if np.std(y_true) == 0 or np.std(y_pred) == 0:\n",
    "        return 0.0\n",
    "    return pearsonr(y_true, y_pred)[0]\n",
    "\n",
    "# ---- HYPERPARAM DISTRIBUTION & SAMPLER ----\n",
    "param_dist = {\n",
    "    \"n_estimators\":  [300],\n",
    "    \"learning_rate\": [0.05],\n",
    "    \"max_depth\":     [6],\n",
    "    \"subsample\":     [0.6]\n",
    "}\n",
    "n_iter     = 1\n",
    "param_list = list(ParameterSampler(param_dist, n_iter=n_iter, random_state=42))\n",
    "\n",
    "results_by_lipid = {}\n",
    "\n",
    "for lipid in tqdm(lipids2learn, desc=\"Lipids (XGB Single Split)\"):\n",
    "    records = []\n",
    "\n",
    "    for sect in tqdm(sections_to_use, desc=f\"  Sections for {lipid}\", leave=False):\n",
    "        # select only this section\n",
    "        idx   = sids[sids == sect].index\n",
    "        X_sec = genes.loc[idx]\n",
    "        y_sec = lipids.loc[idx, lipid]\n",
    "\n",
    "        # train/test split per-section\n",
    "        X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "            X_sec, y_sec, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # fit scaler & PCA on TRAIN, apply to TRAIN & TEST\n",
    "        scaler = StandardScaler().fit(X_tr)\n",
    "        X_tr_s = scaler.transform(X_tr)\n",
    "        X_te_s = scaler.transform(X_te)\n",
    "\n",
    "        pca = PCA(n_components=0.95, random_state=42).fit(X_tr_s)\n",
    "        X_tr_p = pca.transform(X_tr_s)\n",
    "        X_te_p = pca.transform(X_te_s)\n",
    "\n",
    "        # evaluate each parameter set on TRAIN→TEST\n",
    "        for params in param_list:\n",
    "            model = xgb.XGBRegressor(\n",
    "                objective='reg:squarederror',\n",
    "                n_jobs=4,\n",
    "                random_state=42,\n",
    "                **params\n",
    "            )\n",
    "            model.fit(X_tr_p, y_tr)\n",
    "            y_te_pred = model.predict(X_te_p)\n",
    "\n",
    "            rec = params.copy()\n",
    "            rec.update({\n",
    "                'Section':  sect,\n",
    "                'Test_MSE': mean_squared_error(y_te, y_te_pred),\n",
    "                'Test_R':   pearson_scorer(y_te, y_te_pred)\n",
    "            })\n",
    "            records.append(rec)\n",
    "\n",
    "    # aggregate & save\n",
    "    results_df = pd.DataFrame(records)\n",
    "    fname = f\"{lipid.replace(' ', '_').replace('/', '_')}_xgb_no_cv_results.csv\"\n",
    "    results_df.to_csv(fname, index=False)\n",
    "    results_by_lipid[lipid] = results_df\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from threadpoolctl import threadpool_limits, threadpool_info\n",
    "threadpool_limits(limits=8)\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "\n",
    "pattern = '_xgb_no_cv_results.csv'\n",
    "files = [\n",
    "    f \n",
    "    for f in os.listdir('.') \n",
    "    if f.endswith(pattern) and 'l2l' not in f\n",
    "]\n",
    "\n",
    "lipid_dfs = {\n",
    "    f.replace(pattern, ''): pd.read_csv(f)\n",
    "    for f in files\n",
    "}\n",
    "\n",
    "testr = [lipid_dfs[xxx]['Test_R'].mean() for xxx in list(lipid_dfs.keys())]\n",
    "testmse = [lipid_dfs[xxx]['Test_MSE'].mean() for xxx in list(lipid_dfs.keys())]\n",
    "\n",
    "performance_gene2lipideasy = pd.DataFrame([testr, testmse], index = [\"test R\", \"test MSE\"], columns = list(lipid_dfs.keys())).T\n",
    "performance_gene2lipideasy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd467913-ed4e-401f-b80a-74f570edc92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a30b7d32-80ed-47b5-92eb-3bcd6f5abf4f",
   "metadata": {},
   "source": [
    "## As a baseline to estimate the irreducible noise, also train lipid to lipid XGBoost models on the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a4f03-f52f-4595-880e-7620b956c981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, ParameterSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import xgboost as xgb\n",
    "\n",
    "from threadpoolctl import threadpool_limits\n",
    "threadpool_limits(limits=8)\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "\n",
    "# ---- SECTIONS TO LOOP OVER ----\n",
    "sections_to_use = np.array([41.0, 91.0, 11.0, 104.0, 58.0, 60.0, 88.0, 76.0, 65.0, 83.0, 78.0])\n",
    "\n",
    "# ---- SCORER FOR PEARSON R ----\n",
    "def pearson_scorer(y_true, y_pred):\n",
    "    if np.std(y_true) == 0 or np.std(y_pred) == 0:\n",
    "        return 0.0\n",
    "    return pearsonr(y_true, y_pred)[0]\n",
    "\n",
    "# ---- HYPERPARAM DISTRIBUTION & SAMPLER ----\n",
    "param_dist = {\n",
    "    \"n_estimators\":  [300],\n",
    "    \"learning_rate\": [0.05],\n",
    "    \"max_depth\":     [6],\n",
    "    \"subsample\":     [0.6]\n",
    "}\n",
    "n_iter     = 1\n",
    "param_list = list(ParameterSampler(param_dist, n_iter=n_iter, random_state=42))\n",
    "\n",
    "results_by_lipid = {}\n",
    "\n",
    "def pearson_scorer(y_true, y_pred):\n",
    "    return np.corrcoef(y_true, y_pred)[0, 1]\n",
    "\n",
    "results_by_lipid = {}\n",
    "all_lipids = lipids.columns.values\n",
    "\n",
    "targets = np.setdiff1d(all_lipids, np.array(list(results_by_lipid.keys())))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from threadpoolctl import threadpool_limits\n",
    "threadpool_limits(limits=8)\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "\n",
    "for lipid in tqdm(targets, desc=\"Lipids (XGB Single Split)\"):\n",
    "    records = []\n",
    "\n",
    "    # Define predictors: all lipids except the current target\n",
    "    predictors = [l for l in all_lipids if l != lipid]\n",
    "\n",
    "    for sect in tqdm(sections_to_use, desc=f\"  Sections for {lipid}\", leave=False):\n",
    "        idx = sids[sids == sect].index\n",
    "\n",
    "        # Select predictor and target data for this section\n",
    "        X_sec = lipids.loc[idx, predictors]\n",
    "        y_sec = lipids.loc[idx, lipid]\n",
    "\n",
    "        # train/test split per-section\n",
    "        X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "            X_sec, y_sec, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # Standardize then PCA on training data\n",
    "        scaler = StandardScaler().fit(X_tr)\n",
    "        X_tr_s = scaler.transform(X_tr)\n",
    "        X_te_s = scaler.transform(X_te)\n",
    "\n",
    "        pca = PCA(n_components=0.95, random_state=42).fit(X_tr_s)\n",
    "        X_tr_p = pca.transform(X_tr_s)\n",
    "        X_te_p = pca.transform(X_te_s)\n",
    "\n",
    "        # Evaluate each parameter set\n",
    "        for params in param_list:\n",
    "            model = xgb.XGBRegressor(\n",
    "                objective='reg:squarederror',\n",
    "                n_jobs=4,\n",
    "                random_state=42,\n",
    "                **params\n",
    "            )\n",
    "            model.fit(X_tr_p, y_tr)\n",
    "            y_te_pred = model.predict(X_te_p)\n",
    "\n",
    "            rec = params.copy()\n",
    "            rec.update({\n",
    "                'Section': sect,\n",
    "                'Test_MSE': mean_squared_error(y_te, y_te_pred),\n",
    "                'Test_R': pearson_scorer(y_te, y_te_pred)\n",
    "            })\n",
    "            records.append(rec)\n",
    "\n",
    "    # Aggregate & save\n",
    "    results_df = pd.DataFrame(records)\n",
    "    fname = f\"{lipid.replace(' ', '_').replace('/', '_')}_xgb_no_cv_results_L2L.csv\"\n",
    "    results_df.to_csv(fname, index=False)\n",
    "    results_by_lipid[lipid] = results_df\n",
    "\n",
    "# Save all results\n",
    "with open(\"results_by_lipid_complete_L2L.pkl\", \"wb\") as f:\n",
    "    pickle.dump(results_by_lipid, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from threadpoolctl import threadpool_limits, threadpool_info\n",
    "threadpool_limits(limits=8)\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "\n",
    "pattern = '_xgb_no_cv_results_L2L.csv'\n",
    "files = [\n",
    "    f \n",
    "    for f in os.listdir('.') \n",
    "    if f.endswith(pattern)\n",
    "]\n",
    "\n",
    "lipid_dfs = {\n",
    "    f.replace(pattern, ''): pd.read_csv(f)\n",
    "    for f in files\n",
    "}\n",
    "\n",
    "lipid_dfs\n",
    "\n",
    "testr = [lipid_dfs[xxx]['Test_R'].mean() for xxx in list(lipid_dfs.keys())]\n",
    "testmse = [lipid_dfs[xxx]['Test_MSE'].mean() for xxx in list(lipid_dfs.keys())]\n",
    "len(testr)\n",
    "\n",
    "perf_test = pd.DataFrame([testr, testmse], index = [\"test R\", \"test MSE\"], columns = list(lipid_dfs.keys())).T\n",
    "performance_lipid2lipideasy = perf_test.copy()\n",
    "performance_lipid2lipideasy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2934f68a-de7d-4067-bf74-b83987e5370d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a2ebcd3-d9cf-400e-84f2-bb6e98d221f4",
   "metadata": {},
   "source": [
    "## Compare lipid predictions from genes and from lipids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51902398-5681-41af-a5a4-99f56377c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(performance_lipid2lipideasy['test R'], performance_gene2lipideasy['test R'])\n",
    "plt.show()\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "g2l = performance_gene2lipideasy\n",
    "l2l = performance_lipid2lipideasy\n",
    "data_l2l = l2l['test R'].values\n",
    "data_g2l = g2l['test R'].values\n",
    "\n",
    "pearson_min, pearson_max = -1.0, 1.0\n",
    "bins = np.linspace(pearson_min, pearson_max, 30)\n",
    "purples = plt.cm.Purples(np.linspace(0.3, 0.8, 2))\n",
    "labels  = ['l2l', 'g2l']\n",
    "datasets = [data_l2l, data_g2l]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "for data, label, color in zip(datasets, labels, purples):\n",
    "    plt.hist(data, bins=bins, density=True, alpha=0.4, label=f'{label} hist', color=color)\n",
    "x_grid = np.linspace(pearson_min, pearson_max, 300)\n",
    "for data, label, color in zip(datasets, labels, purples):\n",
    "    kde = gaussian_kde(data)\n",
    "    plt.plot(x_grid, kde(x_grid), color=color, lw=2, label=f'{label} KDE')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.grid(False)\n",
    "\n",
    "plt.xlabel('Test Pearson r')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Density Histograms + KDEs of Test Pearson r')\n",
    "plt.legend(frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"prediction_test_set_SPAT.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfc0f26-24c9-499b-9a67-23c076b9f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "r_l2l = data_l2l\n",
    "r_g2l = data_g2l\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. compute per‐lipid irreducible fraction:\n",
    "#      irreducible_i = 1 - (R_g2l[i]^2) / (R_l2l[i]^2)\n",
    "# -----------------------------------------------------------------------------\n",
    "eps = 1e-8\n",
    "denom = r_l2l**2 + eps\n",
    "var_explained_by_genes = (r_g2l**2) / denom\n",
    "irreducible = 1.0 - var_explained_by_genes\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3. basic summaries\n",
    "# -----------------------------------------------------------------------------\n",
    "mean_irred   = np.mean(irreducible)\n",
    "median_irred = np.median(irreducible)\n",
    "p25, p75     = np.percentile(irreducible, [25, 75])\n",
    "\n",
    "print(f\"Mean irreducible fraction:   {mean_irred:.3f}\")\n",
    "print(f\"Median irreducible fraction: {median_irred:.3f}\")\n",
    "print(f\"25th / 75th percentiles:     {p25:.3f} / {p75:.3f}\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4. bootstrap a 95% CI on the *mean* irreducible fraction\n",
    "# -----------------------------------------------------------------------------\n",
    "def bootstrap_mean_irred(r_l2l, r_g2l, n_boot=5000, seed=0):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    n = len(r_l2l)\n",
    "    boot_means = []\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.choice(n, size=n, replace=True)\n",
    "        denom = r_l2l[idx]**2 + eps\n",
    "        ir = 1.0 - (r_g2l[idx]**2) / denom\n",
    "        boot_means.append(ir.mean())\n",
    "    return np.percentile(boot_means, [2.5, 97.5])\n",
    "\n",
    "ci_lower, ci_upper = bootstrap_mean_irred(r_l2l, r_g2l)\n",
    "print(f\"95% CI on mean irreducible fraction: [{ci_lower:.3f}, {ci_upper:.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3dce3d-0e77-4776-8e9f-6bb956ef9f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b60a553-4789-4626-b3be-a3520fe07bd6",
   "metadata": {},
   "source": [
    "## CCA analysis on metabolic genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026365a6-a672-48ca-b545-5cbeeb200371",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lipids = lipidome.loc[transcriptome.index, :].iloc[:,:173]\n",
    "df_genes = transcriptome.loc[:, transcriptome.columns.isin(metabolic)]\n",
    "df_genes.shape\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from threadpoolctl import threadpool_limits, threadpool_info\n",
    "threadpool_limits(limits=8)\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "\n",
    "scaler_g = StandardScaler()\n",
    "scaler_l = StandardScaler()\n",
    "\n",
    "X = scaler_g.fit_transform(df_genes.values)   \n",
    "Y = scaler_l.fit_transform(df_lipids.values) \n",
    "print(X.shape)\n",
    "\n",
    "n_components = 50 \n",
    "cca = CCA(n_components=n_components, scale=False)  \n",
    "Xc, Yc = cca.fit_transform(X, Y)\n",
    "\n",
    "corrs = np.array([np.corrcoef(Xc[:, k], Yc[:, k])[0,1] \n",
    "                  for k in range(n_components)])\n",
    "shared_var = corrs**2\n",
    "\n",
    "import pickle\n",
    "output = {\n",
    "    'scaler_genes': scaler_g,\n",
    "    'scaler_lipids': scaler_l,\n",
    "    'cca_model': cca,\n",
    "    'Xc': Xc,\n",
    "    'Yc': Yc,\n",
    "    'canonical_correlations': corrs,\n",
    "    'shared_variance': shared_var\n",
    "}\n",
    "\n",
    "with open('cca_results.pkl', 'wb') as f:\n",
    "    pickle.dump(output, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "print(\"All outputs saved to cca_results.pkl\")\n",
    "scaler_g = output['scaler_genes']\n",
    "scaler_l = output['scaler_lipids']\n",
    "cca = output['cca_model']\n",
    "Xc = output['Xc']\n",
    "Yc = output['Yc']\n",
    "corrs = output['canonical_correlations']\n",
    "shared_var = output['shared_variance']\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "n_samples, n_components = Xc.shape\n",
    "p = Y.shape[1]  \n",
    "\n",
    "lipid_loading = np.zeros((p, n_components))  \n",
    "for k in range(n_components):\n",
    "    for j in range(p):\n",
    "        lipid_loading[j, k] = np.corrcoef(Y[:, j], Xc[:, k])[0, 1]\n",
    "\n",
    "lipid_loading_sq = lipid_loading**2  \n",
    "comm_Y = lipid_loading_sq.mean(axis=0)  \n",
    "\n",
    "redundancy = comm_Y * shared_var   \n",
    "cum_redundancy = np.cumsum(redundancy)\n",
    "\n",
    "for k in range(5):   \n",
    "    print(f\"Component {k+1}:\")\n",
    "    print(f\"  • ρ_{k+1}^2 = {shared_var[k]:.4f}\") \n",
    "    print(f\"  •  avg. lipid communality = {comm_Y[k]:.4f}\")\n",
    "    print(f\"  •  redundancy (i.e. lipid‐variance explained by X) = {redundancy[k]:.4f}\")\n",
    "    print(f\"  •  cumulative up to {k+1} = {cum_redundancy[k]:.4f}\")\n",
    "    print(\"\")\n",
    "\n",
    "for k in range(50): \n",
    "    print(f\"Component {k+1}:\")\n",
    "    print(f\"  • ρ_{k+1}^2 = {shared_var[k]:.4f}\") \n",
    "    print(f\"  •  avg. lipid communality = {comm_Y[k]:.4f}\")\n",
    "    print(f\"  •  redundancy (i.e. lipid‐variance explained by X) = {redundancy[k]:.4f}\")\n",
    "    print(f\"  •  cumulative up to {k+1} = {cum_redundancy[k]:.4f}\")\n",
    "    print(\"\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "components = np.arange(1, len(redundancy) + 1)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "ax1.bar(components, redundancy, color='lightgray', alpha=0.8, label='Redundancy per component')\n",
    "ax1.set_xlabel('Canonical Component (k)')\n",
    "ax1.set_ylabel('Redundancy (mean $r^2$)')\n",
    "ax1.tick_params(axis='y')\n",
    "ax1.set_xticks(components)\n",
    "ax1.set_xticklabels(components, rotation=0)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(components, cum_redundancy, color='black', marker='o', linewidth=2, label='Cumulative redundancy')\n",
    "ax2.set_ylabel('Cumulative Redundancy')\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "plt.title('Redundancy‐Scree Plot')\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"ccaresult.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a7cafa-f01d-4014-8efb-aaf4a352ff3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee98421-c76b-4894-8377-1767b4b538a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca4e0c-95b5-4fc6-85eb-fdcbf64dbab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e74085f-e77e-4dd9-8a43-314ff86ffe99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
