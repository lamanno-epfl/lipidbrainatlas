{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fa1e3e-376e-4611-8c47-6e22afadaaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"]       = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"]       = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"]   = \"1\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"]       = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"]       = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"]   = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe3468d-0823-447f-9a6f-6f8cca73e36b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecd97108-22cc-4156-abb6-282bc6275c74",
   "metadata": {},
   "source": [
    "## Import all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74787322-77b4-479b-93d0-0adc4538e79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the lipizone - cell type correspondence data\n",
    "ct=pd.read_csv(\"./zenodo/csv/colocalization_all_levels.csv\", index_col=0)\n",
    "\n",
    "# prepare the lipid brain atlas data, add the merfish neighbors, symmetrize\n",
    "atlas = pd.read_parquet(\"./zenodo/maindata_2.parquet\")\n",
    "for i in range(2, 11):\n",
    "    atlas['level_'+str(i)] = atlas['level_'+str(i-1)].astype(str) + atlas['level_'+str(i)].astype(str)\n",
    "center = 456/2\n",
    "\n",
    "# read in the merfish\n",
    "merfish = pd.read_parquet(\"./zenodo/multimodal/cell_filtered_w500genes.parquet\")\n",
    "merfish = merfish.iloc[:, :-550]\n",
    "\n",
    "# look at the nuclei density in the neighborhoods\n",
    "nuclei = np.load(\"./zenodo/mixed/nucleidensity.npy\")\n",
    "sigma = 2.5\n",
    "nuclei_sm = gaussian_filter(nuclei, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f0de23-6966-49b9-ad2c-714761503319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the connectome data and its binarized version\n",
    "alltests = []\n",
    "for xxx in tqdm(range(30)):\n",
    "    test = pd.read_parquet(\"./zenodo/multimodal/connectomic_datasets/connectome_batch_\"+str(xxx)+\".parquet\")\n",
    "    alltests.append(test)\n",
    "\n",
    "connectome = pd.concat(alltests, axis=1)\n",
    "connectome.index = pd.read_csv(\"./zenodo/csv/index_connectome.csv\", index_col=0)[\"0\"].values\n",
    "connectome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc27790a-d9d7-41c4-b1dc-0da9324896ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "atlas_mid = atlas.loc[atlas['z_index'] < center,:]\n",
    "coords = atlas_mid.loc[atlas_mid.index.isin(connectome.index), ['xccf', 'yccf', 'zccf']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bf0ca1-9edd-40bd-9ec6-6ba9039fdd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "connectome = connectome.loc[coords.index,:]\n",
    "q = 0.95\n",
    "cutoffs = connectome.quantile(q)\n",
    "connectome_binarized = (connectome > 0) & (connectome > cutoffs)\n",
    "\n",
    "atlas = atlas.loc[connectome.index,:]\n",
    "del connectome\n",
    "\n",
    "# prioritize fine-grained lipizones for now to start working on the results\n",
    "ct=pd.read_parquet(\"./zenodo/csv/relaxed_colocalization_all_levels.parquet\")\n",
    "theyrecelltypeterritories = pd.read_csv(\"./zenodo/csv/theyrecelltypeterritories.csv\")\n",
    "\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb67b4f-952d-4058-aff8-89c5adecc2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7830e38-b440-4876-9558-368f48cdf538",
   "metadata": {},
   "source": [
    "## Detection loop at all levels for all lipizones detected at any level as overlapping with cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca453f44-2b24-41cd-9099-ea1ea75b642a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "for iiiii in tqdm(range(ct.shape[0])):#np.random.choice(np.arange(ct.shape[0])[10:],10)):#range(ct.shape[0])[10:]):\n",
    "    \n",
    "    noooow = ct.iloc[iiiii,:]\n",
    "    lipizonenow = ct.index.values[iiiii]\n",
    "    celltypenow = noooow.putative_celltype\n",
    "    levelnow = noooow.label1\n",
    "    levelnow2 = noooow.label2\n",
    "    atlas['putative_celltype'] = atlas[levelnow].map(ct.loc[(ct['label1'] ==levelnow) & (ct['label2'] ==levelnow2), 'putative_celltype']).fillna(\"nocelltype\")\n",
    "    atlas['xlevc'] = atlas[levelnow].map(ct.loc[(ct['label1'] ==levelnow) & (ct['label2'] ==levelnow2), 'label2']).fillna(\"nocelltype\")\n",
    "\n",
    "    lipizone = lipizonenow\n",
    "    \n",
    "    print(lipizone)\n",
    "    \n",
    "    bait = atlas.loc[atlas[levelnow] == lipizonenow,:]\n",
    "    #bait.loc[mask, 'z_index'] = 2*center - bait.loc[mask, 'z_index']\n",
    "    \n",
    "    X = bait[['xccf', 'yccf', 'zccf']].values\n",
    "    pca = PCA(n_components=2, random_state=0)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    bait['PC1'] = X_pca[:, 0]\n",
    "    bait['PC2'] = X_pca[:, 1]\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "    bait['cluster'] = kmeans.fit_predict(X_pca)\n",
    "    bait['clustercolor'] = \"orange\"\n",
    "    bait.loc[bait['cluster'] ==0, 'clustercolor'] = \"yellow\"\n",
    "\n",
    "    # extract the coordinates in space of that same cell type - DIRECTLY FROM THE MERFISH NOT OUR DATA, does it match one of the two spatial clusters?\n",
    "    baited = merfish.loc[merfish[bait['xlevc'].unique()[0]] == bait['putative_celltype'].unique()[0],:]\n",
    "    X_new = baited[['x_ccf', 'y_ccf', 'z_ccf']].values\n",
    "    X_new_pca = pca.transform(X_new)\n",
    "    baited['PC1'] = X_new_pca[:, 0]\n",
    "    baited['PC2'] = X_new_pca[:, 1]\n",
    "    baited['cluster'] = kmeans.predict(X_new_pca)\n",
    "    bait['nucl'] = nuclei_sm[bait['x_index'].astype(int), bait['y_index'].astype(int), bait['z_index'].astype(int)]\n",
    "    baited['nucl'] = nuclei_sm[(baited['x_ccf']*40).astype(int), (baited['y_ccf']*40).astype(int), (baited['z_ccf']*40).astype(int)]\n",
    "    bait['subcell'] = \"soma\"\n",
    "\n",
    "    if np.mean(baited['cluster'] == 0) > 0.8:\n",
    "        bait.loc[bait['cluster'] == 1, 'subcell'] = \"terminal\"\n",
    "    elif np.mean(baited['cluster'] == 0) < 0.2:\n",
    "        bait.loc[bait['cluster'] == 0, 'subcell'] = \"terminal\"\n",
    "    else:\n",
    "        bait['subcell'] = \"no_soma_terminal_detected\"\n",
    "\n",
    "    # assign soma vs nonsoma\n",
    "    mediannuclei_soma = baited['nucl'].median()\n",
    "    mediannuclei_terminals = bait.loc[bait['subcell'] == \"terminal\", 'nucl'].median()\n",
    "    \n",
    "    x0 = connectome_binarized.loc[connectome_binarized.index.isin(bait.loc[bait['cluster'] == 0,:].index),:]\n",
    "    overlap_x0centric = x0.sum().sort_values()[::-1] / len(x0)\n",
    "    candidates_x0 = overlap_x0centric[overlap_x0centric > 0.2].index.values\n",
    "    x1 = connectome_binarized.loc[connectome_binarized.index.isin(bait.loc[bait['cluster'] == 1,:].index),:]\n",
    "    overlap_x1centric = x1.sum().sort_values()[::-1] / len(x1)\n",
    "    candidates_x1 = overlap_x1centric[overlap_x1centric > 0.2].index.values\n",
    "    passthroughboth = np.intersect1d(candidates_x0, candidates_x1) \n",
    "    subdf = connectome_binarized.loc[:, passthroughboth]\n",
    "    for x in subdf.columns:\n",
    "        coordstream = coords.loc[subdf[x].values,:]\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(coordstream.values)\n",
    "        pca = PCA(n_components=1)\n",
    "        t_pca = pca.fit_transform(X_scaled).ravel()\n",
    "        bait[x+\"_pca\"] = pca.transform(bait[['xccf','yccf','zccf']]) \n",
    "\n",
    "    try:\n",
    "        criterion = bait.loc[:, np.array(passthroughboth)+\"_pca\"].groupby(bait[\"subcell\"]).mean()\n",
    "        connectomestream = np.abs(criterion.loc['soma',:] - criterion.loc['terminal',:]).sort_values().index[-1][:-4]\n",
    "        overlap0_val = overlap_x0centric[connectomestream]\n",
    "        overlap1_val = overlap_x1centric[connectomestream]\n",
    "\n",
    "        coordstream = coords.loc[subdf[connectomestream].values,:]\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(coordstream.values)\n",
    "        pca = PCA(n_components=1)\n",
    "        coordstream['t_pca'] = pca.fit_transform(X_scaled).ravel()\n",
    "\n",
    "        unique_sections = atlasss['SectionID'].unique()\n",
    "\n",
    "        lipizonenowRN = lipizonenow.replace(\"/\", \"_\")\n",
    "\n",
    "        toperc = coordstream['t_pca'].values\n",
    "        plow = np.percentile(toperc, 1)\n",
    "        phigh = np.percentile(toperc, 95)\n",
    "\n",
    "        out = {\n",
    "        \"bait\": bait,\n",
    "        \"connectomestream\": connectomestream,\n",
    "        \"mediannuclei_soma\": mediannuclei_soma,\n",
    "        \"mediannuclei_terminals\": mediannuclei_terminals, \n",
    "        \"overlap_x0centric\": overlap0_val,\n",
    "        \"overlap_x1centric\": overlap1_val\n",
    "        }\n",
    "\n",
    "        with open(f\"./lipizone_subcell_go/{lipizonenowRN}\"+str(iiiii)+\".pkl\", \"wb\") as f:\n",
    "            pickle.dump(out, f)\n",
    "\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fef6a60-a82e-41f6-85a3-507d36821226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00bccadd-ee13-47fe-9f98-f518ff195529",
   "metadata": {},
   "source": [
    "## Analyze the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85726e5d-b85b-4884-90fa-a2e8fc3d8174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = {}\n",
    "folder = \"./lipizone_subcell_go\"\n",
    "\n",
    "for fname in tqdm(os.listdir(folder)):\n",
    "    if not fname.endswith(\".pkl\"):\n",
    "        continue\n",
    "    key = os.path.splitext(fname)[0]  \n",
    "    path = os.path.join(folder, fname)\n",
    "    with open(path, \"rb\") as f:\n",
    "        data[key] = pickle.load(f)\n",
    "\n",
    "ct=pd.read_parquet(\"./zenodo/csv/relaxed_colocalization_all_levels.parquet\")\n",
    "theyrecelltypeterritories = pd.read_csv(\"./zenodo/csv/theyrecelltypeterritories.csv\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "allresults = []\n",
    "\n",
    "for NOW, NOW2 in tqdm(zip(ct.index.values, np.arange(ct.shape[0]).astype(str))):\n",
    "    \n",
    "    try:\n",
    "        ctcorr = ct.iloc[int(NOW2),:]\n",
    "        allresults.append((NOW, ctcorr['putative_celltype'],  ctcorr['colocalization'], data[NOW+NOW2]['bait']['subcell'].value_counts()[\"soma\"]/data[NOW+NOW2]['bait'].shape[0],data[NOW+NOW2][\"connectomestream\"], data[NOW+NOW2][\"mediannuclei_soma\"] - data[NOW+NOW2][\"mediannuclei_terminals\"], data[NOW+NOW2][\"overlap_x0centric\"],data[NOW+NOW2][\"overlap_x1centric\"], data[NOW+NOW2]['bait']['subcell'].value_counts()[\"soma\"], data[NOW+NOW2]['bait']['subcell'].value_counts()[\"terminal\"])) \n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "subcellresults = pd.DataFrame(allresults, columns=['lipizone', 'celltype', 'colocalization', 'soma_fraction', 'connectomestream', 'nucleidifference', 'overlap_x0centric', 'overlap_x1centric', 'soma_count', 'terminal_count'])\n",
    "subcellresults['abundance'] = subcellresults['soma_count'] + subcellresults['terminal_count']\n",
    "subcellresults.to_parquet(\"predicted_soma_axon.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1f6330-3efd-48a1-9b1d-60e3763c5624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb0b275d-7e9c-495b-8d7e-941e478af63b",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248276d8-317f-43a6-ae97-d2e6f261ef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ct.loc[ct['label1'] == \"lipizone_names\",:]\n",
    "ct = (\n",
    "    ct\n",
    "    .sort_values('colocalization', ascending=False)\n",
    "    .loc[~ct.index.duplicated(keep='first')]\n",
    ")\n",
    "\n",
    "subcellresults = subcellresults.loc[subcellresults['lipizone'].isin(ct.index),:]\n",
    "\n",
    "ct[\"lc\"] = ct.index + \"_\" + ct[\"putative_celltype\"]\n",
    "subcellresults[\"lc\"] = subcellresults[\"lipizone\"] + \"_\" + subcellresults[\"celltype\"]\n",
    "ct = ct.loc[ct[\"lc\"].isin(subcellresults[\"lc\"]),:]\n",
    "neighs = pd.read_parquet(\"./zenodo/multimodal/merfishsubclassannotated_acronymized.parquet\")\n",
    "\n",
    "subcellresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b980c-c8c2-4e54-ad3a-81a017754b58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c4681d-d3e6-4149-81e4-c58b8d25aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "from scipy import ndimage\n",
    "from scipy.signal import savgol_filter\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "def smooth_contours_savgol(input_array, window_length=15, polyorder=3, passes=1):\n",
    "    \"\"\"Extract and smooth contours using a Savitzky–Golay filter.\"\"\"\n",
    "    smoothed = ndimage.gaussian_filter(input_array.astype(float), sigma=0.75)\n",
    "    contours = measure.find_contours(smoothed, 0.5)\n",
    "    smoothed_contours = []\n",
    "\n",
    "    for contour in contours:\n",
    "        if len(contour) <= 3:\n",
    "            smoothed_contours.append(contour)\n",
    "            continue\n",
    "\n",
    "        # Adjust window_length if necessary\n",
    "        if len(contour) <= window_length:\n",
    "            wl = min(len(contour) - 2, 5)\n",
    "            if wl % 2 == 0:\n",
    "                wl -= 1\n",
    "        else:\n",
    "            wl = window_length\n",
    "\n",
    "        # Adjust polyorder if necessary\n",
    "        po = polyorder if wl > polyorder else max(1, wl - 1)\n",
    "\n",
    "        x, y = contour[:, 1], contour[:, 0]\n",
    "        try:\n",
    "            for _ in range(passes):\n",
    "                x = savgol_filter(x, wl, po)\n",
    "                y = savgol_filter(y, wl, po)\n",
    "            smoothed_contours.append(np.column_stack((y, x)))\n",
    "        except:\n",
    "            smoothed_contours.append(contour)\n",
    "\n",
    "    return smoothed_contours\n",
    "\n",
    "ann = np.load(\"./zenodo/mixed/eroded_annot.npy\")\n",
    "\n",
    "def plot_gray_fill(contours, output_filename=\"gray_fill.pdf\"):\n",
    "    \"\"\"Quick alternative: fill each smoothed contour in gray with a white border.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    for cnt in contours:\n",
    "        ax.fill(cnt[:, 1], -cnt[:, 0],\n",
    "                facecolor='white',\n",
    "                edgecolor='lightgray',\n",
    "                linewidth=6.0)\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(output_filename, bbox_inches='tight')\n",
    "    #plt.close(fig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc3f23-4163-4abe-a988-25f603d6028b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "for iiiii in [\"SSp-bfd4-VISl4-VISp4-VISa4-AUDd4\",\n",
    "    \"Medullary reticular nucleus, ventral part\",\n",
    "    \"Oculomotor nucleus_1\",\n",
    "    \"Pa4-IPDL-AV-IPI-SGN\",\n",
    "    \"SPFm-SPA-PRC-DR-IMD\",\n",
    "    \"VISli6a-VISl6a-AUDpo6a-VISam5-SSp-ll5\",\"Pontine gray\", \"em-FF-RN-RT-III\"]: \n",
    "    \n",
    "    noooow = ct.loc[ct.index == iiiii,:]\n",
    "    lipizonenow =noooow.index.values[0]\n",
    "    celltypenow = noooow.putative_celltype[0]\n",
    "    levelnow = noooow.label1[0]\n",
    "    levelnow2 = noooow.label2[0]\n",
    "    atlas['putative_celltype'] = atlas[levelnow].map(ct.loc[(ct['label1'] ==levelnow) & (ct['label2'] ==levelnow2), 'putative_celltype']).fillna(\"nocelltype\")\n",
    "    atlas['xlevc'] = atlas[levelnow].map(ct.loc[(ct['label1'] ==levelnow) & (ct['label2'] ==levelnow2), 'label2']).fillna(\"nocelltype\")\n",
    "\n",
    "    if levelnow2 == \"labels_cluster\":\n",
    "        levelnow2 = \"putative_celltype\"\n",
    "    nn = neighs.loc[neighs[levelnow2] == celltypenow,:]\n",
    "\n",
    "    tmp = atlas.loc[atlas.index.isin(nn.index),:]\n",
    "    \n",
    "    lipizone = lipizonenow\n",
    "    \n",
    "    print(lipizone)\n",
    "    \n",
    "    bait = atlas.loc[atlas[levelnow] == lipizonenow,:]\n",
    "    \n",
    "    X = bait[['xccf', 'yccf', 'zccf']].values\n",
    "    pca = PCA(n_components=2, random_state=0)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    bait['PC1'] = X_pca[:, 0]\n",
    "    bait['PC2'] = X_pca[:, 1]\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "    bait['cluster'] = kmeans.fit_predict(X_pca)\n",
    "    bait['clustercolor'] = \"orange\"\n",
    "    bait.loc[bait['cluster'] ==0, 'clustercolor'] = \"yellow\"\n",
    "\n",
    "    baited = merfish.loc[merfish[bait['xlevc'].unique()[0]] == bait['putative_celltype'].unique()[0],:]\n",
    "    X_new = baited[['x_ccf', 'y_ccf', 'z_ccf']].values\n",
    "    X_new_pca = pca.transform(X_new)\n",
    "    baited['PC1'] = X_new_pca[:, 0]\n",
    "    baited['PC2'] = X_new_pca[:, 1]\n",
    "    baited['cluster'] = kmeans.predict(X_new_pca)\n",
    "    bait['nucl'] = nuclei_sm[bait['x_index'].astype(int), bait['y_index'].astype(int), bait['z_index'].astype(int)]\n",
    "    baited['nucl'] = nuclei_sm[(baited['x_ccf']*40).astype(int), (baited['y_ccf']*40).astype(int), (baited['z_ccf']*40).astype(int)]\n",
    "    bait['subcell'] = \"soma\"\n",
    "\n",
    "    if np.mean(baited['cluster'] == 0) > 0.8:\n",
    "        bait.loc[bait['cluster'] == 1, 'subcell'] = \"terminal\"\n",
    "    elif np.mean(baited['cluster'] == 0) < 0.2:\n",
    "        bait.loc[bait['cluster'] == 0, 'subcell'] = \"terminal\"\n",
    "    else:\n",
    "        bait['subcell'] = \"no_soma_terminal_detected\"\n",
    "\n",
    "    # assign soma vs nonsoma\n",
    "    mediannuclei_soma = baited['nucl'].median()\n",
    "    mediannuclei_terminals = bait.loc[bait['subcell'] == \"terminal\", 'nucl'].median()\n",
    "    \n",
    "    x0 = connectome_binarized.loc[connectome_binarized.index.isin(bait.loc[bait['cluster'] == 0,:].index),:]\n",
    "    overlap_x0centric = x0.sum().sort_values()[::-1] / len(x0)\n",
    "    candidates_x0 = overlap_x0centric[overlap_x0centric > 0.1].index.values\n",
    "    x1 = connectome_binarized.loc[connectome_binarized.index.isin(bait.loc[bait['cluster'] == 1,:].index),:]\n",
    "    overlap_x1centric = x1.sum().sort_values()[::-1] / len(x1)\n",
    "    candidates_x1 = overlap_x1centric[overlap_x1centric > 0.1].index.values\n",
    "    passthroughboth = np.intersect1d(candidates_x0, candidates_x1) \n",
    "    subdf = connectome_binarized.loc[:, passthroughboth]\n",
    "    for x in subdf.columns:\n",
    "        coordstream = coords.loc[subdf[x].values,:]\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(coordstream.values)\n",
    "        pca = PCA(n_components=1)\n",
    "        t_pca = pca.fit_transform(X_scaled).ravel()\n",
    "        bait[x+\"_pca\"] = pca.transform(bait[['xccf','yccf','zccf']])\n",
    "\n",
    "\n",
    "    criterion = bait.loc[:, np.array(passthroughboth)+\"_pca\"].groupby(bait[\"subcell\"]).mean() \n",
    "    connectomestream = np.abs(criterion.loc['soma',:] - criterion.loc['terminal',:]).sort_values().index[-1][:-4]\n",
    "\n",
    "    print(f\"[{lipizone}] connectomic stream → {connectomestream}\")\n",
    "    \n",
    "    overlap0_val = overlap_x0centric[connectomestream]\n",
    "    overlap1_val = overlap_x1centric[connectomestream]\n",
    "    \n",
    "    coordstream = coords.loc[subdf[connectomestream].values,:]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(coordstream.values)\n",
    "    pca = PCA(n_components=1)\n",
    "    coordstream['t_pca'] = pca.fit_transform(X_scaled).ravel()\n",
    "\n",
    "    atlasss = atlas.loc[connectome_binarized.index,:]\n",
    "    \n",
    "    top32_sections = bait['SectionID'] \\\n",
    "        .value_counts() \\\n",
    "        .nlargest(32) \\\n",
    "        .index\n",
    "\n",
    "    means = (\n",
    "        atlasss[atlasss['SectionID'].isin(top32_sections)]\n",
    "        .groupby('SectionID')['xccf']\n",
    "        .mean()\n",
    "    )\n",
    "\n",
    "    unique_sections = means.sort_values(ascending=True).index.tolist()\n",
    "\n",
    "    toperc = coordstream.loc[coordstream.index.isin(atlasss.loc[atlasss['SectionID'].isin(unique_sections),:].index), 't_pca'].values\n",
    "    plow = np.percentile(toperc, 1)\n",
    "    phigh = np.percentile(toperc, 95)\n",
    "\n",
    "    soma_vals = coordstream.loc[coordstream.index.isin(bait.loc[bait['subcell'] == 'soma'].index), 't_pca']\n",
    "    terminal_vals = coordstream.loc[coordstream.index.isin(bait.loc[bait['subcell'] == 'terminal'].index), 't_pca']\n",
    "    \n",
    "    if len(soma_vals) > 0 and len(terminal_vals) > 0:\n",
    "        soma_mean = soma_vals.mean()\n",
    "        terminal_mean = terminal_vals.mean()\n",
    "        if soma_mean > terminal_mean:\n",
    "            coordstream['t_pca'] = -coordstream['t_pca']\n",
    "            plow, phigh = -phigh, -plow\n",
    "    \n",
    "    colors_list = ['#00C800', '#000000', '#C80000']\n",
    "    custom_cmap = LinearSegmentedColormap.from_list('custom_dark_middle', colors_list, N=256)\n",
    "    \n",
    "    subset = atlasss.loc[atlasss['SectionID'].isin(unique_sections[:32]), ['z_index','y_index']]\n",
    "    x_min, x_max = subset['z_index'].min(), subset['z_index'].max()\n",
    "    y_vals = -subset['y_index']\n",
    "    y_min, y_max = y_vals.min(), y_vals.max()\n",
    "\n",
    "    \n",
    "    fig, axs = plt.subplots(4, 8, figsize=(32, 16))\n",
    "    fig.patch.set_facecolor('black')\n",
    "\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    for i, section_value in enumerate(unique_sections[:32]):\n",
    "        if i >= len(axs):\n",
    "            break\n",
    "        ax = axs[i]\n",
    "        \n",
    "        filtered_section = atlasss[atlasss[\"SectionID\"] == section_value] \n",
    "        \n",
    "        ahahahalol = filtered_section['x_index'].mean()\n",
    "        ANN = ann[int(ahahahalol), :, :]\n",
    "        contours = smooth_contours_savgol(ANN, window_length=15, polyorder=3, passes=2)\n",
    "        \n",
    "        midcol = ANN.shape[1] / 2\n",
    "\n",
    "        for cnt in contours:\n",
    "            left_pts = cnt[cnt[:,1] <= midcol]\n",
    "            if len(left_pts) < 3:\n",
    "                continue\n",
    "            ax.fill(left_pts[:,1], -left_pts[:,0],\n",
    "                    facecolor='none',\n",
    "                    edgecolor='gray',\n",
    "                    linewidth=1.5)\n",
    "        \n",
    "        filtered_section = atlasss[atlasss[\"SectionID\"] == section_value] \n",
    "        filtered_section2 = coordstream.loc[coordstream.index.isin(filtered_section.index),:]\n",
    "        filtered_section = filtered_section.loc[filtered_section2.index,:]\n",
    "        \n",
    "        ax.scatter(filtered_section['z_index'], -filtered_section['y_index'],\n",
    "                        c=filtered_section2[\"t_pca\"],s=0.2,alpha=0.75,cmap=custom_cmap, vmin=plow, vmax=phigh,\n",
    "                        zorder=1, rasterized=True)   \n",
    "\n",
    "        filtered_section = atlasss[atlasss[\"SectionID\"] == section_value] \n",
    "        filtered_section = filtered_section.loc[filtered_section[levelnow] == lipizonenow,:]\n",
    "        \n",
    "        section_stream_data = coordstream.loc[coordstream.index.isin(filtered_section.index), 't_pca']\n",
    "\n",
    "        stream_idx    = set(filtered_section2.index)\n",
    "\n",
    "        stream_coords = atlasss.loc[list(stream_idx), ['z_index','y_index']].values\n",
    "\n",
    "        colors = []\n",
    "        for idx, row in filtered_section[['z_index','y_index']].iterrows():\n",
    "            z, y = row['z_index'], row['y_index']\n",
    "\n",
    "            if idx in stream_idx:\n",
    "                keep_old = True\n",
    "            else:\n",
    "                deltas = np.abs(stream_coords - np.array([z, y]))\n",
    "                keep_old = np.any(deltas.max(axis=1) <= 2)\n",
    "\n",
    "            if keep_old:\n",
    "                sub = bait.loc[idx, \"subcell\"]\n",
    "                if sub == \"soma\":\n",
    "                    colors.append(\"cyan\")\n",
    "                elif sub == \"terminal\":\n",
    "                    colors.append(\"magenta\")\n",
    "                else:\n",
    "                    colors.append(\"gray\")\n",
    "            else:\n",
    "                colors.append(\"blue\")\n",
    "        \n",
    "        sc = ax.scatter(\n",
    "        filtered_section['z_index'], \n",
    "        -filtered_section['y_index'],\n",
    "        s=12.0,             \n",
    "        c=colors,     \n",
    "        alpha=1.0,\n",
    "        rasterized=False,   \n",
    "    )\n",
    "\n",
    "        \n",
    "        sc.set_path_effects([\n",
    "            pe.Stroke(linewidth=1.5, foreground='white'),\n",
    "            pe.Normal()\n",
    "        ])\n",
    "\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        ax.set_aspect('equal')\n",
    "        \n",
    "    for ax in axs:\n",
    "        ax.set_xlim(x_min, x_max)\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_facecolor('black')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\n",
    "    \"./lipizone_subcell_go_leaves/new_archiecturelipizones_\"\n",
    "    + lipizone\n",
    "    + str(iiiii)\n",
    "    + \".png\"\n",
    "    )\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5548de6d-c04a-49b8-a73d-6ecbebe4a87a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3788e174-8877-4dbb-b4a2-73afe45eb6ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78b262b-7149-496d-9f65-fc867cc4437b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172fa5e1-aa68-47dc-a5b5-e66c41d391f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3163773f-d1bc-49b2-9a37-8599ff7bc685",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978a8a3a-b8e3-40b5-80eb-fedcb093431f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
