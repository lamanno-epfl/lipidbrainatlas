{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda200f2-32b0-4d28-b911-1cb8762bddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import NMF\n",
    "from openTSNE import TSNEEmbedding, affinity, initialization\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "import harmonypy as hm\n",
    "import networkx as nx\n",
    "from threadpoolctl import threadpool_limits, threadpool_info\n",
    "\n",
    "# configure thread limits\n",
    "threadpool_limits(limits=8)\n",
    "os.environ['OMP_NUM_THREADS'] = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c06ff08-a86d-408e-b203-63bd721d974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_hdf(\"20241103_featsel_lba.h5\", key=\"table\")\n",
    "\n",
    "coordinates = data[['Section', 'xccf', 'yccf', 'zccf']]\n",
    "coordinates['Section'] = coordinates['Section'].astype(int)\n",
    "\n",
    "metdat = data.iloc[:,:23]\n",
    "data = data.iloc[:,23:]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8922d8-248a-41ca-a057-7b1e98d4d8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "087c902f-0ab3-4b36-b62d-ebbd382b5392",
   "metadata": {},
   "source": [
    "## Define a seeding procedure to initialize NMF by automatically detecting a reasonable number of factors, as high as possible while preserving good modularity of lipid correlation blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b5dd83-be6d-4873-a1da-bc7b4e0ca188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use NMF to decompose the data into factors\n",
    "\n",
    "def compute_seeded_NMF(data):  # data is a dataframe pixels x lipids\n",
    "    # 1. calculate the correlation matrix of this dataset\n",
    "    corr = np.corrcoef(data.values.T)\n",
    "    corr_matrix = np.abs(corr)  # anticorrelated lipids convey the same info\n",
    "    np.fill_diagonal(corr_matrix, 0)\n",
    "    \n",
    "    adata = anndata.AnnData(X=np.zeros_like(corr_matrix))\n",
    "    adata.obsp['connectivities'] = csr_matrix(corr_matrix)\n",
    "    adata.uns['neighbors'] = {\n",
    "        'connectivities_key': 'connectivities',\n",
    "        'distances_key': 'distances',\n",
    "        'params': {'n_neighbors': 10, 'method': 'custom'}\n",
    "    }\n",
    "    \n",
    "    G = nx.from_numpy_array(corr_matrix)\n",
    "    \n",
    "    # span reasonable Leiden resolution parameters\n",
    "    gamma_values = np.linspace(0.8, 1.5, num=100)\n",
    "    num_communities = []\n",
    "    modularity_scores = []\n",
    "    objective_values = []\n",
    "    \n",
    "    for gamma in gamma_values:\n",
    "        sc.tl.leiden(adata, resolution=gamma, key_added=f'leiden_{gamma}')\n",
    "        clusters = adata.obs[f'leiden_{gamma}'].astype(int).values\n",
    "        num_comms = len(np.unique(clusters))\n",
    "        num_communities.append(num_comms)\n",
    "        partition = {i: clusters[i] for i in range(len(clusters))}\n",
    "        modularity = nx.community.modularity(G, [np.where(clusters == i)[0] for i in range(num_comms)])\n",
    "        modularity_scores.append(modularity)\n",
    "    \n",
    "    # 3. pick a number of blocks that is relatively high while preserving good modularity\n",
    "    epsilon = 1e-10\n",
    "    alpha = 0.7  # controls the weight of modularity vs pushing higher the number of communities\n",
    "    for Q, N_c in zip(modularity_scores, num_communities):\n",
    "        f_gamma = Q**alpha * np.log(N_c + 1 + epsilon)\n",
    "        objective_values.append(f_gamma)\n",
    "        \n",
    "    plt.plot(np.arange(len(objective_values)), objective_values)\n",
    "    plt.title(\"obj\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(np.arange(len(modularity_scores)), modularity_scores)\n",
    "    plt.title(\"mod\")\n",
    "    plt.show()\n",
    "        \n",
    "    plt.plot(np.arange(len(num_communities)), num_communities)\n",
    "    plt.title(\"ncomms\")\n",
    "    plt.show()\n",
    "    \n",
    "    max_index = np.argmax(objective_values)\n",
    "    best_gamma = gamma_values[max_index]\n",
    "    best_modularity = modularity_scores[max_index]\n",
    "    best_num_comms = num_communities[max_index]\n",
    "    print(f'Number of communities at best gamma: {best_num_comms}')\n",
    "    \n",
    "    sc.tl.leiden(adata, resolution=best_gamma, key_added='leiden_best') # run Leiden one final time with best parameters\n",
    "    clusters = adata.obs['leiden_best'].astype(int).values\n",
    "    print(clusters)\n",
    "    \n",
    "    N_factors = best_num_comms\n",
    "    \n",
    "    # 4. pick a representative lipid from each block, use to initialize W\n",
    "    dist = 1 - corr_matrix\n",
    "    np.fill_diagonal(dist, 0)\n",
    "    dist = np.maximum(dist, dist.T)  # as numerical instability makes it unreasonably asymmetric\n",
    "    dist_condensed = squareform(dist, checks=True)\n",
    "    representatives = []\n",
    "    \n",
    "    for i in range(0, N_factors):\n",
    "        cluster_members = np.where(clusters == i)[0]\n",
    "        print(cluster_members)\n",
    "        if len(cluster_members) > 0:  # find most central feature in cluster\n",
    "            mean_dist = dist[cluster_members][:, cluster_members].mean(axis=1)\n",
    "            central_idx = cluster_members[np.argmin(mean_dist)]\n",
    "            representatives.append(central_idx)\n",
    "    \n",
    "    W_init = data.values[:, representatives]\n",
    "    \n",
    "    # 5. initialize H as a subset of the correlation matrix\n",
    "    H_init = corr[representatives,:]\n",
    "    H_init[H_init < 0.] = 0.  # only positive correlated can contribute by def in NMF\n",
    "    \n",
    "    # 6. compute the NMF with this initialization and rank N\n",
    "    N_factors = W_init.shape[1]\n",
    "    nmf = NMF(\n",
    "        n_components=N_factors,\n",
    "        init='custom',\n",
    "        random_state=42\n",
    "    )\n",
    "    data_offset = data - np.min(data) + 1e-7\n",
    "    \n",
    "    data_offset = np.ascontiguousarray(data_offset)\n",
    "    W_init = np.ascontiguousarray(W_init)\n",
    "    H_init = np.ascontiguousarray(H_init)\n",
    "    \n",
    "    nmf_result = nmf.fit_transform(\n",
    "        data_offset,\n",
    "        W=W_init,\n",
    "        H=H_init\n",
    "    )\n",
    "    nmfdf = pd.DataFrame(nmf_result, index=data.index)\n",
    "    factor_to_lipid = nmf.components_\n",
    "    \n",
    "    return nmfdf, factor_to_lipid, N_factors, nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c61e0e-17f4-4efd-a119-9ba2bf89485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmfdf, factor_to_lipid, N_factors, nmf = compute_seeded_NMF(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788e9491-bc8e-4cf6-8213-d8eea9113ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "\n",
    "np.save(\"factor_to_lipid.npy\", factor_to_lipid)\n",
    "nmfdf.to_hdf(\"nmfdf.h5ad\", key=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b96f7-92c5-4dda-b2be-95a073063fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "730b1723-3449-4f33-aafe-f1ff33a2c3de",
   "metadata": {},
   "source": [
    "## Check visually the NMF embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aac585-0723-40cf-a5d6-543660dea3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for PC_I in range(0, N_factors):\n",
    "\n",
    "    results = []\n",
    "    filtered_data = pd.concat([coordinates.loc[data.index,:], pd.DataFrame(nmf_result[:,PC_I], index=coordinates.loc[data.index,:].index,columns=[\"test\"])], axis=1)\n",
    "\n",
    "    currentPC = \"test\"\n",
    "    \n",
    "    for section in filtered_data['Section'].unique():\n",
    "        subset = filtered_data[filtered_data['Section'] == section]\n",
    "\n",
    "        perc_2 = subset[currentPC].quantile(0.02) \n",
    "        perc_98 = subset[currentPC].quantile(0.98)\n",
    "\n",
    "        results.append([section, perc_2, perc_98])\n",
    "    percentile_df = pd.DataFrame(results, columns=['Section', '2-perc', '98-perc'])\n",
    "    med2p = percentile_df['2-perc'].median()\n",
    "    med98p = percentile_df['98-perc'].median()\n",
    "\n",
    "    cmap = plt.cm.PuOr\n",
    "\n",
    "    fig, axes = plt.subplots(4, 8, figsize=(20, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for section in range(1, 33):\n",
    "        ax = axes[section - 1]\n",
    "        ddf = filtered_data[(filtered_data['Section'] == section)]\n",
    "\n",
    "        ax.scatter(ddf['zccf'], -ddf['yccf'], c=ddf[currentPC], cmap=\"PuOr\", s=0.5,rasterized=True, vmin=med2p, vmax=med98p) \n",
    "        ax.axis('off')\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    norm = Normalize(vmin=med2p, vmax=med98p)\n",
    "    sm = ScalarMappable(norm=norm, cmap=cmap)\n",
    "    fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e1297e-77f0-4d97-8dbc-1763d3423ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3f51658-b823-4ad9-a2be-9e3f10c6240c",
   "metadata": {},
   "source": [
    "## Use the NMF computed on the atlas to transform the other brains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec87961e-98dc-4adf-b1c3-62b3462a1275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the whole dataset with the NMF learnt on the atlas\n",
    "\n",
    "allbrains = pd.read_hdf(\"/data/luca/lipidatlas/ManuscriptAnalysisRound3/20241103_pixels_allips_allbrains_allen_pixelcleaned.h5ad\")\n",
    "\n",
    "tmp = allbrains.iloc[:,:-23]\n",
    "tmp.columns = tmp.columns.astype(float).astype(str)\n",
    "tmp = tmp.loc[:, data.columns.astype(float).astype(str)]\n",
    "tmp\n",
    "\n",
    "nmf_allbrains = nmf.transform(tmp.fillna(0.0001))\n",
    "\n",
    "# save it to file\n",
    "nmfall = pd.DataFrame(nmf_allbrains, index=tmp.index)\n",
    "nmfall.to_hdf(\"seeded_nmf_allbrains.h5ad\", key=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3de9f6-85c7-4a58-9899-6a6b1974da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "metdat = allbrains.iloc[:, -23:]\n",
    "\n",
    "# remove the bad sections\n",
    "nmfall = nmfall.loc[metdat['BadSection'] == 0,:]\n",
    "nmfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0836888d-4c64-4275-b02e-68d4f0785f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a9a631d-b027-468b-b823-87ec644142f9",
   "metadata": {},
   "source": [
    "## Use Harmony to integrate all brains in NMF space with full covariates awareness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ca549b-0aba-40fe-85c0-7430e6de310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = metdat[['SectionID','Sample', 'Sex', 'Condition']].astype(\"category\")\n",
    "batches = batches.loc[nmfall.index,:]\n",
    "batches['SectionID'] = batches['SectionID'].astype(\"category\")\n",
    "batches['Sample'] = batches['Sample'].astype(\"category\")\n",
    "batches['Sex'] = batches['Sex'].astype(\"category\")\n",
    "batches['Condition'] = batches['Condition'].astype(\"category\")\n",
    "batchessub = batches.copy()\n",
    "unique_values = sorted(batchessub['SectionID'].unique())\n",
    "value_mapping = {old_value: new_index for new_index, old_value in enumerate(unique_values)}\n",
    "batchessub['SectionID'] = batchessub['SectionID'].map(value_mapping)\n",
    "batchessub['SectionID'] = batchessub['SectionID'].astype(\"category\")\n",
    "batchessub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb05423-f2bc-45a5-8aec-5e52955dd405",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmfall_mat = nmfall\n",
    "meta_nmfall = batchessub\n",
    "vars_use = list(batchessub.columns)\n",
    "\n",
    "ho = hm.run_harmony(nmfall_mat, meta_nmfall, vars_use)\n",
    "\n",
    "corrected_chunk = pd.DataFrame(\n",
    "    ho.Z_corr.T,\n",
    "    index=nmfall_mat.index,\n",
    "    columns=nmfall_mat.columns\n",
    ")\n",
    "\n",
    "corrected_chunk.to_hdf(\"corrected_nmfall_nochunking.h5ad\", key=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b9534-7ae0-4cdd-8b55-d23df9bf06f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_nmfall = corrected_chunk\n",
    "\n",
    "coordinates = metdat[['x', 'y', 'SectionID']]\n",
    "coordinates = coordinates.loc[corrected_nmfall.index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c3e752-55fa-4212-8355-b67d4cacc2cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2dc1a34b-9b5e-4e70-95dd-2976334d5c72",
   "metadata": {},
   "source": [
    "## Check batch integration in embeddings with spatial plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84a9a91-09a6-4c55-96c9-23fe85b56d64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# note: the harmonized components that use all covariates to remove any sample-specific features and achieve full integration\n",
    "# which is very important to do label transfer and annotate clusters regardless of their specific sex/condition, to then use the native lipids to do 1-1 differential comparisons\n",
    "\n",
    "for PC_I in range(N_factors):\n",
    "\n",
    "    results = []\n",
    "    filtered_data = pd.concat([coordinates, pd.DataFrame(corrected_nmfall.values[:,PC_I], index=coordinates.index,columns=[\"test\"])], axis=1)\n",
    "    filtered_data = filtered_data.dropna(subset=['SectionID'])\n",
    "   \n",
    "    currentPC = \"test\"\n",
    "    \n",
    "    for section in filtered_data['SectionID'].unique():\n",
    "        subset = filtered_data[filtered_data['SectionID'] == section]\n",
    "\n",
    "        perc_2 = subset[currentPC].quantile(0.02)\n",
    "        perc_98 = subset[currentPC].quantile(0.98)\n",
    "\n",
    "        results.append([section, perc_2, perc_98])\n",
    "    percentile_df = pd.DataFrame(results, columns=['SectionID', '2-perc', '98-perc'])\n",
    "    med2p = percentile_df['2-perc'].median()\n",
    "    med98p = percentile_df['98-perc'].median()\n",
    "\n",
    "    cmap = plt.cm.PuOr\n",
    "\n",
    "    fig, axes = plt.subplots(14, 10, figsize=(20, 38))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for section in range(1, np.max(filtered_data['SectionID'].astype(int))+1):\n",
    "        ax = axes[section - 1]\n",
    "        try:\n",
    "            ddf = filtered_data[(filtered_data['SectionID'] == section)]\n",
    "\n",
    "            ax.scatter(ddf['y'], -ddf['x'], c=ddf[currentPC], cmap=\"PuOr\", s=0.5,rasterized=True, vmin=med2p, vmax=med98p) \n",
    "            ax.axis('off')\n",
    "            ax.set_aspect('equal')\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    norm = Normalize(vmin=med2p, vmax=med98p)\n",
    "    sm = ScalarMappable(norm=norm, cmap=cmap)\n",
    "    fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70c1f6e-096c-445c-b94b-40b19bf6893d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6713a337-4366-4950-8e51-057a64d0d094",
   "metadata": {},
   "source": [
    "## Check coembedding on a t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58dc1c-a852-49e9-b932-1379e800921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embds = corrected_nmfall#[::5] # do a minimal downsampling\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(embds)\n",
    "\n",
    "affinities_train = affinity.PerplexityBasedNN(\n",
    "    x_train,\n",
    "    perplexity=30,\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "init_train = x_train[:,[2, 9]] # initialize with two uncorrelated NMFs, note this affects results a bit\n",
    "\n",
    "embedding_train = TSNEEmbedding(\n",
    "    init_train,\n",
    "    affinities_train,\n",
    "    negative_gradient_method=\"fft\",\n",
    "    n_jobs=8,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "embedding_train_1 = embedding_train.optimize(n_iter=500, exaggeration=1.2)\n",
    "\n",
    "embedding_train_N = embedding_train_1.optimize(n_iter=100, exaggeration=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3320a333-8725-4f69-b84f-1979144d561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = embedding_train_N\n",
    "\n",
    "np.save(\"globaltsne.npy\", tsne)\n",
    "\n",
    "tsne_df = pd.DataFrame(tsne, index = embds.index)\n",
    "tsne_df.to_hdf(\"tsne_df.h5ad\", key=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96870186-ea23-4e5a-8f65-0f1641ac3222",
   "metadata": {},
   "outputs": [],
   "source": [
    "metdat = pd.read_hdf(\"metadata.h5ad\", key=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f660a85-52c4-4e24-9bca-b124ab68a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if samples / sections / conditions are well integrated vs anatomical regions defining regions\n",
    "\n",
    "labels = metdat.loc[embds.index, \"Sample\"]\n",
    "plt.scatter(tsne[:, 0], tsne[:, 1], c=labels.astype(\"category\").cat.codes, cmap=\"tab20\", s=0.005, alpha=0.3, \n",
    "            rasterized=True)\n",
    "plt.show()\n",
    "\n",
    "labels = metdat.loc[embds.index, 'Condition']\n",
    "plt.scatter(tsne[:, 0], tsne[:, 1], c=labels.astype(\"category\").cat.codes, cmap=\"tab20\", s=0.005, alpha=0.3, \n",
    "            rasterized=True)\n",
    "plt.show()\n",
    "\n",
    "labels = metdat.loc[embds.index, 'Sex']\n",
    "plt.scatter(tsne[:, 0], tsne[:, 1], c=labels.astype(\"category\").cat.codes, cmap=\"viridis\", s=0.005, alpha=0.3, \n",
    "            rasterized=True)\n",
    "plt.show()\n",
    "\n",
    "labels = metdat.loc[embds.index, 'allencolor']\n",
    "plt.scatter(tsne[:, 0][labels!=\"#000000\"], tsne[:, 1][labels!=\"#000000\"], c=labels[labels!=\"#000000\"], s=0.5, alpha=0.3, \n",
    "            rasterized=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1067f9fe-5f99-41da-9678-9a569e1758ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4dcbc1-f05c-4d56-acff-f69f2a83df87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
