{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efce96f4-b0f1-46b2-99bb-0eab7d179dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from adjustText import adjust_text\n",
    "import random\n",
    "import squidpy as sq\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "# here, we use Moran I / spatial autocorrelation and variance within vs across sections to select those lipids having a spatially informative pattern across all sections, to be used for clustering\n",
    "data = pd.read_parquet(\"brain2only.parquet\")\n",
    "data = data.loc[data['BadSection'] == 0,:]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9485e-2538-4158-9c55-69299240cb37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05bb007c-8557-4ec0-a2b6-4d6272baf3d2",
   "metadata": {},
   "source": [
    "## Check various metrics for each lipid: variance of section-wise variances, Moran's I, dropout level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9f8cf6-7325-4797-8bce-115b822ed212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset of the section-wise, lipid-wise precalculated Moran's coefficients\n",
    "\n",
    "moran = pd.read_csv(\"morans_by_sec.csv\", index_col=0)\n",
    "moran = moran.fillna(0) ### risky move\n",
    "moran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe5e9c8-5635-4a77-ae60-fb7840ac5a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the sections of the atlas\n",
    "\n",
    "moran = moran.iloc[:,:32]\n",
    "moran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbfe843-be61-4e5d-86d3-6eb42563fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize the data\n",
    "\n",
    "inputlips = data.iloc[:,:-23]\n",
    "inputlips[inputlips > 1.] = 0.0001 ### broken values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(inputlips)\n",
    "\n",
    "inputlips = pd.DataFrame(scaled_data, columns=inputlips.columns, index=inputlips.index)\n",
    "inputlips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3084387a-3e2c-4f84-843a-6ec24ef67503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to evaluate the variances and the means of section-wise variances\n",
    "\n",
    "adata = sc.AnnData(X=inputlips)\n",
    "adata.obsm['spatial'] = data[['zccf', 'yccf', 'Section']].loc[data.index,:].values\n",
    "\n",
    "def rank_features_by_combined_score(tempadata):\n",
    "    \n",
    "    sections = tempadata.obsm['spatial'][:, 2]  \n",
    "    \n",
    "    unique_sections = np.unique(sections)\n",
    "\n",
    "    var_of_vars = []\n",
    "    mean_of_vars = []\n",
    "\n",
    "    for i in range(tempadata.X.shape[1]):\n",
    "        feature_values = tempadata.X[:, i]\n",
    "\n",
    "        section_variances = []\n",
    "        for section in unique_sections:\n",
    "            section_values = feature_values[sections == section]\n",
    "            section_variance = np.var(section_values)\n",
    "            section_variances.append(section_variance)\n",
    "\n",
    "        var_of_vars.append(np.var(section_variances))\n",
    "        mean_of_vars.append(np.mean(section_variances))\n",
    "\n",
    "    var_of_vars = np.array(var_of_vars)\n",
    "    mean_of_vars = np.array(mean_of_vars)\n",
    "\n",
    "    combined_score = -var_of_vars/2 + mean_of_vars\n",
    "\n",
    "    return var_of_vars, mean_of_vars, combined_score\n",
    "\n",
    "var_of_vars, mean_of_vars, combined_score = rank_features_by_combined_score(adata)\n",
    "ranked_indices = np.argsort(combined_score)[::-1]\n",
    "\n",
    "plt.plot(var_of_vars[ranked_indices])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(mean_of_vars[ranked_indices])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(combined_score[ranked_indices])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6558e0-e744-485b-889d-b8a24a208068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the scores\n",
    "\n",
    "scores = pd.DataFrame([np.array(inputlips.columns)[ranked_indices], var_of_vars[ranked_indices], mean_of_vars[ranked_indices], combined_score[ranked_indices]]).T\n",
    "scores.columns = [\"spatvar\", \"var_of_vars\", \"mean_of_vars\", \"combined_score\"]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad32c9f-783a-4723-bfd5-690e19bb9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_sorted = moran.mean(axis=1).sort_values()[::-1]\n",
    "moran_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa1311-7d0c-4fc1-8632-38595852e4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.index = scores['spatvar'].astype(float).astype(str)\n",
    "scores = scores.loc[moran_sorted.index.astype(str),:]\n",
    "\n",
    "scores['combined_score'][scores['combined_score'] < -5] = -5 # bad is bad, control outliers\n",
    "scores.index = scores.index.astype(float).astype(str)\n",
    "\n",
    "# a very permissive threshold on Moran's I\n",
    "scores_good_moran = scores.loc[moran_sorted.index[moran_sorted > 0.4].astype(float).astype(str),:]\n",
    "scores = scores_good_moran\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7bb9f-399f-4786-80fa-506555629fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a permissive filter over section-wise dropout: too many dropouts => lipids should be excluded for clustering and reimputed\n",
    "\n",
    "peakmeans = data.iloc[:,:1400].groupby(data['Section']).mean()\n",
    "missinglipid = np.sum(peakmeans < 0.00015).sort_values()\n",
    "missinglipid\n",
    "\n",
    "plt.plot(np.array(missinglipid))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b242537-4ede-4af0-8e96-00d119cd1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_acceptable_lipids = missinglipid.loc[missinglipid < 4].index.astype(float).astype(str)\n",
    "scores = scores.loc[scores.index.isin(dropout_acceptable_lipids),:]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690a90c1-411d-4c91-b7ad-1f43dcc45a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "346309bf-7b7b-4042-a217-7831283d5be4",
   "metadata": {},
   "source": [
    "## Cluster the lipids in the space of scores to detect \"good\" and \"bad\" groups of lipids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89d6503-494e-4e98-97e2-6d90c887f856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess, then cluster\n",
    "\n",
    "moran_sorted.index = moran_sorted.index.astype(float).astype(str)\n",
    "scores['moran'] = moran_sorted.loc[scores.index.astype(float).astype(str)]\n",
    "missinglipid.index = missinglipid.index.astype(float).astype(str)\n",
    "scores['missinglipid'] = missinglipid.loc[scores.index.astype(float).astype(str)]\n",
    "\n",
    "scores = scores.loc[scores['combined_score'] > 0,:]\n",
    "X = scores[['var_of_vars',\t'combined_score',\t'moran',\t'missinglipid']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "plt.scatter(X['combined_score'], X['moran'], c=cluster_labels, s=2, cmap=\"tab20\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50174a8-3b46-4226-b700-72d2ce7eca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = np.array(data.columns)\n",
    "cols[:1400] = cols[:1400].astype(float).astype(str)\n",
    "data.columns = cols\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914eed4b-d4bb-4048-8869-90bd6744f457",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34b88cb4-113b-4809-86a3-1c6a0c825c47",
   "metadata": {},
   "source": [
    "## Manually inspect and annotate \"good\" and \"bad\" groups of lipids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82aacb-5fe2-4ca8-a782-fd1e2258c950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores['cl'] = cluster_labels\n",
    "\n",
    "for xxx in range(0,10):\n",
    "    \n",
    "    print(\"**************\")\n",
    "\n",
    "    scoresaaa = scores.loc[scores['cl'] == xxx,:]\n",
    "\n",
    "    for currentPC in np.random.choice(np.array(scoresaaa.index), 5).astype(float).astype(str):\n",
    "        print(scoresaaa.loc[scoresaaa['spatvar'].astype(float).astype(str) == currentPC,:])\n",
    "        results = []\n",
    "        filtered_data = pd.concat([data[['yccf','zccf','Section']], data.loc[:,str(currentPC)]], axis=1)\n",
    "\n",
    "        for section in filtered_data['Section'].unique():\n",
    "            subset = filtered_data[filtered_data['Section'] == section]\n",
    "\n",
    "            perc_2 = subset[str(currentPC)].quantile(0.02)\n",
    "            perc_98 = subset[str(currentPC)].quantile(0.98)\n",
    "\n",
    "            results.append([section, perc_2, perc_98])\n",
    "        percentile_df = pd.DataFrame(results, columns=['Section', '2-perc', '98-perc'])\n",
    "        med2p = percentile_df['2-perc'].median()\n",
    "        med98p = percentile_df['98-perc'].median()\n",
    "\n",
    "        cmap = plt.cm.inferno\n",
    "\n",
    "        fig, axes = plt.subplots(4, 8, figsize=(20, 10))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for section in range(1, 33):\n",
    "            ax = axes[section - 1]\n",
    "            ddf = filtered_data[(filtered_data['Section'] == section)]\n",
    "\n",
    "            ax.scatter(ddf['zccf'], -ddf['yccf'], c=ddf[str(currentPC)], cmap=\"inferno\", s=0.5,rasterized=True, vmin=med2p, vmax=med98p) \n",
    "            ax.axis('off')\n",
    "            ax.set_aspect('equal')\n",
    "\n",
    "        cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "        norm = Normalize(vmin=med2p, vmax=med98p)\n",
    "        sm = ScalarMappable(norm=norm, cmap=cmap)\n",
    "        fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc64b191-a2d5-498a-bfac-9eb16d0b3108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually annotate the score clusters to keep and to discard\n",
    "scores['keep'] = 1\n",
    "scores.loc[scores['cl'].isin([1,2,3,7,8]), 'keep'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028865fa-63a1-46dc-b1b3-72285e0cecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the scores space for good and bad features, then keep the good ones\n",
    "plt.scatter(scores['combined_score'], scores['moran'], c=scores['keep'], s=2)\n",
    "plt.show()\n",
    "\n",
    "scores = scores.loc[scores['keep'] == 1,:]\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d2e76f-73c3-4d0f-98ea-01caec7b759d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check the distributions of lipids to add a round of manual feature curation (removing bad lipids)\n",
    "\n",
    "with PdfPages('ranking_clustering_featsel.pdf') as pdf:\n",
    "    for currentPC in tqdm(np.array(scores['spatvar'].astype(float).astype(str))):\n",
    "        results = []\n",
    "        filtered_data = pd.concat([data[['yccf','zccf','Section']], data.loc[:,str(currentPC)]], axis=1)[::5] #### ds to go faster\n",
    "\n",
    "        for section in filtered_data['Section'].unique():\n",
    "            subset = filtered_data[filtered_data['Section'] == section]\n",
    "\n",
    "            perc_2 = subset[str(currentPC)].quantile(0.02)\n",
    "            perc_98 = subset[str(currentPC)].quantile(0.98)\n",
    "\n",
    "            results.append([section, perc_2, perc_98])\n",
    "        percentile_df = pd.DataFrame(results, columns=['Section', '2-perc', '98-perc'])\n",
    "        med2p = percentile_df['2-perc'].median()\n",
    "        med98p = percentile_df['98-perc'].median()\n",
    "\n",
    "        cmap = plt.cm.inferno\n",
    "\n",
    "        fig, axes = plt.subplots(4, 8, figsize=(20, 10))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for section in range(1, 33):\n",
    "            ax = axes[section - 1]\n",
    "            ddf = filtered_data[(filtered_data['Section'] == section)]\n",
    "\n",
    "            ax.scatter(ddf['zccf'], -ddf['yccf'], c=ddf[str(currentPC)], cmap=\"inferno\", s=2.0, alpha=0.8,rasterized=True, vmin=med2p, vmax=med98p) \n",
    "            ax.axis('off')\n",
    "            ax.set_aspect('equal')\n",
    "\n",
    "        cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "        norm = Normalize(vmin=med2p, vmax=med98p)\n",
    "        sm = ScalarMappable(norm=norm, cmap=cmap)\n",
    "        fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "        pdf.savefig(fig) \n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7336af5-d4df-41ed-b3de-9842157b28a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was too gentle - there are still several peaks that break the NMF, i'll remove them manually for now. mostly corresponds to raising Moran's to 0.5\n",
    "\n",
    "bad_folks = np.array([25,26,34,35,45,51,55,59,62,67,70,72,73,76,77,91,92,95,97,101,102,103,106,107,110,116,117,118,121,122,127,132,134])\n",
    "sub_scores = scores.iloc[bad_folks,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e011f-4920-4f47-9309-55316db241b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is some cluster to be discarded altogether? it seems not to be the case\n",
    "\n",
    "tmp = scores['cl'].value_counts()\n",
    "tmp2 = sub_scores['cl'].value_counts()\n",
    "tmp2 / tmp.loc[tmp2.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb9aedd-bb76-449a-9073-0fc39d952154",
   "metadata": {},
   "outputs": [],
   "source": [
    "goodscores = scores.loc[~scores.index.isin(sub_scores.index),:]\n",
    "goodscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd55d9c4-0b78-4403-a99f-b8bdc9aa71c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df69bd10-268c-4f45-92f9-e009ab324bec",
   "metadata": {},
   "source": [
    "## Export the feature-selected dataset with lipids that are overall consistent across sections to be used for clustering and to recover other lipids by imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7209c2cd-cbce-404f-b78c-88de497f3c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a feature-selected dataframe\n",
    "\n",
    "#scores = scores.iloc[:elbow_index,:]\n",
    "goodscores.to_csv(\"scores_featsellipids_log.csv\")\n",
    "featsel_lba = pd.concat([data.iloc[:,-23:], data.loc[:,np.array(goodscores['spatvar']).astype(float).astype(str)]], axis=1)\n",
    "\n",
    "featsel_lba.to_hdf(\"20241103_featsel_lba.h5\", key=\"table\")\n",
    "peaks_for_imputation_and_clustering = np.array(goodscores['spatvar'])\n",
    "np.save(\"peaks_for_imputation_and_clustering.npy\", peaks_for_imputation_and_clustering)\n",
    "\n",
    "featsel_lba                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a32a4fd-23d3-4680-84e0-c330dd6f0e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ecb5b9-c416-4098-a509-9d1b924e7c07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
