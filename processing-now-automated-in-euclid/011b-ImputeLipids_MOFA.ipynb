{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b18c91c-a5a5-4fef-90e2-b6161ffcd420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from tqdm import tqdm\n",
    "from matplotlib import cm\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram,fcluster\n",
    "import networkx as nx\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.spatial.distance import pdist\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from skimage import measure\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "import scipy\n",
    "import scanpy as sc\n",
    "import zarr\n",
    "# import tarfile\n",
    "import io\n",
    "import anndata as ad\n",
    "import os\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b764ad5-3a89-4954-b944-b46e465e5ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_parquet(\"atlas.parquet\")\n",
    "dat = pd.concat([dat[['Section', 'y_index', 'z_index']], dat.iloc[:,:173]],axis=1)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d500e890-5242-46b2-92c0-9252be121c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f1f7ace-7ca3-4493-ab97-8c7cc41d89f2",
   "metadata": {},
   "source": [
    "## Impute lipids onto Langlieb et al. cells by colocalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f90c8ba-08ee-4ad9-80a0-ba3adba9640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "for i in tqdm(range(1, 33)):\n",
    "    try:\n",
    "        gexpr = pd.read_hdf(f\"gexpr_{i}.h5\", key=\"table\")\n",
    "        \n",
    "        sec = dat.loc[dat['Section'] == i,:]\n",
    "        sec = sec.loc[sec['z_index'] > 456/2,:]\n",
    "        \n",
    "        distance_matrix = cdist(gexpr[['y_index', 'z_index']], \n",
    "                              sec[['y_index', 'z_index']], \n",
    "                              metric='euclidean')\n",
    "        distance_df = pd.DataFrame(distance_matrix, \n",
    "                                 index=gexpr.index, \n",
    "                                 columns=sec.index)\n",
    "        distance_df_masked = distance_df.copy()\n",
    "        distance_df_masked[distance_df_masked > 4] = np.nan\n",
    "        \n",
    "        # find closest cells and their indices\n",
    "        closest_indices = distance_df_masked.idxmin(axis=1)\n",
    "        min_distances = distance_df_masked.min(axis=1)\n",
    "        \n",
    "        section_result = pd.DataFrame({\n",
    "            'closest_cell': closest_indices,\n",
    "            'distance': min_distances,\n",
    "            'section': i\n",
    "        }, index=gexpr.index)\n",
    "        \n",
    "        # impute the lipidome of the closest voxel for simplicity\n",
    "        section_result = section_result.merge(\n",
    "            sec, \n",
    "            left_on='closest_cell',\n",
    "            right_index=True,\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        all_results.append(section_result)\n",
    "        del gexpr, distance_df_masked, distance_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing section {i}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "final_df = pd.concat(all_results, axis=0)\n",
    "final_df.to_parquet(\"cells_lipidimputed.parquet\")\n",
    "final_df = final_df.dropna()\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8005a99-6ffc-4d8f-abc4-20079d09b389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc4ab1b2-d2de-40fa-9e34-06269e634c8d",
   "metadata": {},
   "source": [
    "## Filter, normalize, prepare the imputed transcriptomics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9302d8a2-8ad4-4a4a-a1f5-0f9836a87e7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare their transcriptome by ***concatenation*** of simple assignment of scrna-seq centroids\n",
    "\n",
    "gexprs = []\n",
    "sizes = []\n",
    "for i in tqdm(range(1, 33)):\n",
    "    try:\n",
    "        gexpr = pd.read_hdf(f\"gexpr_{i}.h5\", key=\"table\")\n",
    "        gexpr['Section'] = i\n",
    "        print(i)\n",
    "        gexprs.append(gexpr)\n",
    "        sizes.append(gexpr.shape[0])\n",
    "        del gexpr\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "gexpr = pd.concat(gexprs)\n",
    "gexpr.drop_duplicates(inplace=True)\n",
    "gexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cd38ac-80bd-40f0-bd9f-33e8bff0bb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "gexpr = gexpr[~gexpr.index.duplicated(keep='first')]\n",
    "final_df = final_df.loc[gexpr.index,:]\n",
    "final_df = final_df[~final_df.index.duplicated(keep='first')]\n",
    "final_df = final_df.loc[final_df.index.isin(np.intersect1d(final_df.index, gexpr.index)),:]\n",
    "gexpr = gexpr.loc[final_df.index,:]\n",
    "\n",
    "# normalize the transcriptomes\n",
    "# preprocess it as if it were common scRNA-seq data (as it fundamentally is)\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "\n",
    "adata = anndata.AnnData(gexpr.iloc[:,:-3]) \n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "gexpr.iloc[:,:-3] = adata.X \n",
    "gexpr\n",
    "\n",
    "# save this pseudo-sc multimodal dataset\n",
    "gexpr = pd.concat([gexpr, final_df],axis=1)\n",
    "coords = gexpr[[\"y_index\",\t\"z_index\",\t\"Section\"]]\n",
    "gexpr.drop([\"y_index\",\t\"z_index\",\t\"Section\"], axis=1,inplace=True)\n",
    "gexpr.to_parquet(\"multimodal_on_macoscko.parquet\")\n",
    "gexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e8f63c-b3f1-48fe-becb-bf8f9a40cd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89e4c575-8cb2-4ac1-bd7a-e1dd6a8ec94f",
   "metadata": {},
   "source": [
    "## Run a multi-omics factor analysis (MOFA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d89a20-f100-4259-939e-0eabf322d4ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in and prepare the data\n",
    "gexpr = pd.read_parquet(\"multimodal_on_macoscko.parquet\")\n",
    "gexpr = gexpr[~gexpr.index.duplicated(keep='first')]\n",
    "genes = gexpr.iloc[:,:-176]\n",
    "lipids = gexpr.iloc[:,-173:]\n",
    "\n",
    "# downsample or MOFA will take 4ever\n",
    "gexpr = genes[::10]\n",
    "print(gexpr.shape)\n",
    "\n",
    "# remove zero-variance features\n",
    "variance = genes.var()\n",
    "zero_var_columns = variance[variance < 0.0001].index\n",
    "print(f\"Columns to remove (zero variance): {list(zero_var_columns)}\")\n",
    "genes = genes.drop(columns=zero_var_columns)\n",
    "lipids = lipids.loc[genes.index,:]\n",
    "genes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba22003d-579f-4945-b3e3-83f4654df25f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run a MOFA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mofapy2.run.entry_point import entry_point\n",
    "\n",
    "data = [\n",
    "    [genes],\n",
    "    [lipids]\n",
    "]\n",
    "\n",
    "# Create MOFA object\n",
    "ent = entry_point()\n",
    "\n",
    "# Set data options\n",
    "ent.set_data_options(scale_groups=True, scale_views=True)\n",
    "ent.set_data_matrix(\n",
    "    data,\n",
    "    likelihoods=[\"gaussian\", \"gaussian\"],  \n",
    "    views_names=[\"gene_expression\", \"lipid_profiles\"],\n",
    "    samples_names=[gexpr.index.tolist()]  # same samples across views\n",
    ")\n",
    "\n",
    "# Set model options\n",
    "ent.set_model_options(\n",
    "    factors=100,  # number of factors to learn ########################\n",
    "    spikeslab_weights=True,  # spike and slab sparsity on weights\n",
    "    ard_weights=True  # Automatic Relevance Determination on weights\n",
    ")\n",
    "\n",
    "# Set training options\n",
    "ent.set_train_options(\n",
    "    iter=10,########################\n",
    "    convergence_mode=\"fast\",\n",
    "    startELBO=1,\n",
    "    freqELBO=1,\n",
    "    dropR2=0.001,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Build and run the model\n",
    "ent.build()\n",
    "ent.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812ffeb7-ecfb-4a49-ac84-43c940efe1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model output, extract factors and weights\n",
    "model = ent.model\n",
    "expectations = model.getExpectations()\n",
    "factors = expectations[\"Z\"][\"E\"] \n",
    "weights = [w[\"E\"] for w in expectations[\"W\"]]  \n",
    "\n",
    "# extract the coordinates of single cells in factors embeddings\n",
    "factors_df = pd.DataFrame(\n",
    "    factors,\n",
    "    index=genes.index,\n",
    "    columns=[f\"Factor_{i+1}\" for i in range(factors.shape[1])]\n",
    ")\n",
    "\n",
    "# extract the contribution of each gene and lipid to each factor, and the top markers of each factor for both modalities\n",
    "weights_gene = pd.DataFrame(\n",
    "    weights[0],  # first view (genes)\n",
    "    index=genes.columns,\n",
    "    columns=factors_df.columns\n",
    ")\n",
    "weights_lipid = pd.DataFrame(\n",
    "    weights[1],  # second view (lipids)\n",
    "    index=lipids.columns,\n",
    "    columns=factors_df.columns\n",
    ")\n",
    "def get_top_features(weights_df, n=10):\n",
    "    top_features = {}\n",
    "    for factor in weights_df.columns:\n",
    "        top_pos = weights_df[factor].nlargest(n).index.tolist()\n",
    "        top_neg = weights_df[factor].nsmallest(n).index.tolist()\n",
    "        top_features[factor] = {'positive': top_pos, 'negative': top_neg}\n",
    "    return top_features\n",
    "top_genes = get_top_features(weights_gene)\n",
    "top_lipids = get_top_features(weights_lipid)\n",
    "\n",
    "# example - reassuring, well-known white matter markers for both modalities\n",
    "print(\"\\nTop features for Factor 1:\")\n",
    "print(\"Genes (positive):\", \", \".join(top_genes['Factor_1']['positive'][:10]))\n",
    "print(\"Lipids (positive):\", \", \".join(top_lipids['Factor_1']['positive'][:5]))\n",
    "\n",
    "factors_df.to_csv(\"minimofa_factors.csv\")\n",
    "weights_gene.to_csv(\"minimofa_weights_genes.csv\")\n",
    "weights_lipid.to_csv(\"minimofa_weights_lipids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9487d04f-86bb-447f-88b4-8cf999712251",
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_df.to_hdf(\"factors_dfMOFA.h5ad\", key=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fbea70-7c03-4efd-b750-0fe034317288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dab3bfb0-e5ee-456a-a099-bf227c6b0070",
   "metadata": {},
   "source": [
    "## Characterize the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0084e13-5f86-4110-a4e8-212888c1aab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do t-SNE on top of MOFA\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import NMF\n",
    "from openTSNE import TSNEEmbedding, affinity, initialization\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "import harmonypy as hm\n",
    "import networkx as nx\n",
    "from threadpoolctl import threadpool_limits, threadpool_info\n",
    "\n",
    "# configure thread limits\n",
    "threadpool_limits(limits=8)\n",
    "os.environ['OMP_NUM_THREADS'] = '6'\n",
    "\n",
    "embds = factors_df\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(embds)\n",
    "\n",
    "affinities_train = affinity.PerplexityBasedNN(\n",
    "    x_train,\n",
    "    perplexity=30,\n",
    "    metric=\"euclidean\",\n",
    "    n_jobs=8,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "init_train = x_train[:,[0, 1]] # initialize with two factors, note this affects results a bit\n",
    "\n",
    "embedding_train = TSNEEmbedding(\n",
    "    init_train,\n",
    "    affinities_train,\n",
    "    negative_gradient_method=\"fft\",\n",
    "    n_jobs=8,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "embedding_train_1 = embedding_train.optimize(n_iter=500, exaggeration=1.2)\n",
    "np.save(\"minimofageneslipidsembedding_train_1.npy\", np.array(embedding_train_1))\n",
    "embedding_train_N = embedding_train_1.optimize(n_iter=100, exaggeration=2.5)\n",
    "np.save(\"minimofageneslipidsembedding_train_N.npy\", np.array(embedding_train_N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91f6b7c-f657-4edd-a86c-9ff4f40392f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embedding_train_N[:,0], embedding_train_N[:,1],s=0.005, c=lipids['HexCer 42:2;O2'], vmin = np.percentile(lipids['HexCer 42:2;O2'], 3), vmax = np.percentile(lipids['HexCer 42:2;O2'], 97), cmap=\"plasma\", rasterized=True)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "plt.savefig('mofa_hexcer.pdf', format='pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0024c815-d00b-42b0-8bc8-c4ff6aa771cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embedding_train_N[:,0], embedding_train_N[:,1],s=0.005, c=genes['Mbp'], cmap=\"plasma\", rasterized=True)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "\n",
    "plt.savefig('mofa_mbp.pdf', format='pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd782725-267e-49f8-8d15-9393e77bcbbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "celltype_classes = np.array([_.split('=')[-1].split('_')[0] for _ in ct])\n",
    "fig, ax = plt.subplots()\n",
    "celltype_series = pd.Series(celltype_classes).astype(\"category\")\n",
    "codes = celltype_series.cat.codes  \n",
    "categories = celltype_series.cat.categories  # Actual names of each category\n",
    "sc = ax.scatter(\n",
    "    embedding_train_N[:, 0],\n",
    "    embedding_train_N[:, 1],\n",
    "    s=0.005,\n",
    "    c=codes,\n",
    "    cmap=\"nipy_spectral\",\n",
    "    rasterized=True\n",
    ")\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(False)\n",
    "counts = celltype_series.value_counts()\n",
    "top_7_categories = counts.index[:7]\n",
    "top_7_codes = [celltype_series.cat.categories.get_loc(cat) for cat in top_7_categories]\n",
    "cmap = plt.cm.nipy_spectral\n",
    "num_cats = len(categories)\n",
    "patches = []\n",
    "for code, cat in zip(top_7_codes, top_7_categories):\n",
    "    color = cmap(code / (num_cats - 1) if num_cats > 1 else 0.5)  # handle single-cat edge case\n",
    "    patches.append(mpatches.Patch(color=color, label=cat))\n",
    "ax.legend(\n",
    "    handles=patches,\n",
    "    bbox_to_anchor=(1.05, 1),\n",
    "    loc='upper left',\n",
    "    title=\"Top 7 Cell Types\"\n",
    ")\n",
    "\n",
    "plt.savefig('celltypeclasses_top7.pdf', format='pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8b006f-a575-45e9-889e-6b1231194219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cell types one at a time in MOFA space to see if some substructure dictated by lipids emerges\n",
    "\n",
    "ct = pd.read_hdf(\"celltypesnow.h5ad\", key=\"table\")\n",
    "ct = ct.loc[factors_df.index]\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import numpy as np\n",
    "\n",
    "unique_cts = ct.unique()\n",
    "def clean_cell_type(cell_type):\n",
    "    if '=' in cell_type:\n",
    "        return cell_type.split('=')[1]\n",
    "    return cell_type\n",
    "\n",
    "with PdfPages('cell_type_MOFA_plots.pdf') as pdf:\n",
    "    plots_per_page = 100\n",
    "    total_pages = 17\n",
    "\n",
    "    for page in range(total_pages):\n",
    "        start_idx = page * plots_per_page\n",
    "        end_idx = min(start_idx + plots_per_page, len(unique_cts))\n",
    "        \n",
    "        fig, axes = plt.subplots(nrows=10, ncols=10, figsize=(20, 20))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, cell_type in enumerate(unique_cts[start_idx:end_idx]):\n",
    "            ax = axes[i]\n",
    "            \n",
    "            ax.scatter(\n",
    "                embedding_train_N[:, 0],\n",
    "                embedding_train_N[:, 1],\n",
    "                c='lightgray',\n",
    "                s=0.005, rasterized=True\n",
    "            )\n",
    "            \n",
    "            mask = (ct == cell_type)\n",
    "            ax.scatter(\n",
    "                embedding_train_N[mask, 0],\n",
    "                embedding_train_N[mask, 1],\n",
    "                c='darkred',\n",
    "                s=0.01, rasterized=True\n",
    "            )\n",
    "            \n",
    "            ax.set_title(clean_cell_type(cell_type), fontsize=8)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "        \n",
    "        for j in range(i+1, 100):\n",
    "            axes[j].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613863ef-c276-4a5f-b2ec-78a44a7ad07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_parquet(\"cells_lipidimputed.parquet\")\n",
    "md = metadata.loc[genes.index, ['z_index', 'y_index', 'Section']]\n",
    "md = md[~md.index.duplicated(keep='first')]\n",
    "md"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bbed584-3962-4907-bd27-4371fb6a2112",
   "metadata": {},
   "source": [
    "factors_df = pd.read_hdf(\"factors_dfMOFA.h5ad\", key=\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea1c75f-b0b3-49f0-b834-a0f24b224d32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "subfactors_df = factors_df.loc[md['Section'].isin([7,11,18]),:].iloc[:, :40]\n",
    "\n",
    "def compute_medians(factors, md, currentLipid):\n",
    "    results = []\n",
    "    for section in md['Section'].unique():\n",
    "        subset = factors[md['Section'] == section]\n",
    "        p2 = subset[currentLipid].quantile(0.02)\n",
    "        p98 = subset[currentLipid].quantile(0.98)\n",
    "        results.append([section, p2, p98])\n",
    "    df = pd.DataFrame(results, columns=['Section', '2-perc', '98-perc'])\n",
    "    return df['2-perc'].median(), df['98-perc'].median()\n",
    "\n",
    "num_per_page = 10\n",
    "lipid_list = subfactors_df.columns\n",
    "\n",
    "with PdfPages(\"lipids_10_per_page.pdf\") as pdf:\n",
    "    for chunk_start in range(0, len(lipid_list), num_per_page):\n",
    "        chunk = lipid_list[chunk_start : chunk_start + num_per_page]\n",
    "        \n",
    "        fig_height = 3 * len(chunk)\n",
    "        fig_width = 8\n",
    "        fig = plt.figure(figsize=(fig_width, fig_height))\n",
    "\n",
    "        for i, currentLipid in enumerate(chunk):\n",
    "            med2p, med98p = compute_medians(factors_df, md, currentLipid)\n",
    "            \n",
    "            rowHeight = 1.0 / len(chunk)\n",
    "            y0 = 1.0 - (i+1)*rowHeight \n",
    "            \n",
    "            w_scatter = 0.8 \n",
    "            h_scatter = rowHeight  \n",
    "            single_ax_width = w_scatter / 3.0\n",
    "            \n",
    "            axes = []\n",
    "            for col_idx in range(3):\n",
    "                x0 = col_idx * single_ax_width\n",
    "                ax = fig.add_axes([x0, y0, single_ax_width, h_scatter])\n",
    "                axes.append(ax)\n",
    "            \n",
    "            for ax, section in zip(axes, [7, 11, 18]):\n",
    "                ddf = pd.concat([\n",
    "                    md[md['Section'] == section],\n",
    "                    factors_df[md['Section'] == section]\n",
    "                ], axis=1)\n",
    "                sc = ax.scatter(ddf['z_index'], -ddf['y_index'],\n",
    "                                c=ddf[currentLipid],\n",
    "                                cmap=\"PuOr\",\n",
    "                                s=0.5,\n",
    "                                rasterized=True,\n",
    "                                vmin=med2p,\n",
    "                                vmax=med98p)\n",
    "                ax.axis('off')\n",
    "                ax.set_aspect('equal')\n",
    "            \n",
    "            cbar_left = 0.82\n",
    "            cbar_bottom = y0 + 0.15*rowHeight \n",
    "            cbar_width = 0.015\n",
    "            cbar_height = 0.7*rowHeight\n",
    "            cbar_ax = fig.add_axes([cbar_left, cbar_bottom, cbar_width, cbar_height])\n",
    "            \n",
    "            norm = Normalize(vmin=med2p, vmax=med98p)\n",
    "            sm = ScalarMappable(norm=norm, cmap=\"PuOr\")\n",
    "            fig.colorbar(sm, cax=cbar_ax)\n",
    "            \n",
    "            top_ax_left = 0.86\n",
    "            top_ax_bottom = y0 + 0.55*rowHeight\n",
    "            top_ax_width = 0.12\n",
    "            top_ax_height = 0.3*rowHeight\n",
    "            top_ax = fig.add_axes([top_ax_left, top_ax_bottom, top_ax_width, top_ax_height])\n",
    "            \n",
    "            bottom_ax_left = 0.86\n",
    "            bottom_ax_bottom = y0 + 0.15*rowHeight\n",
    "            bottom_ax_width = 0.12\n",
    "            bottom_ax_height = 0.3*rowHeight\n",
    "            bottom_ax = fig.add_axes([bottom_ax_left, bottom_ax_bottom, bottom_ax_width, bottom_ax_height])\n",
    "            \n",
    "            for ann_ax in [top_ax, bottom_ax]:\n",
    "                ann_ax.set_xlim(0, 1)\n",
    "                ann_ax.set_ylim(0, 1)\n",
    "                ann_ax.axis('off')\n",
    "            \n",
    "            top_genes_list = top_genes[currentLipid]['positive'][:6]\n",
    "            top_lipids_list = top_lipids[currentLipid]['positive'][:6]\n",
    "            bottom_genes_list = top_genes[currentLipid]['negative'][:6]\n",
    "            bottom_lipids_list = top_lipids[currentLipid]['negative'][:6]\n",
    "            \n",
    "            for j, (gene, lipid) in enumerate(zip(top_genes_list, top_lipids_list)):\n",
    "                y_pos = 0.88 - j * 0.12\n",
    "                top_ax.text(0.10, y_pos, gene, fontsize=4, va='top')\n",
    "                top_ax.text(0.65, y_pos, lipid, fontsize=4, va='top')\n",
    "            \n",
    "            for j, (gene, lipid) in enumerate(zip(bottom_genes_list, bottom_lipids_list)):\n",
    "                y_pos = 0.88 - j * 0.12\n",
    "                bottom_ax.text(0.10, y_pos, gene, fontsize=4, va='top')\n",
    "                bottom_ax.text(0.65, y_pos, lipid, fontsize=4, va='top')\n",
    "            axes[0].text(0.0, 1.02, currentLipid, fontsize=9, transform=axes[0].transAxes)\n",
    "            \n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c0f717-eeda-49a7-a7b7-28946df6bf14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0144696-7d20-4045-9d68-f24cd97a7dc0",
   "metadata": {},
   "source": [
    "## Do an alluvial diagram that compares gene ontologies and lipid classes that dictate MOFA factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5087f5-9c37-4811-acdf-c157b2e9aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_f1 = weights_gene.index[weights_gene['Factor_1'] > np.percentile(weights_gene['Factor_1'], 99)]\n",
    "negative_f1 = weights_gene.index[weights_gene['Factor_1'] < np.percentile(weights_gene['Factor_1'], 1)]\n",
    "negative_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf11975e-653f-4408-87db-da7d087969e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do gene ontology on such clusters: does it make sense?\n",
    "\n",
    "# (by colocalization, it's something)\n",
    "\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import goatools\n",
    "from goatools.anno.genetogo_reader import Gene2GoReader\n",
    "from goatools.base import download_go_basic_obo, download_ncbi_associations\n",
    "from goatools.obo_parser import GODag\n",
    "from goatools.test_data.genes_NCBI_10090_ProteinCoding import GENEID2NT as GeneID2nt_mus\n",
    "from goatools.goea.go_enrichment_ns import GOEnrichmentStudyNS\n",
    "import collections as cx\n",
    "import pandas as pd\n",
    "from goatools.godag_plot import plot_gos, plot_results, plot_goid2goobj\n",
    "from goatools.associations import read_ncbi_gene2go\n",
    "from goatools.anno.factory import get_objanno\n",
    "from goatools.go_enrichment import GOEnrichmentStudy\n",
    "import mygene\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from goatools.gosubdag.gosubdag import GoSubDag\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "obo_dag = GODag(\"go-basic.obo\")\n",
    "# wget http://geneontology.org/ontology/go-basic.obo\n",
    "obo_fname = download_go_basic_obo()\n",
    "\n",
    "# dictionary of  gene symbols: Gene Ontology terms\n",
    "associations = read_ncbi_gene2go('gene2go', taxids=[10090],namespace='MF')  # 10090 is the taxid for mouse\n",
    "obj_ncbi = get_objanno('gene2go', taxid=10090)\n",
    "associations = obj_ncbi.get_id2gos(namespace='all')\n",
    "\n",
    "bp_terms = []\n",
    "for go_id, go_term in obo_dag.items():\n",
    "    if go_term.namespace == 'biological_process':\n",
    "        bp_terms.append(go_id)\n",
    "    elif go_term.namespace == 'molecular_function':\n",
    "        bp_terms.append(go_id)\n",
    "    elif go_term.namespace == 'cellular_component':\n",
    "        bp_terms.append(go_id)\n",
    "        \n",
    "go_subdag = GoSubDag(bp_terms, obo_dag)\n",
    "bp_associations = {}\n",
    "for gene, terms in associations.items():\n",
    "    bp_associations[gene] = [term for term in terms if term in bp_terms]\n",
    "    \n",
    "mg = mygene.MyGeneInfo()\n",
    "\n",
    "population_genes = weights_gene.index.values\n",
    "def convert_symbols_to_entrez(gene_symbols):\n",
    "    gene_info = mg.querymany(gene_symbols, scopes='symbol', fields='entrezgene', species='mouse')\n",
    "    entrez_ids = [int(gene['entrezgene']) for gene in gene_info if 'entrezgene' in gene]\n",
    "    return entrez_ids\n",
    "population_genes = convert_symbols_to_entrez(population_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeb5c72-4c67-43fd-a964-d94147a7d100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loop over clusters\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "gosPOS = []\n",
    "gosNEG = []\n",
    "\n",
    "for f in tqdm(weights_gene.columns):\n",
    "\n",
    "    positive_f = weights_gene.index[weights_gene[f] > np.percentile(weights_gene[f], 99)]\n",
    "    negative_f = weights_gene.index[weights_gene[f] < np.percentile(weights_gene[f], 1)]\n",
    "\n",
    "    markersNOW = positive_f\n",
    "\n",
    "    study_genes = convert_symbols_to_entrez(markersNOW)\n",
    "\n",
    "    g = GOEnrichmentStudy(\n",
    "        population_genes,\n",
    "        associations,\n",
    "        obo_dag,\n",
    "        propagate_counts=False,\n",
    "        alpha=0.05,  # default significance level\n",
    "        methods=['fdr_bh']  # use FDR Benjamini-Hochberg correction\n",
    "    )\n",
    "\n",
    "    # run the enrichment analysis\n",
    "    results = g.run_study(study_genes)\n",
    "    results_df = pd.DataFrame(columns=['GO_name', 'p-value', 'number_items', 'category'])\n",
    "\n",
    "    for r in results:\n",
    "        results_df.loc[r.GO] = [r.name, r.p_fdr_bh, r.study_count, obo_dag[r.GO].namespace]\n",
    "\n",
    "    results_df = results_df.loc[results_df['p-value'] < 0.1,:]\n",
    "\n",
    "    results_df['cluster'] = cl\n",
    "\n",
    "    print(results_df['GO_name'][:10])\n",
    "    gosPOS.append(results_df)\n",
    "\n",
    "\n",
    "    markersNOW = negative_f\n",
    "\n",
    "    study_genes = convert_symbols_to_entrez(markersNOW)\n",
    "\n",
    "    g = GOEnrichmentStudy(\n",
    "        population_genes,\n",
    "        associations,\n",
    "        obo_dag,\n",
    "        propagate_counts=False,\n",
    "        alpha=0.05,  # default significance level\n",
    "        methods=['fdr_bh']  # use FDR Benjamini-Hochberg correction\n",
    "    )\n",
    "\n",
    "    # run the enrichment analysis\n",
    "    results = g.run_study(study_genes)\n",
    "    results_df = pd.DataFrame(columns=['GO_name', 'p-value', 'number_items', 'category'])\n",
    "\n",
    "    for r in results:\n",
    "        results_df.loc[r.GO] = [r.name, r.p_fdr_bh, r.study_count, obo_dag[r.GO].namespace]\n",
    "\n",
    "    results_df = results_df.loc[results_df['p-value'] < 0.1,:]\n",
    "\n",
    "    results_df['cluster'] = cl\n",
    "\n",
    "    print(results_df['GO_name'][:10])\n",
    "    gosNEG.append(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3b71a-c0bb-4aef-9ae5-8afa44376f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_filename = 'mofa.pkl'\n",
    "with open(pickle_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e80c764-a7d2-410a-967c-15d58d0184d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_filename = 'gosPOS.pkl'\n",
    "with open(pickle_filename, 'wb') as file:\n",
    "    pickle.dump(gosPOS, file)\n",
    "pickle_filename = 'gosNEG.pkl'\n",
    "with open(pickle_filename, 'wb') as file:\n",
    "    pickle.dump(gosNEG, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffcee30-5501-4512-a52c-53444018709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## start by keeping only the very top terms...\n",
    "\n",
    "i = 0\n",
    "xs = []\n",
    "for go in gosPOS:\n",
    "    i = i + 1\n",
    "    gotmp = go.loc[(go['p-value'] < 0.01) & (go['category'] == \"biological_process\"),:]\n",
    "    x = pd.DataFrame(-np.log(gotmp['p-value']).values, index = gotmp['GO_name'], columns = [\"Factor_\"+str(i)+\"_+\"])\n",
    "    xs.append(x)\n",
    "    \n",
    "i = 0\n",
    "for go in gosNEG:\n",
    "    i = i + 1\n",
    "    gotmp = go.loc[(go['p-value'] < 0.01) & (go['category'] == \"biological_process\"),:]\n",
    "    x = pd.DataFrame(-np.log(gotmp['p-value']).values, index = gotmp['GO_name'], columns = [\"Factor_\"+str(i)+\"_-\"])\n",
    "    xs.append(x)\n",
    "    \n",
    "goandfact = pd.concat(xs, axis=1).fillna(0)\n",
    "goandfact = goandfact.loc[:,goandfact.sum() > 0]\n",
    "goandfact # index needs cleaning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee975c5c-b0b1-4570-8f09-3e5b289ecfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_test_categorical(\n",
    "    test_labels, \n",
    "    other_labels, \n",
    "    n_permutations=10_000, \n",
    "    alternative='two-sided', \n",
    "    random_state=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform a permutation test to assess whether each category in test_labels \n",
    "    is over- or under-represented compared to what we would expect by chance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    test_labels : 1D array-like of categorical labels (the \"test\" set)\n",
    "    other_labels : 1D array-like of categorical labels (all non-test elements)\n",
    "    n_permutations : int, optional\n",
    "        Number of random permutations\n",
    "    alternative : {'two-sided', 'greater', 'less'}, optional\n",
    "        - 'two-sided': tests if the proportion differs in either direction\n",
    "        - 'greater': tests if test_labels has a higher proportion of the category\n",
    "        - 'less': tests if test_labels has a lower proportion of the category\n",
    "    random_state : int, optional\n",
    "        If provided, sets the random seed for reproducibility\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results : pd.DataFrame\n",
    "        A DataFrame with columns: 'category', 'observed_count', 'expected_count',\n",
    "        'observed_proportion', 'expected_proportion', 'p_value'\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    test_labels = np.array(test_labels)\n",
    "    other_labels = np.array(other_labels)\n",
    "    \n",
    "    all_labels = np.concatenate([test_labels, other_labels])\n",
    "    n_test = len(test_labels)\n",
    "    unique_categories = np.unique(all_labels)\n",
    "    \n",
    "    # calculate expected proportions from full dataset\n",
    "    total_counts = {cat: np.sum(all_labels == cat) for cat in unique_categories}\n",
    "    expected_props = {cat: count/len(all_labels) for cat, count in total_counts.items()}\n",
    "    \n",
    "    # observed counts and proportions\n",
    "    observed_counts = {cat: np.sum(test_labels == cat) for cat in unique_categories}\n",
    "    observed_props = {cat: count/n_test for cat, count in observed_counts.items()}\n",
    "    \n",
    "    # store permutation counts\n",
    "    perm_counts = {cat: np.zeros(n_permutations) for cat in unique_categories}\n",
    "    for i in range(n_permutations):\n",
    "        np.random.shuffle(all_labels)\n",
    "        perm_test = all_labels[:n_test]\n",
    "        for cat in unique_categories:\n",
    "            perm_counts[cat][i] = np.sum(perm_test == cat)\n",
    "    results = []\n",
    "    for cat in unique_categories:\n",
    "        observed = observed_counts[cat]\n",
    "        distribution = perm_counts[cat]\n",
    "        expected = expected_props[cat] * n_test\n",
    "        \n",
    "        if alternative == 'two-sided':\n",
    "            # count permutations that deviate from expected as much as or more than observed\n",
    "            observed_dev = abs(observed - expected)\n",
    "            p_value = np.mean(abs(distribution - expected) >= observed_dev)\n",
    "        \n",
    "        elif alternative == 'greater':\n",
    "            # count permutations where count >= observed\n",
    "            p_value = np.mean(distribution >= observed)\n",
    "        \n",
    "        elif alternative == 'less':\n",
    "            # count permutations where count <= observed\n",
    "            p_value = np.mean(distribution <= observed)\n",
    "        \n",
    "        results.append({\n",
    "            'category': cat,\n",
    "            'observed_count': observed,\n",
    "            'expected_count': expected,\n",
    "            'observed_proportion': observed_props[cat],\n",
    "            'expected_proportion': expected_props[cat],\n",
    "            'p_value': p_value\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "import re\n",
    "\n",
    "df = pd.DataFrame(weights_lipid.index)\n",
    "df.columns = [\"lipid_name\"]\n",
    "\n",
    "# extract the \"class\" etc from the lipid_name\n",
    "df[\"class\"] = df[\"lipid_name\"].apply(lambda x: \n",
    "    \"PC O\" if x.startswith(\"PC O\") else\n",
    "    \"PE O\" if x.startswith(\"PE O\") else\n",
    "    re.split(' |\\(', x)[0]\n",
    ")\n",
    "df[\"carbons\"] = df[\"lipid_name\"].apply(lambda x: int(re.search(r'(\\d+):', x).group(1)) if re.search(r'(\\d+):', x) else np.nan)\n",
    "df[\"insaturations\"] = df[\"lipid_name\"].apply(lambda x: int(re.search(r':(\\d+)', x).group(1)) if re.search(r':(\\d+)', x) else np.nan)\n",
    "df[\"insaturations_per_Catom\"] = df[\"insaturations\"] / df[\"carbons\"]\n",
    "df[\"broken\"] = df[\"lipid_name\"].str.endswith('_uncertain')\n",
    "df.loc[df[\"broken\"], 'carbons'] = np.nan\n",
    "df.loc[df[\"broken\"], 'class'] = np.nan\n",
    "df.loc[df[\"broken\"], 'insaturations'] = np.nan\n",
    "df.loc[df[\"broken\"], 'insaturations_per_Catom'] = np.nan\n",
    "colors = pd.read_hdf(\"lipidclasscolors.h5ad\", key=\"table\")\n",
    "df['color'] = df['class'].map(colors['classcolors'])\n",
    "df.loc[df[\"broken\"], 'color'] = \"gray\"\n",
    "df.index = df['lipid_name']\n",
    "df = df.drop_duplicates()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc37c0d-ca61-4cce-add9-02ecd8913007",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = []\n",
    "\n",
    "for f in tqdm(weights_lipid.columns):\n",
    "\n",
    "    positive_f = weights_lipid.index[weights_lipid[f] > np.percentile(weights_lipid[f], 90)]\n",
    "    negative_f = weights_lipid.index[weights_lipid[f] < np.percentile(weights_lipid[f], 10)]\n",
    "\n",
    "    class_enrichments = permutation_test_categorical(\n",
    "    df.loc[positive_f.values, 'class'], df.loc[np.setdiff1d(weights_lipid.index.values, positive_f), 'class'], \n",
    "    n_permutations=5000, \n",
    "    alternative='two-sided', \n",
    "    random_state=42\n",
    "    )\n",
    "    class_enrichments = class_enrichments.loc[(class_enrichments['p_value'] < 0.1),:]\n",
    "    y = pd.DataFrame(-np.log(class_enrichments['p_value']).values, index = class_enrichments['category'], columns = [f+\"_+\"])\n",
    "    ys.append(y)\n",
    "    \n",
    "    class_enrichments = permutation_test_categorical(\n",
    "    df.loc[negative_f.values, 'class'], df.loc[np.setdiff1d(weights_lipid.index.values, negative_f), 'class'], \n",
    "    n_permutations=5000, \n",
    "    alternative='two-sided', \n",
    "    random_state=42\n",
    "    )\n",
    "    class_enrichments = class_enrichments.loc[(class_enrichments['p_value'] < 0.1),:]\n",
    "    y = pd.DataFrame(-np.log(class_enrichments['p_value']).values, index = class_enrichments['category'], columns = [f+\"_-\"])\n",
    "    ys.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17714de-e7f1-4149-9361-9d1eb43af484",
   "metadata": {},
   "outputs": [],
   "source": [
    "loandfact = pd.concat(ys, axis=1).fillna(0)\n",
    "lipidsandfact = loandfact.loc[:,goandfact.columns]\n",
    "\n",
    "# clip outliers\n",
    "lipidsandfact[lipidsandfact > 10] = 10\n",
    "goandfact[goandfact > 10] = 10\n",
    "lipidsandfact = lipidsandfact.loc[:,lipidsandfact.sum() > 0]\n",
    "goandfact = goandfact.loc[:, lipidsandfact.columns]\n",
    "goandfact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408932ec-0d09-4b25-ab09-06ed32fc2c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "def build_color_dict(terms, palette=px.colors.qualitative.Dark24):\n",
    "    \"\"\"\n",
    "    Assign each term a color (in hex or \"rgb(...)\") from the chosen palette.\n",
    "    Cycles if there are more terms than colors.\n",
    "    \"\"\"\n",
    "    color_dict = {}\n",
    "    pal_len = len(palette)\n",
    "    for i, term in enumerate(terms):\n",
    "        color_dict[term] = palette[i % pal_len]  # e.g., \"#1f77b4\"\n",
    "    return color_dict\n",
    "\n",
    "def to_rgba(hex_or_rgb_str, alpha=1.0):\n",
    "    \"\"\"\n",
    "    Convert a Plotly palette color (like \"#1f77b4\" or \"rgb(31,119,180)\")\n",
    "    into an RGBA string with the specified alpha.\n",
    "    \"\"\"\n",
    "    if hex_or_rgb_str.startswith(\"#\"):\n",
    "        hex_val = hex_or_rgb_str.lstrip(\"#\")\n",
    "        r = int(hex_val[0:2], 16)\n",
    "        g = int(hex_val[2:4], 16)\n",
    "        b = int(hex_val[4:6], 16)\n",
    "        return f\"rgba({r},{g},{b},{alpha})\"\n",
    "    elif hex_or_rgb_str.startswith(\"rgb(\"):\n",
    "        inside = hex_or_rgb_str.strip(\"rgb() \")\n",
    "        r, g, b = inside.split(\",\")\n",
    "        return f\"rgba({r.strip()},{g.strip()},{b.strip()},{alpha})\"\n",
    "    else:\n",
    "        return hex_or_rgb_str\n",
    "\n",
    "go_terms = goandfact.index.tolist()\n",
    "factors = goandfact.columns.tolist()\n",
    "lipid_terms = lipidsandfact.index.tolist()\n",
    "go_color_dict = build_color_dict(go_terms, px.colors.qualitative.Dark24)\n",
    "lipid_color_dict = build_color_dict(lipid_terms, px.colors.qualitative.Light24)\n",
    "go_factor_values = []\n",
    "for go_term in go_terms:\n",
    "    for factor in factors:\n",
    "        flow_value = goandfact.loc[go_term, factor]\n",
    "        go_factor_values.append(flow_value)\n",
    "\n",
    "p70 = np.percentile(go_factor_values, 70)  # keep flows >= this\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "node_labels = go_terms + factors + lipid_terms\n",
    "label_to_index = {label: idx for idx, label in enumerate(node_labels)}\n",
    "\n",
    "# Node colors\n",
    "# if it's a GO term, color = go_color_dict[term]\n",
    "# if it's a lipid term, color = lipid_color_dict[term]\n",
    "factor_color = \"rgba(160,160,160,1.0)\"  # light gray for factors\n",
    "node_colors = []\n",
    "for lbl in node_labels:\n",
    "    if lbl in go_color_dict:\n",
    "        node_colors.append(to_rgba(go_color_dict[lbl], alpha=1.0))\n",
    "    elif lbl in lipid_color_dict:\n",
    "        node_colors.append(to_rgba(lipid_color_dict[lbl], alpha=1.0))\n",
    "    else:\n",
    "        node_colors.append(factor_color)\n",
    "\n",
    "# build links (source, target, value) + link colors\n",
    "sources = []\n",
    "targets = []\n",
    "values = []\n",
    "link_colors = []\n",
    "\n",
    "# --- GO -> Factor ---\n",
    "for go_term in go_terms:\n",
    "    for factor in factors:\n",
    "        flow_value = goandfact.loc[go_term, factor]\n",
    "        # only keep flows in top 30% (>= p70)\n",
    "        if flow_value >= p70:\n",
    "            go_idx = label_to_index[go_term]\n",
    "            factor_idx = label_to_index[factor]\n",
    "            sources.append(go_idx)\n",
    "            targets.append(factor_idx)\n",
    "            values.append(flow_value)\n",
    "            # color of flow = GO color with partial alpha\n",
    "            base_col = go_color_dict[go_term]\n",
    "            link_colors.append(to_rgba(base_col, alpha=0.4))\n",
    "\n",
    "# --- Factor -> Lipid ---\n",
    "for lipid_term in lipid_terms:\n",
    "    for factor in factors:\n",
    "        flow_value = lipidsandfact.loc[lipid_term, factor]\n",
    "        # let's keep all for now\n",
    "        if flow_value > 0:\n",
    "            factor_idx = label_to_index[factor]\n",
    "            lipid_idx = label_to_index[lipid_term]\n",
    "            sources.append(factor_idx)\n",
    "            targets.append(lipid_idx)\n",
    "            values.append(flow_value)\n",
    "            # color of flow = lipid color\n",
    "            base_col = lipid_color_dict[lipid_term]\n",
    "            link_colors.append(to_rgba(base_col, alpha=1.0))\n",
    "\n",
    "# construct the Sankey figure\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    arrangement=\"snap\",\n",
    "    node=dict(\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color=\"black\", width=0.5),\n",
    "        label=node_labels,\n",
    "        color=node_colors\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=sources,\n",
    "        target=targets,\n",
    "        value=values,\n",
    "        color=link_colors\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    font_size=10,\n",
    "    height=2000\n",
    ")\n",
    "fig.write_image(\"sankey.pdf\", format=\"pdf\", engine=\"kaleido\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e4dd9b-24ee-4f6e-a948-a6efa1f55ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "goandfactbu = goandfact.copy()\n",
    "goandfact = goandfact.loc[(goandfact >0).sum(axis=1) > 2,:]\n",
    "goandfact = goandfact.loc[:,goandfact.sum() > 0]\n",
    "lipidsandfact = lipidsandfact.loc[:, goandfact.columns]\n",
    "goandfact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea01b49d-bf3f-40ca-9ef3-84df8261842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a subset zoom in\n",
    "\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "def build_color_dict(terms, palette=px.colors.qualitative.Dark24):\n",
    "    color_dict = {}\n",
    "    pal_len = len(palette)\n",
    "    for i, term in enumerate(terms):\n",
    "        color_dict[term] = palette[i % pal_len]\n",
    "    return color_dict\n",
    "\n",
    "def to_rgba(hex_or_rgb_str, alpha=1.0):\n",
    "    if hex_or_rgb_str.startswith(\"#\"):\n",
    "        hex_val = hex_or_rgb_str.lstrip(\"#\")\n",
    "        r = int(hex_val[0:2], 16)\n",
    "        g = int(hex_val[2:4], 16)\n",
    "        b = int(hex_val[4:6], 16)\n",
    "        return f\"rgba({r},{g},{b},{alpha})\"\n",
    "    elif hex_or_rgb_str.startswith(\"rgb(\"):\n",
    "        inside = hex_or_rgb_str.strip(\"rgb() \")\n",
    "        r, g, b = inside.split(\",\")\n",
    "        return f\"rgba({r.strip()},{g.strip()},{b.strip()},{alpha})\"\n",
    "    else:\n",
    "        return hex_or_rgb_str\n",
    "\n",
    "go_terms = goandfact.index.tolist()\n",
    "factors = goandfact.columns.tolist()\n",
    "lipid_terms = lipidsandfact.index.tolist()\n",
    "\n",
    "go_color_dict = build_color_dict(go_terms, px.colors.qualitative.Dark24)\n",
    "lipid_color_dict = build_color_dict(lipid_terms, px.colors.qualitative.Light24)\n",
    "\n",
    "go_factor_values = []\n",
    "for go_term in go_terms:\n",
    "    for factor in factors:\n",
    "        flow_value = goandfact.loc[go_term, factor]\n",
    "        go_factor_values.append(flow_value)\n",
    "\n",
    "p70 = np.percentile(go_factor_values, 70)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "node_labels = go_terms + factors + lipid_terms\n",
    "label_to_index = {label: idx for idx, label in enumerate(node_labels)}\n",
    "\n",
    "factor_color = \"rgba(160,160,160,1.0)\"\n",
    "\n",
    "node_colors = []\n",
    "for lbl in node_labels:\n",
    "    if lbl in go_color_dict:\n",
    "        node_colors.append(to_rgba(go_color_dict[lbl], alpha=1.0))\n",
    "    elif lbl in lipid_color_dict:\n",
    "        node_colors.append(to_rgba(lipid_color_dict[lbl], alpha=1.0))\n",
    "    else:\n",
    "        node_colors.append(factor_color)\n",
    "\n",
    "sources = []\n",
    "targets = []\n",
    "values = []\n",
    "link_colors = []\n",
    "\n",
    "for go_term in go_terms:\n",
    "    for factor in factors:\n",
    "        flow_value = goandfact.loc[go_term, factor]\n",
    "        if flow_value >= p70:\n",
    "            go_idx = label_to_index[go_term]\n",
    "            factor_idx = label_to_index[factor]\n",
    "            sources.append(go_idx)\n",
    "            targets.append(factor_idx)\n",
    "            values.append(flow_value)\n",
    "            base_col = go_color_dict[go_term]\n",
    "            link_colors.append(to_rgba(base_col, alpha=0.4))\n",
    "\n",
    "for lipid_term in lipid_terms:\n",
    "    for factor in factors:\n",
    "        flow_value = lipidsandfact.loc[lipid_term, factor]\n",
    "        if flow_value > 0:\n",
    "            factor_idx = label_to_index[factor]\n",
    "            lipid_idx = label_to_index[lipid_term]\n",
    "            sources.append(factor_idx)\n",
    "            targets.append(lipid_idx)\n",
    "            values.append(flow_value)\n",
    "            base_col = lipid_color_dict[lipid_term]\n",
    "            link_colors.append(to_rgba(base_col, alpha=1.0))\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    arrangement=\"snap\",\n",
    "    node=dict(\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color=\"black\", width=0.5),\n",
    "        label=node_labels,\n",
    "        color=node_colors\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=sources,\n",
    "        target=targets,\n",
    "        value=values,\n",
    "        color=link_colors\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    font_size=10,\n",
    "    height=2000,\n",
    ")\n",
    "fig.write_image(\"sankey.pdf\", format=\"pdf\", engine=\"kaleido\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159ba804-cda2-41a0-b9cd-ce326975715a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5856b5-8323-4b29-aca5-38950d46c1f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
