{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc48fe4",
   "metadata": {},
   "source": [
    "# Lipid2Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27035f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sys.path.append(os.path.abspath(\"./lipid2position\"))\n",
    "\n",
    "sc.set_figure_params(frameon=False)\n",
    "sc.set_figure_params(dpi=200)\n",
    "sc.set_figure_params(figsize=(4, 4))\n",
    "\n",
    "np.random.seed(4242)\n",
    "random.seed(4242)\n",
    "project_name = \"lipid2position\"\n",
    "project_path = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf5c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee98c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = os.path.join(project_path, project_name)\n",
    "\n",
    "data_path = os.path.join(src_path, \"data/\")\n",
    "\n",
    "results_path = os.path.join(project_path, \"results\")\n",
    "\n",
    "directories = [src_path, data_path, results_path]\n",
    "for directory in directories:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "initial_format = 'exp'\n",
    "final_format = 'norm_exp'\n",
    "\n",
    "datavignettes = pd.read_parquet(\"./zenodo/maindata_2.parquet\")\n",
    "df = datavignettes.loc[datavignettes['Sample'] == \"ReferenceAtlas\",:]\n",
    "\n",
    "df = df[~df['name'].isna()]\n",
    "zcenter = (df['z_index'].max() - df['z_index'].min()) /2\n",
    "allenbrain_df = df.loc[df['z_index'] > zcenter,:]\n",
    "df = df.loc[df['z_index'] < zcenter, :]\n",
    "print(df.shape)\n",
    "\n",
    "allen_global_min_z = allenbrain_df['z_index'].min()\n",
    "allen_global_max_z = allenbrain_df['z_index'].max()\n",
    "allen_global_min_y = -allenbrain_df['y_index'].max() \n",
    "allen_global_max_y = -allenbrain_df['y_index'].min()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650eee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_handler import DataHandler # it is in \"assets\"\n",
    "data_handler = DataHandler(df, \n",
    "                           initial_format=initial_format, \n",
    "                           final_format=final_format)\n",
    "\n",
    "del df\n",
    "\n",
    "adata = data_handler.adata\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b40fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import logging\n",
    "from lipid2position import compute_loss\n",
    "\n",
    "def train(X, Y, \n",
    "          model, optimizer, scheduler,\n",
    "          loss_type,\n",
    "          k=None, a=None, b=None,\n",
    "          num_epochs=100, batch_size=64,\n",
    "          savepath=None,\n",
    "          device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "    \n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler) \n",
    "    logging.basicConfig(filename=os.path.join(savepath, \"logging.log\"), \n",
    "                        level=logging.INFO, \n",
    "                        format=\"%(asctime)s - %(message)s\")\n",
    "    logging.info(\"Starting training session\")\n",
    "    \n",
    "    # Data preparation\n",
    "    train_data = TensorDataset(torch.tensor(X, dtype=torch.float32), \n",
    "                               torch.tensor(Y, dtype=torch.float32))\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Early stopping setup\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    patience = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for data, targets in train_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = compute_loss(outputs.squeeze(), targets, \n",
    "                                loss_type=loss_type,\n",
    "                                k=k, a=a, b=b)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += compute_loss(outputs.squeeze(), targets, loss_type='standardmse').item()\n",
    "\n",
    "        total_loss /= len(train_loader)\n",
    "        scheduler.step(total_loss)\n",
    "        \n",
    "        # Validation\n",
    "        # model.eval()\n",
    "        # val_loss = 0\n",
    "        # with torch.no_grad():\n",
    "        #     for data, targets in test_loader:\n",
    "        #         data, targets = data.to(device), targets.to(device)\n",
    "        #         outputs = model(data)\n",
    "        #         val_loss += criterion(outputs.squeeze(), targets).item()\n",
    "\n",
    "        # val_loss /= len(test_loader)\n",
    "        # scheduler.step(val_loss)\n",
    "\n",
    "        # predict the whole X at every epoch\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            epoch_pred = model(torch.tensor(X, dtype=torch.float32).to(device))\n",
    "            epoch_loss = compute_loss(epoch_pred.squeeze(), \n",
    "                                    torch.tensor(Y, dtype=torch.float32).to(device), \n",
    "                                    loss_type='standardmse').item()\n",
    "            # append to list\n",
    "            if epoch == 0:\n",
    "                losses = [epoch_loss]\n",
    "                predictions = epoch_pred.cpu().numpy()\n",
    "            else:\n",
    "                losses.append(epoch_loss)\n",
    "                predictions = np.concatenate([predictions, epoch_pred.cpu().numpy()], axis=1)\n",
    "\n",
    "        logging.info(f'Epoch {epoch+1} (LR: {scheduler.get_last_lr()}), Training Loss: {total_loss}')\n",
    "        print(f'Epoch {epoch+1} (LR: {scheduler.get_last_lr()}), Training Loss: {total_loss}')\n",
    "\n",
    "        # Early stopping\n",
    "        if total_loss < best_loss:\n",
    "            best_loss = total_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping.\")\n",
    "                logging.info(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "    # Save model\n",
    "    if savepath is not None:\n",
    "        torch.save(model.state_dict(), os.path.join(savepath, \"model.pth\"))\n",
    "        np.save(os.path.join(savepath, \"history_predictions.npy\"), predictions)\n",
    "        np.save(os.path.join(savepath, \"history_losses.npy\"), losses)\n",
    "    \n",
    "    logging.info(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaf880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "add_LP = False\n",
    "\n",
    "if add_LP:\n",
    "    LP = pd.read_hdf(os.path.join(data_path, f\"{dataset_name}_latent.h5ad\"), key='table').loc[adata.obs_names,:]\n",
    "    X = np.concatenate([adata.X, LP/1000], axis=1)\n",
    "else:\n",
    "    X = adata.X\n",
    "\n",
    "scaler = StandardScaler()\n",
    "XTRAIN = scaler.fit_transform(X)\n",
    "\n",
    "YTRAIN = adata.obs[['x_index', 'y_index', 'z_index']].values\n",
    "a = torch.quantile(torch.tensor(YTRAIN), 0.1, axis=0).to(device)\n",
    "b = torch.quantile(torch.tensor(YTRAIN), 0.9, axis=0).to(device)\n",
    "k = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf756665-3b9d-4f24-a03b-ed32b6e31d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lipid2position import Lipid2Position\n",
    "model = Lipid2Position(XTRAIN.shape[1]).to(device)\n",
    "\n",
    "l2_reg = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), \n",
    "                       lr=0.001,\n",
    "                       weight_decay=l2_reg)\n",
    "scheduler = ReduceLROnPlateau(optimizer, \n",
    "                              'min', \n",
    "                              factor=0.1, \n",
    "                              patience=5, \n",
    "                              verbose=True)\n",
    "\n",
    "format = final_format.replace(\"_\", \"\")\n",
    "latents = \"+LPs\" if add_LP else \"\"\n",
    "loss_type = 'standardmse'\n",
    "modelname = f\"lipid2position_{dataset_name.split('_')[-1]}_{format}{latents}_{loss_type}\"\n",
    "\n",
    "savepath = os.path.join(results_path, modelname)\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "print(f\"Results will be saved in {savepath}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "031d58d1-b14a-4a40-9c17-66e2360f058a",
   "metadata": {},
   "source": [
    "train(XTRAIN, YTRAIN, \n",
    "      model, optimizer, scheduler, \n",
    "      loss_type, \n",
    "      num_epochs=50, \n",
    "      batch_size=64, \n",
    "      savepath=savepath, \n",
    "      device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf77f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Lipid2Position(X.shape[1]).to(device)\n",
    "model.load_state_dict(torch.load(os.path.join(savepath, \"model.pth\")))\n",
    "history_losses = np.load(os.path.join(savepath, \"history_losses.npy\"))\n",
    "history_predictions = np.load(os.path.join(savepath, \"history_predictions.npy\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3b90d5-3428-4a0a-8780-8b9d7c61d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(torch.tensor(X, dtype=torch.float32).to(device)).cpu().detach().numpy()\n",
    "adata.obs['x_index_pred'] = outputs[:,0]\n",
    "adata.obs['y_index_pred'] = outputs[:,1]\n",
    "adata.obs['z_index_pred'] = outputs[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a87167d-e245-4a52-8b8d-5037d114d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "allen_colors = {\n",
    "    'Cerebral cortex': [\n",
    "        '#1f9d5a', # green\n",
    "        '#40a666', # green\n",
    "        '#2fa850', # green\n",
    "        '#59b363', # green\n",
    "        '#219866', # green\n",
    "        '#188064', # green\n",
    "        '#248a5e', # green\n",
    "        '#a4daa4', # green\n",
    "        '#9ad2bd', # green\n",
    "        '#6acbba', # green\n",
    "        '#54bf94', # green\n",
    "        '#a0ee9d', # green\n",
    "        '#62d09f', # green\n",
    "        '#009c75', # green\n",
    "        '#8ada87', # green\n",
    "        '#11ad83', # green\n",
    "        '#1aa698', # green\n",
    "        '#7ed04b', # green\n",
    "        '#66a83d', # green\n",
    "        '#90eb8d', # green\n",
    "        '#9de79c', # green\n",
    "        '#84ea81', # green\n",
    "        '#61e7b7', # green\n",
    "        '#59daab', # green\n",
    "        '#32b825', # green\n",
    "        '#58ba48', # green\n",
    "        '#4fc244', # green\n",
    "        '#97ec93', # green\n",
    "        '#48c83c', # green\n",
    "        '#33b932', # green\n",
    "        '#a8ecd3', # green\n",
    "        '#59b947', # green\n",
    "        '#72d569', # green\n",
    "    ],\n",
    "\n",
    "    'Cerebral Nuclei': [\n",
    "        '#80cdf8', # blue\n",
    "        '#98d6f9', # blue\n",
    "        '#a2b1d8', # blue\n",
    "        '#90cbed', # blue\n",
    "        '#b3c0df', # blue\n",
    "        '#96a7d3', # blue\n",
    "        '#8599cc', # blue\n",
    "        '#80c0e2', # blue \n",
    "        '#009fac', # blue\n",
    "        '#019399', # blue\n",
    "        '#08858c', # blue\n",
    "        '#15b0b3', # blue\n",
    "        '#0d9f91', # blue\n",
    "        '#0e9684', # blue\n",
    "    ],\n",
    "\n",
    "    'InterBrain': [\n",
    "        '#e64438', # red\n",
    "        '#f2483b', # red\n",
    "        '#ff5547', # red\n",
    "        '#ff909f', # red\n",
    "        '#ff7080', # red\n",
    "        '#ff8084', # red\n",
    "        '#ff4c3e', # red\n",
    "        '#ff9b88', # red\n",
    "    ],\n",
    "\n",
    "    'MidBrain': [\n",
    "        '#ff90ff', # pink\n",
    "        '#ff64ff', # pink\n",
    "        '#ff7aff', # pink\n",
    "        '#ffa6ff', # pink\n",
    "        '#ffc395', # pink\n",
    "        '#ffb3d9', # pink\n",
    "        '#ff9bcd', # pink\n",
    "        '#ffa5d2', # pink\n",
    "    ],\n",
    "    \n",
    "    'HindBrain': [\n",
    "        '#ffba86', # orange\n",
    "        '#ffae6f', # orange\n",
    "    ],\n",
    "\n",
    "    'Cerebellum': [\n",
    "        '#f0f080', # yellow\n",
    "        '#fffc91', # yellow\n",
    "        '#fffdbc', # yellow\n",
    "    ],\n",
    "\n",
    "    'Fiber Tracts': [\n",
    "    '#cccccc', # grey\n",
    "    '#aaaaaa', # grey\n",
    "    ]\n",
    "}\n",
    "\n",
    "# '#ffffff', # white \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e06ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_min_x = adata.obs['x_index_pred'].min()\n",
    "global_max_x = adata.obs['x_index_pred'].max()\n",
    "global_min_z = adata.obs['z_index_pred'].min()\n",
    "global_max_z = adata.obs['z_index_pred'].max()\n",
    "global_min_y = adata.obs['y_index_pred'].max() \n",
    "global_max_y = adata.obs['y_index_pred'].min()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea00442",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(allen_colors.keys()), 3, \n",
    "                         figsize=(15, 3*len(allen_colors.keys())))\n",
    "\n",
    "for i, col in enumerate(allen_colors.keys()):\n",
    "    xx = adata.obs[adata.obs['allencolor'].isin(allen_colors[col])]\n",
    "    \n",
    "    for j, axis_name in enumerate(['x', 'y', 'z']):\n",
    "        pred_col = f'{axis_name}_index_pred'\n",
    "        true_col = f'{axis_name}_index'\n",
    "\n",
    "        xx_filtered = xx\n",
    "\n",
    "        ax = axes[i][j]\n",
    "        ax.scatter(xx_filtered[true_col], xx_filtered[pred_col], \n",
    "                   s=1, alpha=0.5, c=allen_colors[col][0])\n",
    "        ax.set_ylabel(col if j == 0 else '')\n",
    "        \n",
    "        mse = np.mean((xx_filtered[true_col] - xx_filtered[pred_col])**2)\n",
    "        ax.set_title(f\"MSE: {mse:.3f}\", fontsize=10)\n",
    "\n",
    "        lims = [\n",
    "            np.min([ax.get_xlim(), ax.get_ylim()]),  \n",
    "            np.max([ax.get_xlim(), ax.get_ylim()]), \n",
    "        ]\n",
    "        ax.plot(lims, lims, 'k--', alpha=0.75, zorder=0)\n",
    "\n",
    "plt.suptitle(f\"Predictions on {dataset_name}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a3657-d755-4783-b022-cae5398fddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 7, figsize=(15, 7))\n",
    "axes = axes.flatten()\n",
    "dot_size = 2\n",
    "\n",
    "sections_to_plot = np.sort(adata.obs['Section'].unique())\n",
    "allen_global_min_z = allenbrain_df['z_index'].min()\n",
    "allen_global_max_z = allenbrain_df['z_index'].max()\n",
    "allen_global_min_y = -allenbrain_df['y_index'].max() \n",
    "allen_global_max_y = -allenbrain_df['y_index'].min()  \n",
    "\n",
    "for i, section_num in enumerate(sections_to_plot):\n",
    "    ax = axes[i]\n",
    "    xx = adata.obs[adata.obs[\"Section\"] == section_num]\n",
    "    ax.scatter(xx['z_index_pred'], -xx['y_index_pred'],\n",
    "                     c=xx['allencolor'], \n",
    "                     s=dot_size, \n",
    "                     alpha=0.3) \n",
    "    ax.scatter(allen_global_max_z-xx['z_index'], -xx['y_index'],\n",
    "                     c=xx['allencolor'], \n",
    "                     s=dot_size, \n",
    "                     alpha=0.3) \n",
    "    ax.set_title(f\"{int(section_num)}\")\n",
    "    ax.axis('off')\n",
    "    ax.set_aspect('equal')  \n",
    "\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.suptitle(f\"Predictions on {dataset_name}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaea5967-990c-4299-b7a7-80b8a512ab9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd9763cb",
   "metadata": {},
   "source": [
    "### Test on Brain3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886125ca-695c-44a7-86ac-2c0a86bed498",
   "metadata": {},
   "outputs": [],
   "source": [
    "datavignettes = pd.read_parquet(\"./zenodo/maindata_2.parquet\")\n",
    "df = datavignettes.loc[datavignettes['Sample'] == \"SecondAtlas\",:]\n",
    "\n",
    "df = df[~df['name'].isna()]\n",
    "zcenter = (df['z_index'].max() - df['z_index'].min()) /2\n",
    "allenbrain_df = df.loc[df['z_index'] > zcenter,:]\n",
    "df = df.loc[df['z_index'] < zcenter, :]\n",
    "print(df.shape)\n",
    "\n",
    "allen_global_min_z = allenbrain_df['z_index'].min()\n",
    "allen_global_max_z = allenbrain_df['z_index'].max()\n",
    "allen_global_min_y = -allenbrain_df['y_index'].max() \n",
    "allen_global_max_y = -allenbrain_df['y_index'].min()  \n",
    "\n",
    "data_handler = DataHandler(df, \n",
    "                           initial_format=initial_format, \n",
    "                           final_format=final_format)\n",
    "\n",
    "del df\n",
    "\n",
    "adata_test = data_handler.adata\n",
    "adata_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b806824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "if add_LP:\n",
    "    LPTEST = pd.read_hdf(os.path.join(data_path, f\"{dataset_name}_latent.h5ad\"), key='table').loc[adata_test.obs_names,:]\n",
    "    XTEST = np.concatenate([adata_test.X, LPTEST/1000], axis=1)\n",
    "else:\n",
    "    XTEST = adata_test.X\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "XTEST = scaler.transform(XTEST)\n",
    "\n",
    "YTEST = adata_test.obs[['x_index', 'y_index', 'z_index']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf91ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(torch.tensor(XTEST, dtype=torch.float32).to(device)).cpu().detach().numpy()\n",
    "adata_test.obs['x_index_pred'] = outputs[:,0]\n",
    "adata_test.obs['y_index_pred'] = outputs[:,1]\n",
    "adata_test.obs['z_index_pred'] = outputs[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a90b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_min_x = adata_test.obs['x_index_pred'].min()\n",
    "global_max_x = adata_test.obs['x_index_pred'].max()\n",
    "global_min_z = adata_test.obs['z_index_pred'].min()\n",
    "global_max_z = adata_test.obs['z_index_pred'].max()\n",
    "global_min_y = adata_test.obs['y_index_pred'].max() \n",
    "global_max_y = adata_test.obs['y_index_pred'].min()  \n",
    "\n",
    "fig, axes = plt.subplots(len(allen_colors.keys()), 3, \n",
    "                         figsize=(15, 3*len(allen_colors.keys())))\n",
    "\n",
    "for i, col in enumerate(allen_colors.keys()):\n",
    "    xx = adata_test.obs[adata_test.obs['allencolor'].isin(allen_colors[col])]\n",
    "    \n",
    "    for j, axis_name in enumerate(['x', 'y', 'z']):\n",
    "        pred_col = f'{axis_name}_index_pred'\n",
    "        true_col = f'{axis_name}_index'\n",
    "\n",
    "        xx_filtered = xx\n",
    "\n",
    "        ax = axes[i][j]\n",
    "        ax.scatter(xx_filtered[true_col], xx_filtered[pred_col], \n",
    "                   s=1, alpha=0.5, c=allen_colors[col][0])\n",
    "        ax.set_ylabel(col if j == 0 else '')\n",
    "        \n",
    "        mse = np.mean((xx_filtered[true_col] - xx_filtered[pred_col])**2)\n",
    "        ax.set_title(f\"MSE: {mse:.3f}\", fontsize=10)\n",
    "\n",
    "        lims = [\n",
    "            np.min([ax.get_xlim(), ax.get_ylim()]), \n",
    "            np.max([ax.get_xlim(), ax.get_ylim()]), \n",
    "        ]\n",
    "        ax.plot(lims, lims, 'k--', alpha=0.75, zorder=0)\n",
    "\n",
    "plt.suptitle(f\"Predictions on {dataset_name}\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd3a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, 7, figsize=(15, 7))\n",
    "axes = axes.flatten()\n",
    "dot_size = 2\n",
    "\n",
    "sections_to_plot = np.sort(adata_test.obs['Section'].unique())\n",
    "allen_global_min_z = allenbrain_df['z_index'].min()\n",
    "allen_global_max_z = allenbrain_df['z_index'].max()\n",
    "allen_global_min_y = -allenbrain_df['y_index'].max() \n",
    "allen_global_max_y = -allenbrain_df['y_index'].min()  \n",
    "\n",
    "for i, section_num in enumerate(sections_to_plot):\n",
    "    ax = axes[i]\n",
    "    xx = adata_test.obs[adata_test.obs[\"Section\"] == section_num]\n",
    "    ax.scatter(xx['z_index_pred'], -xx['y_index_pred'],\n",
    "                     c=xx['allencolor'], \n",
    "                     s=dot_size, \n",
    "                     alpha=0.3, rasterized=True)\n",
    "    ax.scatter(allen_global_max_z-xx['z_index'], -xx['y_index'],\n",
    "                     c=xx['allencolor'], \n",
    "                     s=dot_size, \n",
    "                     alpha=0.3, rasterized=True) \n",
    "    ax.axis('off')\n",
    "    ax.set_aspect('equal')  \n",
    "\n",
    "for j in range(i+1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"recon_holdoutbrain.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef582d-5590-4d74-8776-1dab05bba9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "sections_to_plot = sorted(adata_test.obs['Section'].unique())\n",
    "dot_size = 6\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for sec in sections_to_plot:\n",
    "    df = adata_test.obs[adata_test.obs['Section'] == sec]\n",
    "\n",
    "    print(df.shape)\n",
    "    print(df['x_index_pred'])\n",
    "    df = df.loc[df['x_index_pred'] > 250,:]\n",
    "    print(df.shape)\n",
    "    \n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=df['z_index_pred'],\n",
    "        y=-df['y_index_pred'],\n",
    "        z=df['x_index_pred'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=dot_size,\n",
    "            color=df['allencolor'],\n",
    "            opacity=1.0\n",
    "        ),\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(showbackground=False, showgrid=False, zeroline=False, showticklabels=False),\n",
    "        yaxis=dict(showbackground=False, showgrid=False, zeroline=False, showticklabels=False),\n",
    "        zaxis=dict(showbackground=False, showgrid=False, zeroline=False, showticklabels=False),\n",
    "        bgcolor='rgba(0,0,0,0)'\n",
    "    ),\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    margin=dict(t=0, l=0, r=0, b=0)\n",
    ")\n",
    "\n",
    "fig.write_html(f\"{dataset_name}_3d_sections3.html\", include_plotlyjs='cdn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ed129c-3890-4361-8442-025e0183b4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0d4aa-eba7-4534-b68c-eff254ba8610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
