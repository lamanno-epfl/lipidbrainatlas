{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3ac821-9e27-49dd-b7db-065aba580ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "sub_alldata = pd.read_parquet(\"./zenodo/maindata_2.parquet\")\n",
    "sub_alldata = sub_alldata.loc[sub_alldata[\"Sample\"].isin(['Male1','Male2','Male3','Female1','Female2','Female3']),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29917e15-f237-49f1-a40c-918fbe7599f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5ec6455-a87b-41ee-ae8f-378de252c152",
   "metadata": {},
   "source": [
    "## Characterize interindividual variation first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d3bb48-a00a-4c0b-b4f9-89ea676ec089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q0: how many lipids does a lipizone contain?\n",
    "import matplotlib.pyplot as plt\n",
    "atlas = sub_alldata\n",
    "atlasmeans = atlas.iloc[:,:173].groupby(atlas['lipizone_names']).mean()\n",
    "plt.hist((atlasmeans > 0.00015).sum(axis=1), bins=20, color=\"black\")\n",
    "plt.title(\"Number of lipids contained in a lipizone above background\")\n",
    "plt.show()\n",
    "(atlasmeans > 0.00015).sum(axis=1).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f38636-8b5d-4e9b-9a04-eadf5bcc2fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lipids = sub_alldata.columns.values[:173]\n",
    "\n",
    "for col in lipids:\n",
    "    vals = sub_alldata[col].astype(np.float32)\n",
    "    lo = np.percentile(vals, 0.1)\n",
    "    hi = np.percentile(vals, 99.9)\n",
    "    sub_alldata[col] = (np.clip(vals, lo, hi) - lo) / (hi - lo)\n",
    "    \n",
    "coords = sub_alldata[['xccf','yccf','zccf','SectionID', 'Sample', 'SectionPlot', 'x', 'y']]\n",
    "shift = pd.read_parquet(\"./zenodo/bayes/shift_MF.parquet\")\n",
    "baseline = pd.read_parquet(\"./zenodo/bayes/baseline_MF.parquet\")\n",
    "significance = pd.read_parquet(\"./zenodo/bayes/sign_significance_MF.parquet\")\n",
    "significance = significance.loc[shift.index, shift.columns]\n",
    "shift[~significance] = 0.0\n",
    "relshift = shift/baseline\n",
    "susc_df = shift\n",
    "relshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3219334-3dc3-4b24-8993-a16ea2f58e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_icc(df, subject_col, measurement_col):\n",
    "    \"\"\"\n",
    "    Computes the intra-class correlation (ICC) for a one-way random effects model.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: pandas DataFrame containing the data\n",
    "    - subject_col: name of the column identifying individuals\n",
    "    - measurement_col: name of the column with the continuous measurements\n",
    "    \n",
    "    Returns:\n",
    "    - icc: estimated ICC (fraction of variance due to between-subject differences)\n",
    "    - sigma_b2: estimated between-subject variance component\n",
    "    - sigma_w2: estimated within-subject variance component\n",
    "    \"\"\"\n",
    "    # Group-level statistics\n",
    "    group_stats = df.groupby(subject_col)[measurement_col].agg(['mean', 'count'])\n",
    "    group_means = group_stats['mean']\n",
    "    counts = group_stats['count']\n",
    "    grand_mean = df[measurement_col].mean()\n",
    "\n",
    "    # Sum of squares between\n",
    "    ss_between = (counts * (group_means - grand_mean)**2).sum()\n",
    "    J = len(group_stats)\n",
    "    df_between = J - 1\n",
    "    ms_between = ss_between / df_between\n",
    "\n",
    "    # Sum of squares within\n",
    "    ss_within = ((df[measurement_col] \n",
    "                  - df.groupby(subject_col)[measurement_col].transform('mean'))**2).sum()\n",
    "    N = len(df)\n",
    "    df_within = N - J\n",
    "    ms_within = ss_within / df_within\n",
    "\n",
    "    # Estimate variance components\n",
    "    n_bar = counts.mean()\n",
    "    sigma_b2 = (ms_between - ms_within) / n_bar\n",
    "    sigma_w2 = ms_within\n",
    "\n",
    "    # ICC\n",
    "    icc = sigma_b2 / (sigma_b2 + sigma_w2)\n",
    "    return icc, sigma_b2, sigma_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5736b8-3c06-49a8-950a-265d89d30bd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# males loop\n",
    "\n",
    "from tqdm import tqdm\n",
    "alldfs = []\n",
    "\n",
    "for l in tqdm(atlas.columns[:173].values):\n",
    "    \n",
    "    icc_vals = []\n",
    "    for subclass in atlas['subclass'].unique():\n",
    "\n",
    "        df = atlas.loc[(atlas['Sample'].isin(['Male1', 'Male2', 'Male3'])) & (atlas['subclass'] == subclass),:]\n",
    "\n",
    "        icc_val, _, _ = compute_icc(df, 'Sample', l)\n",
    "        \n",
    "        icc_vals.append(icc_val)\n",
    "        \n",
    "    alldfs.append(pd.DataFrame(icc_vals, index = atlas['subclass'].unique()))\n",
    "    \n",
    "males = pd.concat(alldfs, axis=1)\n",
    "males.columns = atlas.columns[:173].values\n",
    "\n",
    "# females loop\n",
    "\n",
    "alldfs_F = []\n",
    "\n",
    "for l in tqdm(atlas.columns[:173].values):\n",
    "    \n",
    "    icc_vals = []\n",
    "    for subclass in atlas['subclass'].unique():\n",
    "\n",
    "        df = atlas.loc[(atlas['Sample'].isin(['Female1', 'Female2', 'Female3'])) & (atlas['subclass'] == subclass),:]\n",
    "\n",
    "        icc_val, _, _ = compute_icc(df, 'Sample', l)\n",
    "        \n",
    "        icc_vals.append(icc_val)\n",
    "        \n",
    "    alldfs_F.append(pd.DataFrame(icc_vals, index = atlas['subclass'].unique()))\n",
    "    \n",
    "females = pd.concat(alldfs_F, axis=1)\n",
    "females.columns = atlas.columns[:173].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf495fa9-6269-4f90-a6f2-f4d3ef7eb716",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(females.mean(), bins=20)\n",
    "plt.show()\n",
    "plt.hist(males.mean(), bins=20)\n",
    "plt.show()\n",
    "meanmf = (males.loc[females.index, females.columns] + females) / 2\n",
    "interindvariance_perlipid = meanmf.mean()\n",
    "\n",
    "\n",
    "np.mean(interindvariance_perlipid)\n",
    "np.percentile(interindvariance_perlipid, 5)\n",
    "np.percentile(interindvariance_perlipid, 95)\n",
    "interindvariance_perlipid.sort_values()[:15]\n",
    "malesint = males.mean()\n",
    "malesint.sort_values()[:15]\n",
    "femalesint = females.mean()\n",
    "femalesint.sort_values()[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6c5cec-e831-481e-9f23-90ead3b00506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e40f213-bc62-4abc-9e01-d2be2b3bec69",
   "metadata": {},
   "source": [
    "## Analyze sex variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5398ff43-a8bc-4a3d-a914-be717e8e6572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(susc_df.max(), bins=10, color=\"black\")\n",
    "plt.show()\n",
    "plt.hist(susc_df.min(), bins=10, color=\"black\")\n",
    "plt.show()\n",
    "plt.hist(shift.values.flatten(), bins=100, color=\"black\")\n",
    "plt.show()\n",
    "\n",
    "susc_df = shift.copy()\n",
    "susc_df['supertype'] = susc_df.index\n",
    "\n",
    "coeffmap = pd.merge(\n",
    "    sub_alldata[['supertype']], \n",
    "    susc_df,\n",
    "    on='supertype',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "coeffmap = coeffmap.iloc[:, 1:]\n",
    "coeffmap.index = sub_alldata.index\n",
    "\n",
    "tocheck = relshift\n",
    "\n",
    "plt.hist(tocheck.values.flatten(), bins=100, color=\"black\")\n",
    "plt.show()\n",
    "\n",
    "scores=tocheck\n",
    "scores['supertype'] = scores.index\n",
    "relativesuscmap = pd.merge(\n",
    "    sub_alldata[['supertype']], \n",
    "    scores,\n",
    "    on='supertype',\n",
    "    how='left'\n",
    ")\n",
    "relativesuscmap.index = sub_alldata.index\n",
    "relativesuscmap = relativesuscmap.iloc[:, 1:]\n",
    "relativesuscmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fddf11-428a-4891-a657-9be4b3718650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centroids = baseline\n",
    "tocheck = scores.iloc[:,:-1]\n",
    "mask = (tocheck.abs() >= 0.3) & (centroids > 0.1) # clean up background at least in part\n",
    "indices = mask.where(mask).stack().index.tolist()\n",
    "indices # there are a few cases of relative high difference, and they seem mostly in WM lipids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20cc2d1-ad30-40f6-a692-4019dda8e484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "first_elements = [t[0] for t in indices]\n",
    "second_elements = [t[1] for t in indices]\n",
    "\n",
    "first_counts = Counter(first_elements)\n",
    "second_counts = Counter(second_elements)\n",
    "\n",
    "first_counts = Counter(dict(sorted(first_counts.items(), key=lambda x: (-x[1], x[0]))))\n",
    "second_counts = Counter(dict(sorted(second_counts.items(), key=lambda x: (-x[1], x[0]))))\n",
    "\n",
    "first_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947cd7d8-dceb-46f0-8d30-72e23237c70b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "filtered_lipids = {lipid: count for lipid, count in second_counts.items() if count > 1}\n",
    "\n",
    "sexsusc_lipids = list(filtered_lipids.keys())\n",
    "sexsusc_lipids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9968968a-adcc-43e2-92dd-8b12b1f9dd05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_lipids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54142e3-1e65-4e69-87a5-ace9bc3eaa5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# winner: 11211222 \n",
    "altered = pd.DataFrame(indices)\n",
    "\n",
    "firstlipids2check = tocheck.loc[\"11211222\", altered.loc[altered[0] == \"11211222\", 1].values].sort_values()[::-1][:10].index.values\n",
    "firstlipids2check\n",
    "\n",
    "tocheck.loc[\"11211222\", altered.loc[altered[0] == \"11211222\", 1].values].sort_values()[::-1]#[:10].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3ff44f-4fb6-4529-abb7-67b01168a876",
   "metadata": {},
   "outputs": [],
   "source": [
    "tocheck.loc[\"11211222\", altered.loc[altered[0] == \"11211222\", 1].values].sort_values()[::-1][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a85dbd9-772c-4f53-a02c-56b91180deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tocheck.loc[\"11211222\", altered.loc[altered[0] == \"11211222\", 1].values].sort_values()[::-1][-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64fa3a7-cc55-4cfa-b3c0-1871de6ad6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second winner 11221111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e70c85-2478-42a4-aef4-c2f6b1c3f1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tocheck.loc[\"11221111\", altered.loc[altered[0] == \"11221111\", 1].values].sort_values()[::-1][-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d923e-bd0e-4398-9934-1d7ebbb543cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tocheck.loc[\"11221111\", altered.loc[altered[0] == \"11221111\", 1].values].sort_values()[::-1][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b55eb3-315f-4937-a0b7-47c7ec1a3eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for aaa in range(1, 7):\n",
    "    sec1 = sub_alldata.loc[sub_alldata['SectionPlot'] == aaa,:]\n",
    "\n",
    "    samples = sec1['Sample'].unique()\n",
    "    num_samples = len(samples)\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, samp in enumerate(samples):\n",
    "        ax = axes[idx]\n",
    "        xxx = sec1.loc[sec1['Sample'] == samp, :]\n",
    "\n",
    "        ax.scatter(\n",
    "            xxx['y'], -xxx['x'],\n",
    "            c=xxx['supertype'].astype(\"category\").cat.codes,\n",
    "            s=0.05,\n",
    "            alpha=0.7,\n",
    "            cmap=\"Greys\"\n",
    "        )\n",
    "\n",
    "        yyy = xxx.loc[xxx['supertype'] == \"11211222\", :]\n",
    "\n",
    "        ax.scatter(\n",
    "            yyy['y'], -yyy['x'],\n",
    "            c=\"red\",\n",
    "            s=0.05,\n",
    "            alpha=0.7\n",
    "        )\n",
    "\n",
    "        ax.set_aspect('equal')\n",
    "\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_visible(False)\n",
    "\n",
    "        ax.set_title(samp)\n",
    "\n",
    "    for idx in range(num_samples, len(axes)):\n",
    "        fig.delaxes(axes[idx])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4559c8aa-71a1-42e4-a93f-dfcc59dac289",
   "metadata": {},
   "outputs": [],
   "source": [
    "## i.e., ventricular systems, hindbrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd3f083-2e6d-4a1a-88ca-9c60140674b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstlipids2check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ada775-3fad-46ee-890c-5e33c056a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "filtered_data = sub_alldata\n",
    "\n",
    "def plot_lipid_distribution(filtered_data, currentPC, tocheck, samples=['Male3', 'Female3'], section=2):\n",
    "\n",
    "    results = []\n",
    "    for section_id in filtered_data['SectionID'].unique():\n",
    "        subset = filtered_data[(filtered_data['SectionID'] == section_id) & \n",
    "                             (filtered_data['supertype'].isin(tocheck))]\n",
    "        perc_2 = subset[currentPC].quantile(0.02)\n",
    "        perc_98 = subset[currentPC].quantile(0.98)\n",
    "        results.append([section_id, perc_2, perc_98])\n",
    "    \n",
    "    percentile_df = pd.DataFrame(results, columns=['SectionID', '2-perc', '98-perc'])\n",
    "    med2p = percentile_df['2-perc'].median()\n",
    "    med98p = percentile_df['98-perc'].median()\n",
    "    \n",
    "    plt.rcParams['figure.dpi'] = 100 \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(6.5, 2))\n",
    "    cmap = plt.cm.viridis\n",
    "    \n",
    "    for sample_idx, sample in enumerate(samples):\n",
    "        ax = axes[sample_idx]\n",
    "        \n",
    "        ddf = filtered_data[\n",
    "            (filtered_data['Sample'] == sample) & \n",
    "            (filtered_data['SectionPlot'] == section)\n",
    "        ]\n",
    "        ax.scatter(\n",
    "            ddf['y'], \n",
    "            -ddf['x'], \n",
    "            c=ddf[\"supertype\"].astype(\"category\").cat.codes, \n",
    "            cmap=\"Greys\", \n",
    "            s=0.5, \n",
    "            alpha=0.02,\n",
    "            rasterized=True\n",
    "        )\n",
    "        \n",
    "        ddf = filtered_data[\n",
    "            (filtered_data['Sample'] == sample) & \n",
    "            (filtered_data['SectionPlot'] == section) & \n",
    "            (filtered_data['supertype'].isin(tocheck))\n",
    "        ]\n",
    "        ax.scatter(\n",
    "            ddf['y'], \n",
    "            -ddf['x'], \n",
    "            c=ddf[currentPC], \n",
    "            cmap=cmap, \n",
    "            s=0.5, \n",
    "            alpha=0.5,\n",
    "            rasterized=True, \n",
    "            vmin=med2p, \n",
    "            vmax=med98p\n",
    "        )\n",
    "        \n",
    "        ax.axis('off')\n",
    "        ax.set_aspect('equal')\n",
    "    \n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    norm = Normalize(vmin=med2p, vmax=med98p)\n",
    "    sm = ScalarMappable(norm=norm, cmap=cmap)\n",
    "    fig.colorbar(sm, cax=cbar_ax)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "    plt.suptitle(currentPC)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "for currentPC in firstlipids2check:\n",
    "    fig = plot_lipid_distribution(filtered_data, currentPC, [\"11211222\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a41b4-8471-4fc1-9674-aa32a43644c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for currentPC in tocheck.loc[\"11221111\", altered.loc[altered[0] == \"11221111\", 1].values].sort_values()[::-1][:10].index.values:\n",
    "    fig = plot_lipid_distribution(filtered_data, currentPC, [\"11221111\"], samples=['Male3', 'Female2'], section=6) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096b3a0b-088a-4d41-8d55-55ef3c5a8164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20c365f9-565b-44ae-bb65-8b14f650f668",
   "metadata": {},
   "source": [
    "## Which lipids, classes, features are globally affected by sex?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a7bdc-9bb3-4870-a2d5-26677544d7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "allsusc = susc_df.iloc[:,:-1].values.flatten()\n",
    "\n",
    "plt.hist(allsusc, bins=20, color=\"black\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c529cf77-854e-48f4-b934-1c1577de5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_test_categorical(\n",
    "    test_labels, \n",
    "    other_labels, \n",
    "    n_permutations=10_000, \n",
    "    alternative='two-sided', \n",
    "    random_state=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform a permutation test to assess whether each category in test_labels \n",
    "    is over- or under-represented compared to what we would expect by chance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    test_labels : 1D array-like of categorical labels (the \"test\" set)\n",
    "    other_labels : 1D array-like of categorical labels (all non-test elements)\n",
    "    n_permutations : int, optional\n",
    "        Number of random permutations\n",
    "    alternative : {'two-sided', 'greater', 'less'}, optional\n",
    "        - 'two-sided': tests if the proportion differs in either direction\n",
    "        - 'greater': tests if test_labels has a higher proportion of the category\n",
    "        - 'less': tests if test_labels has a lower proportion of the category\n",
    "    random_state : int, optional\n",
    "        If provided, sets the random seed for reproducibility\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results : pd.DataFrame\n",
    "        A DataFrame with columns: 'category', 'observed_count', 'expected_count',\n",
    "        'observed_proportion', 'expected_proportion', 'p_value'\n",
    "    \"\"\"\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    \n",
    "    test_labels = np.array(test_labels)\n",
    "    other_labels = np.array(other_labels)\n",
    "    \n",
    "    # Combine everything\n",
    "    all_labels = np.concatenate([test_labels, other_labels])\n",
    "    n_test = len(test_labels)\n",
    "    \n",
    "    # Identify all unique categories\n",
    "    unique_categories = np.unique(all_labels)\n",
    "    \n",
    "    # Calculate expected proportions from full dataset\n",
    "    total_counts = {cat: np.sum(all_labels == cat) for cat in unique_categories}\n",
    "    expected_props = {cat: count/len(all_labels) for cat, count in total_counts.items()}\n",
    "    \n",
    "    # Observed counts and proportions\n",
    "    observed_counts = {cat: np.sum(test_labels == cat) for cat in unique_categories}\n",
    "    observed_props = {cat: count/n_test for cat, count in observed_counts.items()}\n",
    "    \n",
    "    # Store permutation counts\n",
    "    perm_counts = {cat: np.zeros(n_permutations) for cat in unique_categories}\n",
    "    \n",
    "    # Perform the permutations\n",
    "    for i in range(n_permutations):\n",
    "        np.random.shuffle(all_labels)\n",
    "        perm_test = all_labels[:n_test]\n",
    "        for cat in unique_categories:\n",
    "            perm_counts[cat][i] = np.sum(perm_test == cat)\n",
    "    \n",
    "    # Compute p-values and prepare results\n",
    "    results = []\n",
    "    for cat in unique_categories:\n",
    "        observed = observed_counts[cat]\n",
    "        distribution = perm_counts[cat]\n",
    "        expected = expected_props[cat] * n_test\n",
    "        \n",
    "        if alternative == 'two-sided':\n",
    "            # Count permutations that deviate from expected as much as or more than observed\n",
    "            observed_dev = abs(observed - expected)\n",
    "            p_value = np.mean(abs(distribution - expected) >= observed_dev)\n",
    "        \n",
    "        elif alternative == 'greater':\n",
    "            # Count permutations where count >= observed\n",
    "            p_value = np.mean(distribution >= observed)\n",
    "        \n",
    "        elif alternative == 'less':\n",
    "            # Count permutations where count <= observed\n",
    "            p_value = np.mean(distribution <= observed)\n",
    "        \n",
    "        results.append({\n",
    "            'category': cat,\n",
    "            'observed_count': observed,\n",
    "            'expected_count': expected,\n",
    "            'observed_proportion': observed_props[cat],\n",
    "            'expected_proportion': expected_props[cat],\n",
    "            'p_value': p_value\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "import re\n",
    "\n",
    "df = pd.DataFrame(sub_alldata.columns[:173]).fillna('')\n",
    "df.columns = [\"lipid_name\"]\n",
    "\n",
    "# extract the \"class\" etc from the lipid_name\n",
    "df[\"class\"] = df[\"lipid_name\"].apply(lambda x: \n",
    "    \"PC O\" if x.startswith(\"PC O\") else\n",
    "    \"PE O\" if x.startswith(\"PE O\") else\n",
    "    re.split(' |\\(', x)[0]\n",
    ")\n",
    "df[\"carbons\"] = df[\"lipid_name\"].apply(lambda x: int(re.search(r'(\\d+):', x).group(1)) if re.search(r'(\\d+):', x) else np.nan)\n",
    "df[\"insaturations\"] = df[\"lipid_name\"].apply(lambda x: int(re.search(r':(\\d+)', x).group(1)) if re.search(r':(\\d+)', x) else np.nan)\n",
    "df[\"insaturations_per_Catom\"] = df[\"insaturations\"] / df[\"carbons\"]\n",
    "df[\"broken\"] = df[\"lipid_name\"].str.endswith('_uncertain')\n",
    "df.loc[df[\"broken\"], 'carbons'] = np.nan\n",
    "df.loc[df[\"broken\"], 'class'] = np.nan\n",
    "df.loc[df[\"broken\"], 'insaturations'] = np.nan\n",
    "df.loc[df[\"broken\"], 'insaturations_per_Catom'] = np.nan\n",
    "colors = pd.read_hdf(\"./zenodo/mixed/lipidclasscolors.h5ad\", key=\"table\")\n",
    "df['color'] = df['class'].map(colors['classcolors'])\n",
    "df.loc[df[\"broken\"], 'color'] = \"gray\"\n",
    "df.index = df['lipid_name']\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff315e28-8c8f-4436-b0a6-e3a112b8b4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adjustText import adjust_text\n",
    "\n",
    "meansus = coeffmap.mean()\n",
    "meansus = meansus.sort_values()\n",
    "dfff = pd.DataFrame(meansus)\n",
    "colors = df.loc[dfff.index, 'color'].fillna(\"black\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(range(len(dfff)), dfff.iloc[:,0], color=colors)\n",
    "n_items = len(dfff)\n",
    "bottom_5 = list(range(5))\n",
    "top_5 = list(range(n_items-5, n_items))\n",
    "middle_start = 5\n",
    "middle_end = n_items - 5\n",
    "middle_5 = list(np.random.choice(range(middle_start, middle_end), 5, replace=False))\n",
    "indices_to_label = sorted(bottom_5 + middle_5 + top_5)\n",
    "\n",
    "texts = []\n",
    "for idx in indices_to_label:\n",
    "    x = idx\n",
    "    y = dfff.iloc[idx, 0]\n",
    "    label = dfff.index[idx]\n",
    "    texts.append(plt.text(x, y, label, ha='center', va='bottom'))\n",
    "\n",
    "adjust_text(texts, \n",
    "           arrowprops=dict(arrowstyle='->', color='gray', lw=0.5),\n",
    "           expand_points=(1.5, 1.5))\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.ylabel('Mean susceptibility across the whole brain')\n",
    "plt.xlabel(\"Sorted lipid species\")\n",
    "plt.xticks([])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb44934-a410-4fd1-8ed3-1f482ca07830",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfff[:8] # globally, the differences are really weak!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67375bf2-a8e1-4dda-8471-db085bd591c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfff[-8:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917f7068-46b4-4f82-9927-2e9c0be52734",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_enrichments = permutation_test_categorical(\n",
    "df.loc[meansus.index[(meansus > 0.01)].values, 'class'], df.loc[np.setdiff1d(df.index.values, meansus.index[(meansus > 0.01)]), 'class'], \n",
    "n_permutations=5000, \n",
    "alternative='two-sided', \n",
    "#random_state=42\n",
    ")\n",
    "class_enrichments = class_enrichments.loc[(class_enrichments['p_value'] < 0.1),:]\n",
    "class_enrichments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c8fbbf-e747-4333-8992-970acc2b8f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_enrichments = permutation_test_categorical(\n",
    "df.loc[meansus.index[(-meansus > 0.01)].values, 'class'], df.loc[np.setdiff1d(df.index.values, meansus.index[(-meansus > 0.01)]), 'class'], \n",
    "n_permutations=5000, \n",
    "alternative='two-sided', \n",
    "#random_state=42\n",
    ")\n",
    "class_enrichments = class_enrichments.loc[(class_enrichments['p_value'] < 0.1),:]\n",
    "class_enrichments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b3aea-b865-4e4b-8542-176b210b97c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "checklip = ['Cer 40:2;O2'] \n",
    "\n",
    "filtered_data = pd.concat([sub_alldata, alldata.loc[:, checklip]],axis=1)\n",
    "\n",
    "for currentPC in checklip:\n",
    "    \n",
    "    print(currentPC)\n",
    "    results = []\n",
    "\n",
    "    for section in filtered_data['SectionID'].unique():\n",
    "        subset = filtered_data[filtered_data['SectionID'] == section]\n",
    "\n",
    "        perc_2 = subset[currentPC].quantile(0.02)\n",
    "        perc_98 = subset[currentPC].quantile(0.98)\n",
    "\n",
    "        results.append([section, perc_2, perc_98])\n",
    "    percentile_df = pd.DataFrame(results, columns=['SectionID', '2-perc', '98-perc'])\n",
    "    med2p = percentile_df['2-perc'].median()\n",
    "    med98p = percentile_df['98-perc'].median()\n",
    "\n",
    "    cmap = plt.cm.plasma\n",
    "\n",
    "    unique_samples = sorted(filtered_data['Sample'].unique())\n",
    "    unique_sections = sorted(filtered_data['SectionPlot'].unique())\n",
    "\n",
    "    fig, axes = plt.subplots(6, 6, figsize=(20, 12))\n",
    "\n",
    "    for sample_idx, sample in enumerate(unique_samples[:6]):\n",
    "        for section_idx, section in enumerate(unique_sections[:6]):\n",
    "            ax = axes[sample_idx, section_idx]\n",
    "\n",
    "            try:\n",
    "                ddf = filtered_data[\n",
    "                    (filtered_data['Sample'] == sample) & \n",
    "                    (filtered_data['SectionPlot'] == section)\n",
    "                ]\n",
    "\n",
    "                ax.scatter(\n",
    "                    ddf['y'], \n",
    "                    -ddf['x'], \n",
    "                    c=ddf[currentPC], \n",
    "                    cmap=\"plasma\", \n",
    "                    s=0.5, \n",
    "                    rasterized=True, \n",
    "                    vmin=med2p, \n",
    "                    vmax=med98p\n",
    "                )\n",
    "\n",
    "                ax.axis('off')\n",
    "                ax.set_aspect('equal')\n",
    "\n",
    "                ax.set_title(f'Sample {sample}, Section {section}', fontsize=8)\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "    norm = Normalize(vmin=med2p, vmax=med98p)\n",
    "    sm = ScalarMappable(norm=norm, cmap=cmap)\n",
    "    fig.colorbar(sm, cax=cbar_ax)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "    plt.show() # this outlier is a bit burnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4083af17-9130-4d15-b695-eb26d8328592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file_path = './zenodo/mixed/allen_name_to_annots.pkl'\n",
    "\n",
    "with open(file_path, 'rb') as file:\n",
    "    allen_name_to_annots = pickle.load(file)\n",
    "\n",
    "divisions = ['Olfactory areas', 'Isocortex', 'Hippocampal formation', 'Cortical subplate', 'Striatum', 'Pallidum', 'Thalamus', 'Hypothalamus', 'Midbrain', 'Hindbrain', 'Cerebellum', 'fiber tracts', 'ventricular systems']#, ventricular systems']\n",
    "\n",
    "sub_alldata['division'] = \"General\"\n",
    "for i in divisions:\n",
    "    sub_alldata['division'][sub_alldata['id'].isin(allen_name_to_annots[i])] = i\n",
    "    \n",
    "sub_alldata['division'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a75939-583c-4ca3-b2e0-32e7fde0a7da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20b94ffe-d8d7-4772-aa57-b936c5a66c4e",
   "metadata": {},
   "source": [
    "## Assess which regions are overall changed the most in positive / negative lipid content, or \"membrane score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e8fb6-8b2f-4e66-8c2f-f794420ab479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at total production and total consumption and absolute balance\n",
    "activity = susc_df.iloc[:,:-1].copy()\n",
    "\n",
    "activitypersupertype = activity.sum(axis=1).sort_values()\n",
    "plt.hist(activitypersupertype, bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e31308-5506-463b-a657-e61900abfe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "activitypersupertype = pd.DataFrame(activitypersupertype)\n",
    "activitypersupertype['supertype'] = activitypersupertype.index\n",
    "actmap = pd.merge(\n",
    "    sub_alldata[['supertype']], \n",
    "    activitypersupertype,\n",
    "    on='supertype',\n",
    "    how='left'\n",
    ")\n",
    "actmap.index = sub_alldata.index\n",
    "actmap = actmap.iloc[:, 1:]\n",
    "actmap.columns = ['actmap']\n",
    "filtered_data2 = pd.concat([sub_alldata.loc[actmap.index,:], actmap],axis=1)\n",
    "\n",
    "for currentPC in [\"actmap\"]:\n",
    "    \n",
    "    print(currentPC)\n",
    "\n",
    "    unique_samples = sorted(filtered_data2['Sample'].unique())\n",
    "    unique_sections = sorted(filtered_data2['SectionPlot'].unique())\n",
    "\n",
    "    fig, axes = plt.subplots(6, 6, figsize=(20, 12))\n",
    "\n",
    "    for sample_idx, sample in enumerate(unique_samples[:6]):\n",
    "        for section_idx, section in enumerate(unique_sections[:6]):\n",
    "            ax = axes[sample_idx, section_idx]\n",
    "\n",
    "            try:\n",
    "                ddf = filtered_data2[\n",
    "                    (filtered_data2['Sample'] == sample) & \n",
    "                    (filtered_data2['SectionPlot'] == section)\n",
    "                ]\n",
    "\n",
    "                ax.scatter(\n",
    "                    ddf['y'], \n",
    "                    -ddf['x'], \n",
    "                    c=ddf[currentPC], \n",
    "                    cmap=\"coolwarm\", \n",
    "                    s=0.5, \n",
    "                    rasterized=True, \n",
    "                    vmin= -4.0, ########################\n",
    "                    vmax= 4.0 ########################\n",
    "                )\n",
    "\n",
    "                ax.axis('off')\n",
    "                ax.set_aspect('equal')\n",
    "\n",
    "                ax.set_title(f'Sample {sample}, Section {section}', fontsize=8)\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8efe42b-f90f-4cee-90fd-c92585fdb20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "namingtable = {\n",
    "    \"cluster\": [\n",
    "        11111, 11112, 11121, 11122, 11211, 11212, 11221, 11222, 12111, 12112, \n",
    "        12121, 12122, 12211, 12212, 12221, 12222, 21111, 21112, 21120, 21211, \n",
    "        21212, 21221, 21222, 22111, 22112, 22121, 22122, 22211, 22212, 22221, 22222\n",
    "    ],\n",
    "    \"zone\": [\n",
    "        \"Mixed and hindbrain white matter\", \"Core callosal white matter\", \n",
    "        \"Callosal and cerebellar white matter\", \"Ventral white matter\", \n",
    "        \"Boundary white matter\", \"Thalamic and mid/hindbrain white matter\", \n",
    "        \"Mid/hindbrain white matter\", \"Mixed white matter\", \n",
    "        \"Choroid plexus and ventricles\", \"Ventricular linings\", \n",
    "        \"Thalamic and midbrain regions\", \"White and gray matter boundary\", \n",
    "        \"Thalamic mixed gray and white matter\", \"Thalamic mixed gray and white matter #2\", \n",
    "        \"Neuron-rich lateral white matter\", \"Neuron-rich lateral white matter #2\", \n",
    "        \"Pallidum and projections\", \"Cortical layer 4\", \n",
    "        \"Subcortical plate, hippocampus and hypothalamus\", \n",
    "        \"GABA-ergic Purkinje cells of the cerebellum\", \"Cortical layers 2-3 and 4\", \n",
    "        \"Piriform cortex\", \"Cortical layers 1 and 2-3\", \"Cortical layer 5\", \n",
    "        \"Cortical layer 6, dentate gyrus\", \"Striatum, hypothalamus and hippocampus\", \n",
    "        \"Striatum, hypothalamus and hippocampus #2\", \n",
    "        \"Retrosplenial, cortical, cerebellar\", \"Cortical layer 6 and cerebellar Y\", \n",
    "        \"Cerebellar glutamatergic neurons\", \"Cortical layer 6 and thalamic\"\n",
    "    ],\n",
    "    \"color\": [\n",
    "        \"#360064\", \"#980053\", \"#170b3b\", \"#ac2f5c\", \"#2a3f6d\", \"#002657\", \n",
    "        \"#21366b\", \"#3e4b6c\", \"#f75400\", \"#ef633e\", \"#a5d4e6\", \"#6399c6\", \n",
    "        \"#853a00\", \"#edeef4\", \"#fdbf71\", \"#ce710e\", \"#940457\", \"#a2d36c\", \n",
    "        \"#d5edb5\", \"#0065d6\", \"#bcf18b\", \"#a68d68\", \"#79e47e\", \"#2f0097\", \n",
    "        \"#47029f\", \"#7500a8\", \"#d70021\", \"#ca99c9\", \"#d4b9da\", \"#e00085\", \n",
    "        \"#f6f3f8\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "namingtable = pd.DataFrame(namingtable)\n",
    "namingtable.index = namingtable['cluster'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a943f5-e430-4e3b-9801-7c4b16f31d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similar results as doing abs prod and abs degr independently\n",
    "activity = susc_df.iloc[:,:-1].copy()\n",
    "\n",
    "overallproduction = activity.sum(axis=1).sort_values()\n",
    "subclasses_tocheck = [x[:5] for x in list(overallproduction.index)]\n",
    "namingtable.loc[subclasses_tocheck, \"zone\"][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9835a76-a4bc-4b80-8591-940398cda182",
   "metadata": {},
   "outputs": [],
   "source": [
    "namingtable.loc[subclasses_tocheck, \"zone\"][-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c43062-77fc-4a3a-9b01-df536c463c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for currentPC in [\"actmap\"]:\n",
    "    print(currentPC)\n",
    "\n",
    "    unique_sections = sorted(filtered_data2['SectionPlot'].unique())\n",
    "    \n",
    "    # Create a figure\n",
    "    fig = plt.figure(figsize=(20, 4))\n",
    "    scatter_plots = []  # Collect scatter plots for colorbar\n",
    "\n",
    "    # Define starting position and width\n",
    "    left_start = 0.05  # Starting position\n",
    "    width = 0.2        # Width of each subplot\n",
    "    overlap = 0.1      # Amount of lateral overlap (50% of width)\n",
    "\n",
    "    for section_idx, section in enumerate(unique_sections[:6][::-1]):\n",
    "        left = left_start + section_idx * (width - overlap)  # Overlap each subplot\n",
    "\n",
    "        # Create an axis with adjusted position\n",
    "        ax = fig.add_axes([left, 0.2, width, 0.6])  # [left, bottom, width, height]\n",
    "\n",
    "        try:\n",
    "            ddf = filtered_data2[\n",
    "                (filtered_data2['Sample'] == 'Male3') & \n",
    "                (filtered_data2['SectionPlot'] == section)\n",
    "            ]\n",
    "\n",
    "            scatter = ax.scatter(\n",
    "                ddf['y'], \n",
    "                -ddf['x'], \n",
    "                c=ddf[currentPC], \n",
    "                cmap=\"coolwarm\", \n",
    "                s=0.5, \n",
    "                rasterized=True, \n",
    "                vmin=-4.0,  # Minimum value for color scale\n",
    "                vmax=4.0    # Maximum value for color scale\n",
    "            )\n",
    "            scatter_plots.append(scatter)\n",
    "\n",
    "            ax.axis('off')  # Hide axes\n",
    "            ax.set_aspect('equal')\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error with section {section}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Add a colorbar\n",
    "    cbar = fig.colorbar(scatter_plots[0], ax=fig.axes, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "    cbar.set_label('Activity Map', fontsize=10)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f7222d-b708-4700-a274-b11652ec32a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "374b98e5-de26-4d9e-9d0d-266c5720a638",
   "metadata": {},
   "source": [
    "## Pregnancy variation vs sex variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82f9537-7f06-43d5-bd1b-c51e0324b98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "sub_alldata = pd.read_parquet(\"./zenodo/maindata_2.parquet\")\n",
    "sub_alldata = sub_alldata.loc[(sub_alldata['Sample'].isin([\"Male1\", \"Male2\", \"Male3\", \"Female3\", \"Female2\", \"Female1\", \"Pregnant1\", \"Pregnant2\", \"Pregnant4\"])) ,:]\n",
    "sub_alldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df3517f-3d94-42f9-ae36-5b24619a2957",
   "metadata": {},
   "outputs": [],
   "source": [
    "lips = sub_alldata.iloc[:,:173]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4632e4-857c-4dde-a007-0f81d67143ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"pink\", \"pink\", \"pink\", \"blue\", \"blue\", \"blue\", \"purple\", \"purple\", \"purple\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae5b5d-803e-40c1-9a3d-f7c38f57fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datemp = lips.copy() \n",
    "p2 = datemp.quantile(0.005)\n",
    "p98 = datemp.quantile(0.995)\n",
    "\n",
    "datemp_values = datemp.values\n",
    "p2_values = p2.values\n",
    "p98_values = p98.values\n",
    "\n",
    "normalized_values = (datemp_values - p2_values) / (p98_values - p2_values)\n",
    "\n",
    "clipped_values = np.clip(normalized_values, 0, 1)\n",
    "\n",
    "normalized_datemp = pd.DataFrame(clipped_values, columns=datemp.columns, index=datemp.index)\n",
    "normalized_datemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337437a2-321e-4fb7-ba10-3e354ff92ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = normalized_datemp.groupby([sub_alldata['Sample'], sub_alldata['supertype']]).mean()\n",
    "centroids = centroids.unstack()\n",
    "centroidsOLD = centroids.copy()\n",
    "centroids = normalized_datemp.groupby([sub_alldata['SectionID'], sub_alldata['supertype']]).mean()\n",
    "centroids = centroids.unstack()\n",
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1bc20-c88d-4853-98b8-d519f8706cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = centroids.fillna(0.0)\n",
    "sub_alldata['colors'] = [x[:-1] for x in sub_alldata['Sample']]\n",
    "mdnow=sub_alldata[['SectionID', 'colors']].drop_duplicates().reset_index()\n",
    "mdnow.index = mdnow['SectionID']\n",
    "mdnow = mdnow.loc[centroids.index,:]\n",
    "mdnow.loc[mdnow['colors'] == \"Female\", 'colors'] = \"pink\"\n",
    "mdnow.loc[mdnow['colors'] == \"Male\", 'colors'] = \"blue\"\n",
    "mdnow.loc[mdnow['colors'] == \"Pregnant\", 'colors'] = \"purple\"\n",
    "mdnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036005fb-f3af-49e0-b27a-37b165e0cc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = pd.DataFrame(scaler.fit_transform(centroids), \n",
    "                          index=centroids.index, \n",
    "                          columns=centroids.columns)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(scaled_data)\n",
    "\n",
    "colors = mdnow['colors']\n",
    "var_explained = pca.explained_variance_ratio_ * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2896e0-1138-41da-b742-284b615583a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "\n",
    "df_pca = pd.DataFrame({\n",
    "    'PC1': pca_result[:, 0],\n",
    "    'PC2': pca_result[:, 1],\n",
    "    'Color': colors\n",
    "})\n",
    "\n",
    "def plot_confidence_ellipse(x, y, ax, color, n_std=2.0, **kwargs):\n",
    "    if len(x) < 3:\n",
    "        return\n",
    "\n",
    "    cov = np.cov(x, y)\n",
    "    if np.linalg.det(cov) == 0:\n",
    "        return\n",
    "\n",
    "    pearson = cov[0, 1] / np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "\n",
    "    mean_x = np.mean(x)\n",
    "    mean_y = np.mean(y)\n",
    "\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "\n",
    "    ellipse = Ellipse((0, 0),\n",
    "                      width=ell_radius_x * 2,\n",
    "                      height=ell_radius_y * 2,\n",
    "                      facecolor='none',\n",
    "                      edgecolor=color,\n",
    "                      linewidth=2,\n",
    "                      alpha=0.6,\n",
    "                      **kwargs)\n",
    "\n",
    "    transf = transforms.Affine2D().rotate_deg(45).scale(scale_x, scale_y).translate(mean_x, mean_y)\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "    ax.add_patch(ellipse)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "for color in np.unique(colors):\n",
    "    group_df = df_pca[df_pca['Color'] == color]\n",
    "    ax.scatter(group_df['PC1'], group_df['PC2'], color=color, edgecolor='black', s=100, alpha=0.9)\n",
    "    plot_confidence_ellipse(group_df['PC1'], group_df['PC2'], ax, color=color, n_std=2.0)\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({var_explained[0]:.1f}% variance)')\n",
    "ax.set_ylabel(f'PC2 ({var_explained[1]:.1f}% variance)')\n",
    "ax.set_title('2D PCA of Centroids with Confidence Ellipses')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"pca_mfpreg_2d.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceb8eb4-08b1-41de-89bd-398bf852883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.clustermap(centroidsOLD.T.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac04bbc-e579-466c-9d1a-6da9f43f3613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e4039-a740-4d18-b047-38b39805391f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
